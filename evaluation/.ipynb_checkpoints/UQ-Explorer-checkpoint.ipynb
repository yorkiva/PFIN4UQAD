{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b870969-f328-4973-9c57-080bb139143a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HDF5_USE_FILE_LOCKING=FALSE\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../model/\")\n",
    "sys.path.append(\"../dataset/\")\n",
    "from PFINTopDataset import PFINTopDataset\n",
    "from UQPFIN import UQPFIN as Model\n",
    "from train import getprobs\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "import json\n",
    "from scipy import interpolate\n",
    "from matplotlib import pyplot as plt\n",
    "%env HDF5_USE_FILE_LOCKING=FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "147ce7e2-f7cd-4f25-81b2-5d33e6193e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UQPFIN_best_baseline_0.1\n",
      "UQPFIN_best_baseline_0\n",
      "UQPFIN_best_baseline_nominal\n"
     ]
    }
   ],
   "source": [
    "saved_model_loc = \"../model/trained_models/\"\n",
    "saved_model_dict_loc = \"../model/trained_model_dicts/\"\n",
    "all_models = [f for f in os.listdir(saved_model_loc) if \"_best\" in f and \"_trial\" not in f]\n",
    "print(\"\\n\".join(all_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c125fc69-d332-4085-8d2e-4871da01c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"../dataset/PFIN_test.h5\"\n",
    "#Loading testing dataset\n",
    "test_set = PFINTopDataset(test_path)\n",
    "testloader = DataLoader(test_set, shuffle=True, batch_size=512, num_workers=8, pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b75a7dae-0963-4aaa-9c91-5cc7dab8a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval2(model, testloader):\n",
    "    labels = []\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for x,m,_,y,_,a,_ in tqdm(testloader):\n",
    "            x = x.cuda()\n",
    "            m = m.cuda()\n",
    "            a = a.cuda()\n",
    "            pred = model(x, a, m)\n",
    "            pred = getprobs(pred)\n",
    "            labels.append(y[:,1].cpu().numpy())\n",
    "            preds.append(pred[:,1].cpu().numpy())\n",
    "    labels = np.concatenate(labels, axis=None)\n",
    "    preds = np.concatenate(preds, axis=None)\n",
    "    return labels, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5fa028-7acc-45c8-aa6f-be6d1df38032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 100, 64] [64, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for modelname in all_models:\n",
    "    model_dict = json.load(open(saved_model_dict_loc + modelname.replace(\"_best\",\"\") + \".json\"))\n",
    "    Np = model_dict['Np']\n",
    "    phi_nodes = list(map(int, model_dict['phi_nodes'].split(',')))\n",
    "    f_nodes = list(map(int, model_dict['f_nodes'].split(',')))\n",
    "    label = model_dict['label']\n",
    "    n_phiI = model_dict['n_phiI']\n",
    "    x_mode = model_dict['x_mode']\n",
    "\n",
    "    model = Model(particle_feats = 3,\n",
    "                  n_consts = Np,\n",
    "                  PhiI_nodes = n_phiI,\n",
    "                  interaction_mode = x_mode,\n",
    "                  Phi_sizes = phi_nodes,\n",
    "                  F_sizes   = f_nodes).cuda()\n",
    "    \n",
    "    model.load_state_dict(torch.load(saved_model_loc + modelname ))\n",
    "    nparams = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "    \n",
    "    labels, preds = eval2(model)\n",
    "    accuracy = accuracy_score(labels, preds.round())*100\n",
    "    \n",
    "    auc = roc_auc_score(labels, preds)*100\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(labels, preds, drop_intermediate=False)\n",
    "    intrp = interpolate.interp1d(tpr, fpr)\n",
    "    if 'baseline' in modelname:\n",
    "        eS = np.array(list(range(1,20)))*0.05\n",
    "        inveB = []\n",
    "        for es in eS:\n",
    "            inveB.append(1./intrp(es))\n",
    "        plt.figure()\n",
    "        plt.plot(eS, inveB)\n",
    "        plt.yscale(\"log\")\n",
    "        plt.show()\n",
    "    brr = 1./intrp(0.3)\n",
    "    print(\"{} \\t\\t Params: {}\\t ROC-AUC: {:.2f}%, Accuracy: {:.2f}%, BRR: {:.2f}\".format(modelname,nparams,auc,accuracy,brr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-toptagger_env]",
   "language": "python",
   "name": "conda-env-.conda-toptagger_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
