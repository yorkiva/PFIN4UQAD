Running "module reset". Resetting modules to system default. The following $MODULEPATH directories have been removed: None
A conda environment has been detected CONDA_PREFIX=
/sw/external/python/anaconda3 
anaconda3_gpu is loaded. Consider running conda deactivate and reloading it.

Currently Loaded Modules:
  1) cue-login-env/1.0   4) gcc/11.2.0    7) openmpi/4.1.2
  2) default             5) cuda/11.6.1   8) cudnn/8.4.1.50
  3) modtree/gpu         6) ucx/1.11.2    9) anaconda3_gpu/4.13.0

 

/u/avroy/UQ_XAI_Studies/models/PFIN_UQ/model/jobsub
total 508K
-rw-rw----+ 1 avroy delta_bbhj  925 Mar 31 16:58 jobsubmitter_dummy.py
-rw-rw----+ 1 avroy delta_bbhj 5.2K May 27 21:16 jobsubmitter_jetclass_1gpu.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 27 21:04 jobsubmitter_jetclass_1gpu.py~
-rw-rw----+ 1 avroy delta_bbhj  743 May 19 01:04 jobsubmitter_jetclass.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 18 13:59 jobsubmitter.py
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 19 13:52 UQPFIN-jetclass-run-jetclass20M_0_baseline.slurm
-rw-------+ 1 avroy delta_bbhj  973 May 19 00:59 UQPFIN-jetclass-run.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_9.slurm
-rw-------+ 1 avroy delta_bbhj  969 May 15 09:44 UQPFIN-run.slurm
/projects/bbhj/avroy/UQ_XAI_Studies/models/PFIN_UQ/model
total 184K
drwxr-s---+ 2 avroy delta_bbhj  12K May 28 01:44 jobouts
drwxr-s---+ 2 avroy delta_bbhj  16K May 27 21:18 jobsub
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 18 21:37 PFINDataset.py
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 15 14:46 PFINDataset.py~
drwxrws---+ 2 avroy delta_bbhj 4.0K May 18 21:38 __pycache__
drwxrws---+ 2 avroy delta_bbhj  16K May 27 23:34 trained_model_dicts
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:09 trained_model_dicts_old
drwxrws---+ 2 avroy delta_bbhj  24K May 27 23:53 trained_models
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:10 trained_models_old
-rw-rw----+ 1 avroy delta_bbhj  23K May 18 15:52 train_mod.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 27 21:06 train.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 18 13:50 train.py~
-rw-rw----+ 1 avroy delta_bbhj  13K May  5 09:36 UQPFIN.py
job is starting on gpua062.delta.ncsa.illinois.edu
# conda environments:
#
base                     /sw/external/python/anaconda3
toptagger_env         *  /u/avroy/.conda/envs/toptagger_env

/sw/external/python/anaconda3_gpu/bin/python
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
UQPFIN                                   [1, 8]                    --
├─Sequential: 1-1                        [60, 64]                  --
│    └─Sequential: 2-1                   [60, 100]                 --
│    │    └─Linear: 3-1                  [60, 100]                 1,200
│    │    └─ReLU: 3-2                    [60, 100]                 --
│    └─Sequential: 2-2                   [60, 100]                 --
│    │    └─Linear: 3-3                  [60, 100]                 10,100
│    │    └─ReLU: 3-4                    [60, 100]                 --
│    └─Sequential: 2-3                   [60, 64]                  --
│    │    └─Linear: 3-5                  [60, 64]                  6,464
│    │    └─ReLU: 3-6                    [60, 64]                  --
├─Sequential: 1-2                        [1770, 64]                --
│    └─Sequential: 2-4                   [1770, 128]               --
│    │    └─Linear: 3-7                  [1770, 128]               640
│    │    └─ReLU: 3-8                    [1770, 128]               --
│    └─Sequential: 2-5                   [1770, 128]               --
│    │    └─Linear: 3-9                  [1770, 128]               16,512
│    │    └─ReLU: 3-10                   [1770, 128]               --
│    └─Sequential: 2-6                   [1770, 64]                --
│    │    └─Linear: 3-11                 [1770, 64]                8,256
│    │    └─ReLU: 3-12                   [1770, 64]                --
├─Sequential: 1-3                        [60, 64]                  --
│    └─Sequential: 2-7                   [60, 128]                 --
│    │    └─Linear: 3-13                 [60, 128]                 9,728
│    │    └─ReLU: 3-14                   [60, 128]                 --
│    └─Sequential: 2-8                   [60, 128]                 --
│    │    └─Linear: 3-15                 [60, 128]                 16,512
│    │    └─ReLU: 3-16                   [60, 128]                 --
│    └─Sequential: 2-9                   [60, 64]                  --
│    │    └─Linear: 3-17                 [60, 64]                  8,256
│    │    └─ReLU: 3-18                   [60, 64]                  --
├─Sequential: 1-4                        [1, 8]                    --
│    └─Sequential: 2-10                  [1, 64]                   --
│    │    └─Linear: 3-19                 [1, 64]                   4,160
│    │    └─ReLU: 3-20                   [1, 64]                   --
│    └─Sequential: 2-11                  [1, 100]                  --
│    │    └─Linear: 3-21                 [1, 100]                  6,500
│    │    └─ReLU: 3-22                   [1, 100]                  --
│    └─Sequential: 2-12                  [1, 100]                  --
│    │    └─Linear: 3-23                 [1, 100]                  10,100
│    │    └─ReLU: 3-24                   [1, 100]                  --
│    └─Linear: 2-13                      [1, 8]                    808
│    └─Softmax: 2-14                     [1, 8]                    --
==========================================================================================
Total params: 99,236
Trainable params: 99,236
Non-trainable params: 0
Total mult-adds (M): 48.13
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 4.81
Params size (MB): 0.40
Estimated Total Size (MB): 5.21
==========================================================================================
data type:  jetclass
m_logic, pt_logic, eta_logic:  AND AND AND
m1, m2, pt1, pt2, eta1, eta2:  0.0 10000.0 0.0 10000.0 -6.0 6.0
skip labels:  [8, 9]
classes:  8
Epoch 0
Best Validation Accuracy: 0
Current Validation Accuracy: 0.6805607059351759
Current Validation Loss: 0.00042895567951590856
Saving best model based on accuracy
Epoch 1
Best Validation Accuracy: 0.6805607059351759
Current Validation Accuracy: 0.6958871934499261
Current Validation Loss: 0.00041225339346646694
Saving best model based on accuracy
Epoch 2
Best Validation Accuracy: 0.6958871934499261
Current Validation Accuracy: 0.6991771135125603
Current Validation Loss: 0.000407477896769113
Saving best model based on accuracy
Epoch 3
Best Validation Accuracy: 0.6991771135125603
Current Validation Accuracy: 0.7028622492147278
Current Validation Loss: 0.00040369586744849187
Saving best model based on accuracy
Epoch 4
Best Validation Accuracy: 0.7028622492147278
Current Validation Accuracy: 0.7047226392900626
Current Validation Loss: 0.00040147844340140466
Saving best model based on accuracy
Epoch 5
Best Validation Accuracy: 0.7047226392900626
Current Validation Accuracy: 0.7064204406529313
Current Validation Loss: 0.0003994302484376539
Saving best model based on accuracy
Epoch 6
Best Validation Accuracy: 0.7064204406529313
Current Validation Accuracy: 0.7061615493953889
Current Validation Loss: 0.00039884617150825097
Epoch 7
Best Validation Accuracy: 0.7064204406529313
Current Validation Accuracy: 0.7086841758034227
Current Validation Loss: 0.00039577902053337754
Saving best model based on accuracy
Epoch 8
Best Validation Accuracy: 0.7086841758034227
Current Validation Accuracy: 0.7274650481168787
Current Validation Loss: 0.0003738966898786184
Saving best model based on accuracy
Epoch 9
Best Validation Accuracy: 0.7274650481168787
Current Validation Accuracy: 0.7240275475306214
Current Validation Loss: 0.0003785461345904398
Epoch 10
Best Validation Accuracy: 0.7274650481168787
Current Validation Accuracy: 0.7477079681601274
Current Validation Loss: 0.00034772746434933127
Saving best model based on accuracy
Epoch 11
Best Validation Accuracy: 0.7477079681601274
Current Validation Accuracy: 0.7509816293515149
Current Validation Loss: 0.00034252820110226997
Saving best model based on accuracy
Epoch 12
Best Validation Accuracy: 0.7509816293515149
Current Validation Accuracy: 0.7516738820619
Current Validation Loss: 0.00034154668393634975
Saving best model based on accuracy
Epoch 13
Best Validation Accuracy: 0.7516738820619
Current Validation Accuracy: 0.7564333539487483
Current Validation Loss: 0.00033545336119325216
Saving best model based on accuracy
Epoch 14
Best Validation Accuracy: 0.7564333539487483
Current Validation Accuracy: 0.7554171744958343
Current Validation Loss: 0.0003365404734859217
Epoch 15
Best Validation Accuracy: 0.7564333539487483
Current Validation Accuracy: 0.762255905878645
Current Validation Loss: 0.00032767416211778834
Saving best model based on accuracy
Epoch 16
Best Validation Accuracy: 0.762255905878645
Current Validation Accuracy: 0.7591898579662528
Current Validation Loss: 0.00033145310480411563
Epoch 17
Best Validation Accuracy: 0.762255905878645
Current Validation Accuracy: 0.7671104296281659
Current Validation Loss: 0.00032094425768185153
Saving best model based on accuracy
Epoch 18
Best Validation Accuracy: 0.7671104296281659
Current Validation Accuracy: 0.7644239638252621
Current Validation Loss: 0.00032458556818328917
Epoch 19
Best Validation Accuracy: 0.7671104296281659
Current Validation Accuracy: 0.7692947464460296
Current Validation Loss: 0.0003175858012391817
Saving best model based on accuracy
Epoch 20
Best Validation Accuracy: 0.7692947464460296
Current Validation Accuracy: 0.7690902598730432
Current Validation Loss: 0.0003178222729251281
Epoch 21
Best Validation Accuracy: 0.7692947464460296
Current Validation Accuracy: 0.7691571713816351
Current Validation Loss: 0.0003175335730804609
Epoch 22
Best Validation Accuracy: 0.7692947464460296
Current Validation Accuracy: 0.7697074716392132
Current Validation Loss: 0.000316621559996453
Saving best model based on accuracy
Epoch 23
Best Validation Accuracy: 0.7697074716392132
Current Validation Accuracy: 0.7698631815984597
Current Validation Loss: 0.0003167185924908251
Saving best model based on accuracy
Epoch 24
Best Validation Accuracy: 0.7698631815984597
Current Validation Accuracy: 0.7713496176351221
Current Validation Loss: 0.0003147238109002869
Saving best model based on accuracy
Epoch 25
Best Validation Accuracy: 0.7713496176351221
Current Validation Accuracy: 0.7722613651073367
Current Validation Loss: 0.000313583162679991
Saving best model based on accuracy
Epoch 26
Best Validation Accuracy: 0.7722613651073367
Current Validation Accuracy: 0.7709081267466561
Current Validation Loss: 0.0003151263829910609
Epoch 27
Best Validation Accuracy: 0.7722613651073367
Current Validation Accuracy: 0.7673111641539415
Current Validation Loss: 0.00032046171917155474
Epoch 28
Best Validation Accuracy: 0.7722613651073367
Current Validation Accuracy: 0.7729185987104213
Current Validation Loss: 0.0003123176571560573
Saving best model based on accuracy
Epoch 29
[[9.87539172e-01 1.34296599e-04 6.74906769e-04 2.37877667e-03
  2.05980341e-05 1.28093970e-05 5.93504123e-03 3.30436253e-03]
 [2.39332840e-02 6.42093888e-04 1.29462391e-01 7.75212884e-01
  5.77694811e-02 1.84763285e-05 1.16171092e-02 1.34423375e-03]
 [3.40195699e-03 2.29168171e-03 3.97338569e-02 1.72546774e-03
  4.52004513e-03 8.48999798e-01 9.16423649e-02 7.68481661e-03]
 [1.94770187e-01 9.71886329e-05 3.04267486e-03 2.76866220e-02
  1.68762123e-03 7.66502053e-04 3.16248477e-01 4.55700815e-01]
 [2.54970081e-02 1.27763852e-01 1.63195553e-04 9.52096016e-04
  7.98854035e-06 7.11789153e-06 8.44272077e-01 1.33679132e-03]
 [6.34955941e-04 3.36150106e-06 1.83226133e-03 4.72185807e-03
  9.91368353e-01 4.58740069e-05 4.56967566e-04 9.36333265e-04]
 [9.89378393e-01 1.08520944e-05 5.21449023e-04 6.31893054e-05
  1.45543095e-06 1.26037805e-04 4.44458378e-03 5.45407366e-03]
 [1.30760585e-04 1.23071790e-04 2.04510950e-02 6.02630107e-03
  9.72733557e-01 2.28623207e-06 1.96053923e-04 3.36801779e-04]
 [3.29089654e-03 1.34823058e-04 5.39184827e-03 1.21458259e-03
  2.21809722e-03 4.11287928e-03 4.00976181e-01 5.82660675e-01]
 [9.87199366e-01 5.79909065e-05 4.58204333e-04 4.05158324e-04
  4.71367684e-06 2.32577549e-05 6.07342692e-03 5.77791734e-03]
 [9.32130683e-03 5.63299400e-04 6.45022467e-02 2.14502960e-01
  6.92033172e-01 3.14459830e-05 9.60227195e-03 9.44328867e-03]
 [3.05716950e-03 4.73531693e-01 2.74628843e-03 6.22301409e-03
  5.85733971e-04 5.23375784e-05 5.13724923e-01 7.88499456e-05]
 [9.68490779e-01 5.08189396e-06 1.48788828e-03 1.91827014e-04
  1.29679647e-05 1.03996226e-05 1.62857231e-02 1.35153290e-02]
 [1.37538472e-02 1.75112626e-04 1.75635405e-02 1.38771057e-01
  8.18198085e-01 1.53702749e-05 6.23531733e-03 5.28760813e-03]
 [2.88633091e-05 1.08934746e-05 1.80404633e-04 3.13674173e-05
  6.36285477e-05 9.99537230e-01 1.09328157e-05 1.36777613e-04]
 [8.13761055e-02 2.94965517e-04 1.08439662e-02 9.80058983e-02
  7.43423283e-01 8.23115814e-04 4.42652814e-02 2.09674034e-02]
 [5.73528087e-06 3.25938299e-06 3.54536951e-06 4.14661763e-08
  3.46507623e-09 9.99987125e-01 2.06162056e-07 9.18130283e-08]
 [1.21404454e-02 2.77930801e-03 7.78840035e-02 1.64320618e-02
  7.10560322e-01 4.67208709e-04 1.16796210e-01 6.29403815e-02]
 [1.08028464e-01 9.85822524e-04 5.19649148e-01 1.32718444e-01
  1.99447662e-01 5.62931473e-06 3.09850592e-02 8.17975868e-03]
 [2.83342358e-02 2.16909826e-01 1.75140530e-03 1.49424377e-04
  6.41849510e-06 7.16409559e-05 7.47547150e-01 5.22986008e-03]]
[[9.87539172e-01 1.34296599e-04 6.74906769e-04 2.37877667e-03
  2.05980341e-05 1.28093970e-05 5.93504123e-03 3.30436253e-03]
 [2.39332840e-02 6.42093888e-04 1.29462391e-01 7.75212884e-01
  5.77694811e-02 1.84763285e-05 1.16171092e-02 1.34423375e-03]
 [3.40195699e-03 2.29168171e-03 3.97338569e-02 1.72546774e-03
  4.52004513e-03 8.48999798e-01 9.16423649e-02 7.68481661e-03]
 [1.94770187e-01 9.71886329e-05 3.04267486e-03 2.76866220e-02
  1.68762123e-03 7.66502053e-04 3.16248477e-01 4.55700815e-01]
 [2.54970081e-02 1.27763852e-01 1.63195553e-04 9.52096016e-04
  7.98854035e-06 7.11789153e-06 8.44272077e-01 1.33679132e-03]
 [6.34955941e-04 3.36150106e-06 1.83226133e-03 4.72185807e-03
  9.91368353e-01 4.58740069e-05 4.56967566e-04 9.36333265e-04]
 [9.89378393e-01 1.08520944e-05 5.21449023e-04 6.31893054e-05
  1.45543095e-06 1.26037805e-04 4.44458378e-03 5.45407366e-03]
 [1.30760585e-04 1.23071790e-04 2.04510950e-02 6.02630107e-03
  9.72733557e-01 2.28623207e-06 1.96053923e-04 3.36801779e-04]
 [3.29089654e-03 1.34823058e-04 5.39184827e-03 1.21458259e-03
  2.21809722e-03 4.11287928e-03 4.00976181e-01 5.82660675e-01]
 [9.87199366e-01 5.79909065e-05 4.58204333e-04 4.05158324e-04
  4.71367684e-06 2.32577549e-05 6.07342692e-03 5.77791734e-03]
 [9.32130683e-03 5.63299400e-04 6.45022467e-02 2.14502960e-01
  6.92033172e-01 3.14459830e-05 9.60227195e-03 9.44328867e-03]
 [3.05716950e-03 4.73531693e-01 2.74628843e-03 6.22301409e-03
  5.85733971e-04 5.23375784e-05 5.13724923e-01 7.88499456e-05]
 [9.68490779e-01 5.08189396e-06 1.48788828e-03 1.91827014e-04
  1.29679647e-05 1.03996226e-05 1.62857231e-02 1.35153290e-02]
 [1.37538472e-02 1.75112626e-04 1.75635405e-02 1.38771057e-01
  8.18198085e-01 1.53702749e-05 6.23531733e-03 5.28760813e-03]
 [2.88633091e-05 1.08934746e-05 1.80404633e-04 3.13674173e-05
  6.36285477e-05 9.99537230e-01 1.09328157e-05 1.36777613e-04]
 [8.13761055e-02 2.94965517e-04 1.08439662e-02 9.80058983e-02
  7.43423283e-01 8.23115814e-04 4.42652814e-02 2.09674034e-02]
 [5.73528087e-06 3.25938299e-06 3.54536951e-06 4.14661763e-08
  3.46507623e-09 9.99987125e-01 2.06162056e-07 9.18130283e-08]
 [1.21404454e-02 2.77930801e-03 7.78840035e-02 1.64320618e-02
  7.10560322e-01 4.67208709e-04 1.16796210e-01 6.29403815e-02]
 [1.08028464e-01 9.85822524e-04 5.19649148e-01 1.32718444e-01
  1.99447662e-01 5.62931473e-06 3.09850592e-02 8.17975868e-03]
 [2.83342358e-02 2.16909826e-01 1.75140530e-03 1.49424377e-04
  6.41849510e-06 7.16409559e-05 7.47547150e-01 5.22986008e-03]]
[[1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0.]]
Best Validation Accuracy: 0.7729185987104213
Current Validation Accuracy: 0.7739172686096851
Current Validation Loss: 0.00031094279984731466
Saving best model based on accuracy
Saving last model
