Running "module reset". Resetting modules to system default. The following $MODULEPATH directories have been removed: None
A conda environment has been detected CONDA_PREFIX=
/sw/external/python/anaconda3 
anaconda3_gpu is loaded. Consider running conda deactivate and reloading it.

Currently Loaded Modules:
  1) cue-login-env/1.0   4) gcc/11.2.0    7) openmpi/4.1.2
  2) default             5) cuda/11.6.1   8) cudnn/8.4.1.50
  3) modtree/gpu         6) ucx/1.11.2    9) anaconda3_gpu/4.13.0

 

/u/avroy/UQ_XAI_Studies/models/PFIN_UQ/model/jobsub
total 508K
-rw-rw----+ 1 avroy delta_bbhj  925 Mar 31 16:58 jobsubmitter_dummy.py
-rw-rw----+ 1 avroy delta_bbhj 5.2K May 27 21:16 jobsubmitter_jetclass_1gpu.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 27 21:04 jobsubmitter_jetclass_1gpu.py~
-rw-rw----+ 1 avroy delta_bbhj  743 May 19 01:04 jobsubmitter_jetclass.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 18 13:59 jobsubmitter.py
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 19 13:52 UQPFIN-jetclass-run-jetclass20M_0_baseline.slurm
-rw-------+ 1 avroy delta_bbhj  973 May 19 00:59 UQPFIN-jetclass-run.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_9.slurm
-rw-------+ 1 avroy delta_bbhj  969 May 15 09:44 UQPFIN-run.slurm
/projects/bbhj/avroy/UQ_XAI_Studies/models/PFIN_UQ/model
total 200K
drwxr-s---+ 2 avroy delta_bbhj  12K May 28 09:28 jobouts
drwxr-s---+ 2 avroy delta_bbhj  16K May 27 21:18 jobsub
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 18 21:37 PFINDataset.py
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 15 14:46 PFINDataset.py~
drwxrws---+ 2 avroy delta_bbhj 4.0K May 18 21:38 __pycache__
drwxrws---+ 2 avroy delta_bbhj  20K May 28 09:28 trained_model_dicts
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:09 trained_model_dicts_old
drwxrws---+ 2 avroy delta_bbhj  36K May 28 09:28 trained_models
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:10 trained_models_old
-rw-rw----+ 1 avroy delta_bbhj  23K May 18 15:52 train_mod.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 27 21:06 train.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 18 13:50 train.py~
-rw-rw----+ 1 avroy delta_bbhj  13K May  5 09:36 UQPFIN.py
job is starting on gpua057.delta.ncsa.illinois.edu
# conda environments:
#
base                     /sw/external/python/anaconda3
toptagger_env         *  /u/avroy/.conda/envs/toptagger_env

/sw/external/python/anaconda3_gpu/bin/python
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
UQPFIN                                   [1, 8]                    --
├─Sequential: 1-1                        [60, 64]                  --
│    └─Sequential: 2-1                   [60, 100]                 --
│    │    └─Linear: 3-1                  [60, 100]                 1,200
│    │    └─ReLU: 3-2                    [60, 100]                 --
│    └─Sequential: 2-2                   [60, 100]                 --
│    │    └─Linear: 3-3                  [60, 100]                 10,100
│    │    └─ReLU: 3-4                    [60, 100]                 --
│    └─Sequential: 2-3                   [60, 64]                  --
│    │    └─Linear: 3-5                  [60, 64]                  6,464
│    │    └─ReLU: 3-6                    [60, 64]                  --
├─Sequential: 1-2                        [1770, 64]                --
│    └─Sequential: 2-4                   [1770, 128]               --
│    │    └─Linear: 3-7                  [1770, 128]               640
│    │    └─ReLU: 3-8                    [1770, 128]               --
│    └─Sequential: 2-5                   [1770, 128]               --
│    │    └─Linear: 3-9                  [1770, 128]               16,512
│    │    └─ReLU: 3-10                   [1770, 128]               --
│    └─Sequential: 2-6                   [1770, 64]                --
│    │    └─Linear: 3-11                 [1770, 64]                8,256
│    │    └─ReLU: 3-12                   [1770, 64]                --
├─Sequential: 1-3                        [60, 64]                  --
│    └─Sequential: 2-7                   [60, 128]                 --
│    │    └─Linear: 3-13                 [60, 128]                 9,728
│    │    └─ReLU: 3-14                   [60, 128]                 --
│    └─Sequential: 2-8                   [60, 128]                 --
│    │    └─Linear: 3-15                 [60, 128]                 16,512
│    │    └─ReLU: 3-16                   [60, 128]                 --
│    └─Sequential: 2-9                   [60, 64]                  --
│    │    └─Linear: 3-17                 [60, 64]                  8,256
│    │    └─ReLU: 3-18                   [60, 64]                  --
├─Sequential: 1-4                        [1, 8]                    --
│    └─Sequential: 2-10                  [1, 64]                   --
│    │    └─Linear: 3-19                 [1, 64]                   4,160
│    │    └─ReLU: 3-20                   [1, 64]                   --
│    └─Sequential: 2-11                  [1, 100]                  --
│    │    └─Linear: 3-21                 [1, 100]                  6,500
│    │    └─ReLU: 3-22                   [1, 100]                  --
│    └─Sequential: 2-12                  [1, 100]                  --
│    │    └─Linear: 3-23                 [1, 100]                  10,100
│    │    └─ReLU: 3-24                   [1, 100]                  --
│    └─Linear: 2-13                      [1, 8]                    808
│    └─Softmax: 2-14                     [1, 8]                    --
==========================================================================================
Total params: 99,236
Trainable params: 99,236
Non-trainable params: 0
Total mult-adds (M): 48.13
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 4.81
Params size (MB): 0.40
Estimated Total Size (MB): 5.21
==========================================================================================
data type:  jetclass
m_logic, pt_logic, eta_logic:  AND AND AND
m1, m2, pt1, pt2, eta1, eta2:  0.0 10000.0 0.0 10000.0 -6.0 6.0
skip labels:  [6, 7]
classes:  8
Epoch 0
Best Validation Accuracy: 0
Current Validation Accuracy: 0.7639000825954866
Current Validation Loss: 0.0003239470516164289
Saving best model based on accuracy
Epoch 1
Best Validation Accuracy: 0.7639000825954866
Current Validation Accuracy: 0.7737308837717063
Current Validation Loss: 0.0003104432373682467
Saving best model based on accuracy
Epoch 2
Best Validation Accuracy: 0.7737308837717063
Current Validation Accuracy: 0.7770640899709321
Current Validation Loss: 0.0003063159606775025
Saving best model based on accuracy
Epoch 3
Best Validation Accuracy: 0.7770640899709321
Current Validation Accuracy: 0.7797189002357817
Current Validation Loss: 0.0003023068586852796
Saving best model based on accuracy
Epoch 4
Best Validation Accuracy: 0.7797189002357817
Current Validation Accuracy: 0.783530422462471
Current Validation Loss: 0.0002991365453421985
Saving best model based on accuracy
Epoch 5
Best Validation Accuracy: 0.783530422462471
Current Validation Accuracy: 0.780349151942557
Current Validation Loss: 0.00030221770206447434
Epoch 6
Best Validation Accuracy: 0.783530422462471
Current Validation Accuracy: 0.7749201087184194
Current Validation Loss: 0.00031218322531477785
Epoch 7
Best Validation Accuracy: 0.783530422462471
Current Validation Accuracy: 0.7840212434841165
Current Validation Loss: 0.00029730603543222465
Saving best model based on accuracy
Epoch 8
Best Validation Accuracy: 0.7840212434841165
Current Validation Accuracy: 0.8052540983555307
Current Validation Loss: 0.0002729143742112893
Saving best model based on accuracy
Epoch 9
Best Validation Accuracy: 0.8052540983555307
Current Validation Accuracy: 0.8243117094889771
Current Validation Loss: 0.00024668147379636174
Saving best model based on accuracy
Epoch 10
Best Validation Accuracy: 0.8243117094889771
Current Validation Accuracy: 0.8199587210142051
Current Validation Loss: 0.0002520234527799071
Epoch 11
Best Validation Accuracy: 0.8243117094889771
Current Validation Accuracy: 0.8338292605609365
Current Validation Loss: 0.00023415456384506502
Saving best model based on accuracy
Epoch 12
Best Validation Accuracy: 0.8338292605609365
Current Validation Accuracy: 0.8376701695239537
Current Validation Loss: 0.00022891709344398492
Saving best model based on accuracy
Epoch 13
Best Validation Accuracy: 0.8376701695239537
Current Validation Accuracy: 0.8276774286730764
Current Validation Loss: 0.00024268739791490489
Epoch 14
Best Validation Accuracy: 0.8376701695239537
Current Validation Accuracy: 0.8448767976710699
Current Validation Loss: 0.0002191423213727997
Saving best model based on accuracy
Epoch 15
Best Validation Accuracy: 0.8448767976710699
Current Validation Accuracy: 0.845572700597301
Current Validation Loss: 0.00021803112555031045
Saving best model based on accuracy
Epoch 16
Best Validation Accuracy: 0.845572700597301
Current Validation Accuracy: 0.8468163222687061
Current Validation Loss: 0.0002163640711843095
Saving best model based on accuracy
Epoch 17
Best Validation Accuracy: 0.8468163222687061
Current Validation Accuracy: 0.8471770913508583
Current Validation Loss: 0.00021573235230916624
Saving best model based on accuracy
Epoch 18
Best Validation Accuracy: 0.8471770913508583
Current Validation Accuracy: 0.8477110546024319
Current Validation Loss: 0.0002146690787610542
Saving best model based on accuracy
Epoch 19
Best Validation Accuracy: 0.8477110546024319
Current Validation Accuracy: 0.8439970713303626
Current Validation Loss: 0.0002198587273989781
Epoch 20
Best Validation Accuracy: 0.8477110546024319
Current Validation Accuracy: 0.8484207130222633
Current Validation Loss: 0.00021335531164730842
Saving best model based on accuracy
Epoch 21
Best Validation Accuracy: 0.8484207130222633
Current Validation Accuracy: 0.8487702276096516
Current Validation Loss: 0.00021296849397097844
Saving best model based on accuracy
Epoch 22
Best Validation Accuracy: 0.8487702276096516
Current Validation Accuracy: 0.8488621393168897
Current Validation Loss: 0.00021257962462844916
Validation Accuracy has not changed much, will stop in 4 epochs if this continues
Saving best model based on accuracy
Epoch 23
Best Validation Accuracy: 0.8488621393168897
Current Validation Accuracy: 0.8494973930213379
Current Validation Loss: 0.000211911766863663
Saving best model based on accuracy
Epoch 24
Best Validation Accuracy: 0.8494973930213379
Current Validation Accuracy: 0.849687468932905
Current Validation Loss: 0.0002116473302077817
Saving best model based on accuracy
Epoch 25
Best Validation Accuracy: 0.849687468932905
Current Validation Accuracy: 0.8507816559238346
Current Validation Loss: 0.00021001976216130245
Saving best model based on accuracy
Epoch 26
Best Validation Accuracy: 0.8507816559238346
Current Validation Accuracy: 0.8510136235659116
Current Validation Loss: 0.00020967150633977467
Saving best model based on accuracy
Epoch 27
Best Validation Accuracy: 0.8510136235659116
Current Validation Accuracy: 0.8513093666783171
Current Validation Loss: 0.00020951593054757304
Saving best model based on accuracy
Epoch 28
Best Validation Accuracy: 0.8513093666783171
Current Validation Accuracy: 0.8516676347616329
Current Validation Loss: 0.00020897003062751637
Saving best model based on accuracy
Epoch 29
[[9.97288465e-01 1.42893507e-04 8.14986823e-04 1.69076899e-03
  7.38882818e-06 1.40569318e-05 1.64918470e-06 3.98638294e-05]
 [3.48926149e-02 1.01211073e-03 1.69189051e-01 7.20996857e-01
  7.12797120e-02 1.15040539e-05 2.61540222e-03 2.78705966e-06]
 [3.20905360e-06 1.92337666e-05 1.31899833e-05 1.16909996e-06
  3.17148512e-08 2.17394531e-03 5.72900319e-07 9.97788668e-01]
 [1.16486177e-02 1.02946982e-02 4.56205830e-02 5.01548173e-03
  1.57041121e-02 9.09641862e-01 1.86452095e-03 2.10171202e-04]
 [1.48622696e-08 1.28451973e-06 8.06430922e-09 8.97065089e-09
  4.52402525e-11 1.32224659e-05 1.12432215e-08 9.99985456e-01]
 [5.27599826e-04 1.75761306e-06 1.05398381e-03 5.47228148e-03
  9.92776990e-01 8.82876120e-05 7.89595797e-05 1.98824992e-07]
 [9.99597371e-01 1.53539004e-05 3.10869626e-04 2.08896872e-05
  1.57902264e-07 4.18691816e-05 1.51222679e-08 1.35239488e-05]
 [2.29791141e-04 4.78850743e-05 1.73776112e-02 6.01113681e-03
  9.75797832e-01 4.40316626e-07 5.35434228e-04 3.16328546e-08]
 [9.97751415e-01 1.59307354e-04 1.15950860e-03 8.39175889e-04
  6.92871890e-06 6.66335109e-05 1.23719542e-06 1.58716775e-05]
 [1.43061476e-02 1.29522965e-03 6.56252503e-02 1.38356864e-01
  7.50371456e-01 4.96779430e-05 2.99923830e-02 2.98999771e-06]
 [9.97857034e-01 1.65461861e-05 1.62085518e-03 1.51373592e-04
  4.85429018e-06 8.99739462e-06 2.64760136e-04 7.55253204e-05]
 [9.77862906e-03 5.42423164e-04 4.02351692e-02 7.71719590e-02
  8.45112085e-01 2.96226281e-05 2.71267463e-02 3.36094217e-06]
 [3.30482617e-05 2.34180720e-06 1.31788620e-04 6.32524097e-05
  1.13316521e-04 9.99581039e-01 1.15209104e-05 6.36667901e-05]
 [5.53963929e-02 1.01174766e-04 1.01537106e-03 1.98963787e-02
  1.88528821e-01 1.80197443e-04 7.34876096e-01 5.49494325e-06]
 [1.21138827e-03 1.40276842e-03 3.63638857e-03 1.25176355e-03
  7.28477258e-04 4.01537636e-06 9.91752803e-01 1.24007211e-05]
 [1.06721000e-05 1.46530283e-06 2.94845468e-05 2.32378829e-06
  2.97100587e-06 9.70939338e-01 1.17873515e-06 2.90125348e-02]
 [1.36829883e-01 5.92676457e-04 3.06331903e-01 1.36094272e-01
  4.16696668e-01 1.40669916e-04 3.31085152e-03 3.11962026e-06]
 [6.81405663e-02 8.81694853e-01 3.55769657e-02 2.66247126e-03
  1.48692809e-03 8.71066644e-04 8.72845016e-03 8.38760636e-04]
 [6.99616720e-08 9.17223186e-09 1.64794699e-06 8.03786904e-08
  2.18053037e-06 9.99941468e-01 7.56303038e-08 5.44569921e-05]
 [5.89247886e-03 7.63520412e-03 9.37586799e-02 5.19945771e-02
  8.25503349e-01 4.53601797e-06 1.52056422e-02 5.51487392e-06]]
[[9.97288465e-01 1.42893507e-04 8.14986823e-04 1.69076899e-03
  7.38882818e-06 1.40569318e-05 1.64918470e-06 3.98638294e-05]
 [3.48926149e-02 1.01211073e-03 1.69189051e-01 7.20996857e-01
  7.12797120e-02 1.15040539e-05 2.61540222e-03 2.78705966e-06]
 [3.20905360e-06 1.92337666e-05 1.31899833e-05 1.16909996e-06
  3.17148512e-08 2.17394531e-03 5.72900319e-07 9.97788668e-01]
 [1.16486177e-02 1.02946982e-02 4.56205830e-02 5.01548173e-03
  1.57041121e-02 9.09641862e-01 1.86452095e-03 2.10171202e-04]
 [1.48622696e-08 1.28451973e-06 8.06430922e-09 8.97065089e-09
  4.52402525e-11 1.32224659e-05 1.12432215e-08 9.99985456e-01]
 [5.27599826e-04 1.75761306e-06 1.05398381e-03 5.47228148e-03
  9.92776990e-01 8.82876120e-05 7.89595797e-05 1.98824992e-07]
 [9.99597371e-01 1.53539004e-05 3.10869626e-04 2.08896872e-05
  1.57902264e-07 4.18691816e-05 1.51222679e-08 1.35239488e-05]
 [2.29791141e-04 4.78850743e-05 1.73776112e-02 6.01113681e-03
  9.75797832e-01 4.40316626e-07 5.35434228e-04 3.16328546e-08]
 [9.97751415e-01 1.59307354e-04 1.15950860e-03 8.39175889e-04
  6.92871890e-06 6.66335109e-05 1.23719542e-06 1.58716775e-05]
 [1.43061476e-02 1.29522965e-03 6.56252503e-02 1.38356864e-01
  7.50371456e-01 4.96779430e-05 2.99923830e-02 2.98999771e-06]
 [9.97857034e-01 1.65461861e-05 1.62085518e-03 1.51373592e-04
  4.85429018e-06 8.99739462e-06 2.64760136e-04 7.55253204e-05]
 [9.77862906e-03 5.42423164e-04 4.02351692e-02 7.71719590e-02
  8.45112085e-01 2.96226281e-05 2.71267463e-02 3.36094217e-06]
 [3.30482617e-05 2.34180720e-06 1.31788620e-04 6.32524097e-05
  1.13316521e-04 9.99581039e-01 1.15209104e-05 6.36667901e-05]
 [5.53963929e-02 1.01174766e-04 1.01537106e-03 1.98963787e-02
  1.88528821e-01 1.80197443e-04 7.34876096e-01 5.49494325e-06]
 [1.21138827e-03 1.40276842e-03 3.63638857e-03 1.25176355e-03
  7.28477258e-04 4.01537636e-06 9.91752803e-01 1.24007211e-05]
 [1.06721000e-05 1.46530283e-06 2.94845468e-05 2.32378829e-06
  2.97100587e-06 9.70939338e-01 1.17873515e-06 2.90125348e-02]
 [1.36829883e-01 5.92676457e-04 3.06331903e-01 1.36094272e-01
  4.16696668e-01 1.40669916e-04 3.31085152e-03 3.11962026e-06]
 [6.81405663e-02 8.81694853e-01 3.55769657e-02 2.66247126e-03
  1.48692809e-03 8.71066644e-04 8.72845016e-03 8.38760636e-04]
 [6.99616720e-08 9.17223186e-09 1.64794699e-06 8.03786904e-08
  2.18053037e-06 9.99941468e-01 7.56303038e-08 5.44569921e-05]
 [5.89247886e-03 7.63520412e-03 9.37586799e-02 5.19945771e-02
  8.25503349e-01 4.53601797e-06 1.52056422e-02 5.51487392e-06]]
[[1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]]
Best Validation Accuracy: 0.8516676347616329
Current Validation Accuracy: 0.8519496223804381
Current Validation Loss: 0.00020858934322260772
Saving best model based on accuracy
Saving last model
