Running "module reset". Resetting modules to system default. The following $MODULEPATH directories have been removed: None
A conda environment has been detected CONDA_PREFIX=
/sw/external/python/anaconda3 
anaconda3_gpu is loaded. Consider running conda deactivate and reloading it.

Currently Loaded Modules:
  1) cue-login-env/1.0   4) gcc/11.2.0    7) openmpi/4.1.2
  2) default             5) cuda/11.6.1   8) cudnn/8.4.1.50
  3) modtree/gpu         6) ucx/1.11.2    9) anaconda3_gpu/4.13.0

 

/u/avroy/UQ_XAI_Studies/models/PFIN_UQ/model/jobsub
total 508K
-rw-rw----+ 1 avroy delta_bbhj  925 Mar 31 16:58 jobsubmitter_dummy.py
-rw-rw----+ 1 avroy delta_bbhj 5.2K May 27 21:16 jobsubmitter_jetclass_1gpu.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 27 21:04 jobsubmitter_jetclass_1gpu.py~
-rw-rw----+ 1 avroy delta_bbhj  743 May 19 01:04 jobsubmitter_jetclass.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 18 13:59 jobsubmitter.py
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 19 13:52 UQPFIN-jetclass-run-jetclass20M_0_baseline.slurm
-rw-------+ 1 avroy delta_bbhj  973 May 19 00:59 UQPFIN-jetclass-run.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_9.slurm
-rw-------+ 1 avroy delta_bbhj  969 May 15 09:44 UQPFIN-run.slurm
/projects/bbhj/avroy/UQ_XAI_Studies/models/PFIN_UQ/model
total 204K
drwxr-s---+ 2 avroy delta_bbhj  16K May 28 16:58 jobouts
drwxr-s---+ 2 avroy delta_bbhj  16K May 27 21:18 jobsub
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 18 21:37 PFINDataset.py
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 15 14:46 PFINDataset.py~
drwxrws---+ 2 avroy delta_bbhj 4.0K May 18 21:38 __pycache__
drwxrws---+ 2 avroy delta_bbhj  20K May 28 16:33 trained_model_dicts
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:09 trained_model_dicts_old
drwxrws---+ 2 avroy delta_bbhj  36K May 28 16:57 trained_models
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:10 trained_models_old
-rw-rw----+ 1 avroy delta_bbhj  23K May 18 15:52 train_mod.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 27 21:06 train.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 18 13:50 train.py~
-rw-rw----+ 1 avroy delta_bbhj  13K May  5 09:36 UQPFIN.py
job is starting on gpua012.delta.ncsa.illinois.edu
# conda environments:
#
base                     /sw/external/python/anaconda3
toptagger_env         *  /u/avroy/.conda/envs/toptagger_env

/sw/external/python/anaconda3_gpu/bin/python
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
UQPFIN                                   [1, 6]                    --
├─Sequential: 1-1                        [60, 64]                  --
│    └─Sequential: 2-1                   [60, 100]                 --
│    │    └─Linear: 3-1                  [60, 100]                 1,200
│    │    └─ReLU: 3-2                    [60, 100]                 --
│    └─Sequential: 2-2                   [60, 100]                 --
│    │    └─Linear: 3-3                  [60, 100]                 10,100
│    │    └─ReLU: 3-4                    [60, 100]                 --
│    └─Sequential: 2-3                   [60, 64]                  --
│    │    └─Linear: 3-5                  [60, 64]                  6,464
│    │    └─ReLU: 3-6                    [60, 64]                  --
├─Sequential: 1-2                        [1770, 64]                --
│    └─Sequential: 2-4                   [1770, 128]               --
│    │    └─Linear: 3-7                  [1770, 128]               640
│    │    └─ReLU: 3-8                    [1770, 128]               --
│    └─Sequential: 2-5                   [1770, 128]               --
│    │    └─Linear: 3-9                  [1770, 128]               16,512
│    │    └─ReLU: 3-10                   [1770, 128]               --
│    └─Sequential: 2-6                   [1770, 64]                --
│    │    └─Linear: 3-11                 [1770, 64]                8,256
│    │    └─ReLU: 3-12                   [1770, 64]                --
├─Sequential: 1-3                        [60, 64]                  --
│    └─Sequential: 2-7                   [60, 128]                 --
│    │    └─Linear: 3-13                 [60, 128]                 9,728
│    │    └─ReLU: 3-14                   [60, 128]                 --
│    └─Sequential: 2-8                   [60, 128]                 --
│    │    └─Linear: 3-15                 [60, 128]                 16,512
│    │    └─ReLU: 3-16                   [60, 128]                 --
│    └─Sequential: 2-9                   [60, 64]                  --
│    │    └─Linear: 3-17                 [60, 64]                  8,256
│    │    └─ReLU: 3-18                   [60, 64]                  --
├─Sequential: 1-4                        [1, 6]                    --
│    └─Sequential: 2-10                  [1, 64]                   --
│    │    └─Linear: 3-19                 [1, 64]                   4,160
│    │    └─ReLU: 3-20                   [1, 64]                   --
│    └─Sequential: 2-11                  [1, 100]                  --
│    │    └─Linear: 3-21                 [1, 100]                  6,500
│    │    └─ReLU: 3-22                   [1, 100]                  --
│    └─Sequential: 2-12                  [1, 100]                  --
│    │    └─Linear: 3-23                 [1, 100]                  10,100
│    │    └─ReLU: 3-24                   [1, 100]                  --
│    └─Linear: 2-13                      [1, 6]                    606
│    └─Softmax: 2-14                     [1, 6]                    --
==========================================================================================
Total params: 99,034
Trainable params: 99,034
Non-trainable params: 0
Total mult-adds (M): 48.13
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 4.81
Params size (MB): 0.40
Estimated Total Size (MB): 5.21
==========================================================================================
data type:  jetclass
m_logic, pt_logic, eta_logic:  AND AND AND
m1, m2, pt1, pt2, eta1, eta2:  0.0 10000.0 0.0 10000.0 -6.0 6.0
skip labels:  [6, 7, 8, 9]
classes:  6
Epoch 0
Best Validation Accuracy: 0
Current Validation Accuracy: 0.7390349505869287
Current Validation Loss: 0.0004563950108189351
Saving best model based on accuracy
Epoch 1
Best Validation Accuracy: 0.7390349505869287
Current Validation Accuracy: 0.7533265131372152
Current Validation Loss: 0.0004354012878299786
Saving best model based on accuracy
Epoch 2
Best Validation Accuracy: 0.7533265131372152
Current Validation Accuracy: 0.7576529187187703
Current Validation Loss: 0.000429055237364579
Saving best model based on accuracy
Epoch 3
Best Validation Accuracy: 0.7576529187187703
Current Validation Accuracy: 0.757229366197007
Current Validation Loss: 0.00042966193317314733
Epoch 4
Best Validation Accuracy: 0.7576529187187703
Current Validation Accuracy: 0.7586501014274887
Current Validation Loss: 0.000426999311887516
Saving best model based on accuracy
Epoch 5
Best Validation Accuracy: 0.7586501014274887
Current Validation Accuracy: 0.7364302693310455
Current Validation Loss: 0.00045590448835569196
Epoch 6
Best Validation Accuracy: 0.7586501014274887
Current Validation Accuracy: 0.7686477752236782
Current Validation Loss: 0.0004126690130174789
Saving best model based on accuracy
Epoch 7
Best Validation Accuracy: 0.7686477752236782
Current Validation Accuracy: 0.7853939413646562
Current Validation Loss: 0.0003870474954857692
Saving best model based on accuracy
Epoch 8
Best Validation Accuracy: 0.7853939413646562
Current Validation Accuracy: 0.7896336354063228
Current Validation Loss: 0.0003817567952408598
Saving best model based on accuracy
Epoch 9
Best Validation Accuracy: 0.7896336354063228
Current Validation Accuracy: 0.8069892836209405
Current Validation Loss: 0.0003501478302026246
Saving best model based on accuracy
Epoch 10
Best Validation Accuracy: 0.8069892836209405
Current Validation Accuracy: 0.7904207093837727
Current Validation Loss: 0.00037974631977209875
Epoch 11
Best Validation Accuracy: 0.8069892836209405
Current Validation Accuracy: 0.8303263605582556
Current Validation Loss: 0.0003099092839515855
Saving best model based on accuracy
Epoch 12
Best Validation Accuracy: 0.8303263605582556
Current Validation Accuracy: 0.809406367795334
Current Validation Loss: 0.00034604756538372214
Epoch 13
Best Validation Accuracy: 0.8303263605582556
Current Validation Accuracy: 0.8171128559029298
Current Validation Loss: 0.00033238095801302726
Epoch 14
Best Validation Accuracy: 0.8303263605582556
Current Validation Accuracy: 0.829773574491466
Current Validation Loss: 0.00031096637980273313
Epoch 15
Best Validation Accuracy: 0.8303263605582556
Current Validation Accuracy: 0.8315053039948174
Current Validation Loss: 0.00030819425622312765
Saving best model based on accuracy
Epoch 16
Best Validation Accuracy: 0.8315053039948174
Current Validation Accuracy: 0.8320189031156957
Current Validation Loss: 0.0003076136767160081
Saving best model based on accuracy
Epoch 17
Best Validation Accuracy: 0.8320189031156957
Current Validation Accuracy: 0.8297193797790356
Current Validation Loss: 0.0003111474503943083
Epoch 18
Best Validation Accuracy: 0.8320189031156957
Current Validation Accuracy: 0.8295451229344519
Current Validation Loss: 0.0003111911244820852
Epoch 19
Best Validation Accuracy: 0.8320189031156957
Current Validation Accuracy: 0.8310450658215627
Current Validation Loss: 0.00030886814944426627
Epoch 20
Best Validation Accuracy: 0.8320189031156957
Current Validation Accuracy: 0.8184368744158436
Current Validation Loss: 0.0003309088935116578
Epoch 21
Best Validation Accuracy: 0.8320189031156957
Current Validation Accuracy: 0.8264993800958663
Current Validation Loss: 0.00031661723494601983
Epoch 22
Best Validation Accuracy: 0.8320189031156957
Current Validation Accuracy: 0.8266944810606155
Current Validation Loss: 0.0003161609806100424
Epoch 23
Best Validation Accuracy: 0.8320189031156957
Current Validation Accuracy: 0.8286221452935227
Current Validation Loss: 0.0003125222254315524
Epoch 24
Best Validation Accuracy: 0.8320189031156957
Current Validation Accuracy: 0.8287597164866152
Current Validation Loss: 0.0003126656503892748
Epoch 25
Best Validation Accuracy: 0.8320189031156957
Current Validation Accuracy: 0.8323882609250287
Current Validation Loss: 0.00030559282832185174
Saving best model based on accuracy
Epoch 26
Best Validation Accuracy: 0.8323882609250287
Current Validation Accuracy: 0.8327034240219313
Current Validation Loss: 0.00030482805063903706
Saving best model based on accuracy
Epoch 27
Best Validation Accuracy: 0.8327034240219313
Current Validation Accuracy: 0.8366863185031587
Current Validation Loss: 0.0002980345949019364
Saving best model based on accuracy
Epoch 28
Best Validation Accuracy: 0.8366863185031587
Current Validation Accuracy: 0.8350621446598615
Current Validation Loss: 0.00030069634431646784
Epoch 29
[[9.94997501e-01 1.29987020e-04 1.44042401e-03 3.36492900e-03
  2.24547439e-05 4.47400562e-05]
 [3.13092358e-02 1.12417247e-03 1.62136227e-01 7.60983706e-01
  4.44399342e-02 6.65406924e-06]
 [1.35254702e-02 2.09118170e-03 3.44074517e-02 1.13942218e-03
  3.37462011e-03 9.45461810e-01]
 [1.67999446e-04 6.00263365e-06 2.24111881e-03 4.24845703e-03
  9.93332684e-01 3.67851612e-06]
 [9.99681592e-01 1.44855812e-05 2.61629350e-04 1.64894354e-05
  1.93301474e-07 2.56165658e-05]
 [2.32091130e-04 3.86144056e-05 2.43306048e-02 1.06071662e-02
  9.64791000e-01 5.46249112e-07]
 [9.98195827e-01 1.45241182e-04 1.16933126e-03 4.51852538e-04
  1.95113739e-06 3.58299549e-05]
 [1.26829157e-02 5.89371135e-04 9.14822072e-02 1.58979684e-01
  7.36254334e-01 1.15473513e-05]
 [9.98939812e-01 5.57963494e-06 9.50779067e-04 7.86152304e-05
  1.70977239e-06 2.35651660e-05]
 [4.71334578e-03 1.29767030e-03 1.01360619e-01 7.00131208e-02
  8.22561681e-01 5.35977888e-05]
 [3.82377766e-06 7.52818721e-07 7.86152941e-06 4.27585337e-06
  1.65702604e-05 9.99966741e-01]
 [1.09423965e-01 6.65823391e-05 4.39752219e-03 9.34929699e-02
  7.92292714e-01 3.26250534e-04]
 [4.61381063e-07 2.25976279e-10 5.20665537e-08 1.23386865e-08
  1.88453640e-07 9.99999285e-01]
 [1.04784988e-01 2.26795510e-03 6.70256436e-01 1.05273284e-01
  1.17359504e-01 5.78222061e-05]
 [9.39171910e-02 9.03484881e-01 2.25208187e-03 3.21436557e-04
  2.21491900e-05 2.25565645e-06]
 [1.50181151e-07 1.68999478e-07 3.38330165e-06 1.38406932e-07
  7.49135052e-06 9.99988794e-01]
 [6.55776355e-03 1.60214398e-02 5.46557307e-02 4.26521078e-02
  8.80099654e-01 1.33866233e-05]
 [1.07856110e-01 2.70843739e-04 1.08009679e-02 3.09280396e-01
  5.71755886e-01 3.58324214e-05]
 [3.07409838e-02 1.88462809e-03 2.52109226e-02 2.36749724e-01
  7.05384493e-01 2.92670375e-05]
 [6.76666060e-03 3.43682654e-02 9.56979871e-01 1.85751100e-03
  2.24909345e-05 5.16985665e-06]]
[[9.94997501e-01 1.29987020e-04 1.44042401e-03 3.36492900e-03
  2.24547439e-05 4.47400562e-05]
 [3.13092358e-02 1.12417247e-03 1.62136227e-01 7.60983706e-01
  4.44399342e-02 6.65406924e-06]
 [1.35254702e-02 2.09118170e-03 3.44074517e-02 1.13942218e-03
  3.37462011e-03 9.45461810e-01]
 [1.67999446e-04 6.00263365e-06 2.24111881e-03 4.24845703e-03
  9.93332684e-01 3.67851612e-06]
 [9.99681592e-01 1.44855812e-05 2.61629350e-04 1.64894354e-05
  1.93301474e-07 2.56165658e-05]
 [2.32091130e-04 3.86144056e-05 2.43306048e-02 1.06071662e-02
  9.64791000e-01 5.46249112e-07]
 [9.98195827e-01 1.45241182e-04 1.16933126e-03 4.51852538e-04
  1.95113739e-06 3.58299549e-05]
 [1.26829157e-02 5.89371135e-04 9.14822072e-02 1.58979684e-01
  7.36254334e-01 1.15473513e-05]
 [9.98939812e-01 5.57963494e-06 9.50779067e-04 7.86152304e-05
  1.70977239e-06 2.35651660e-05]
 [4.71334578e-03 1.29767030e-03 1.01360619e-01 7.00131208e-02
  8.22561681e-01 5.35977888e-05]
 [3.82377766e-06 7.52818721e-07 7.86152941e-06 4.27585337e-06
  1.65702604e-05 9.99966741e-01]
 [1.09423965e-01 6.65823391e-05 4.39752219e-03 9.34929699e-02
  7.92292714e-01 3.26250534e-04]
 [4.61381063e-07 2.25976279e-10 5.20665537e-08 1.23386865e-08
  1.88453640e-07 9.99999285e-01]
 [1.04784988e-01 2.26795510e-03 6.70256436e-01 1.05273284e-01
  1.17359504e-01 5.78222061e-05]
 [9.39171910e-02 9.03484881e-01 2.25208187e-03 3.21436557e-04
  2.21491900e-05 2.25565645e-06]
 [1.50181151e-07 1.68999478e-07 3.38330165e-06 1.38406932e-07
  7.49135052e-06 9.99988794e-01]
 [6.55776355e-03 1.60214398e-02 5.46557307e-02 4.26521078e-02
  8.80099654e-01 1.33866233e-05]
 [1.07856110e-01 2.70843739e-04 1.08009679e-02 3.09280396e-01
  5.71755886e-01 3.58324214e-05]
 [3.07409838e-02 1.88462809e-03 2.52109226e-02 2.36749724e-01
  7.05384493e-01 2.92670375e-05]
 [6.76666060e-03 3.43682654e-02 9.56979871e-01 1.85751100e-03
  2.24909345e-05 5.16985665e-06]]
[[1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 0.]]
Best Validation Accuracy: 0.8366863185031587
Current Validation Accuracy: 0.8364762097718903
Current Validation Loss: 0.000298814214942851
Saving last model
