Running "module reset". Resetting modules to system default. The following $MODULEPATH directories have been removed: None
A conda environment has been detected CONDA_PREFIX=
/sw/external/python/anaconda3 
anaconda3_gpu is loaded. Consider running conda deactivate and reloading it.

Currently Loaded Modules:
  1) cue-login-env/1.0   4) gcc/11.2.0    7) openmpi/4.1.2
  2) default             5) cuda/11.6.1   8) cudnn/8.4.1.50
  3) modtree/gpu         6) ucx/1.11.2    9) anaconda3_gpu/4.13.0

 

/u/avroy/UQ_XAI_Studies/models/PFIN_UQ/model/jobsub
total 508K
-rw-rw----+ 1 avroy delta_bbhj  925 Mar 31 16:58 jobsubmitter_dummy.py
-rw-rw----+ 1 avroy delta_bbhj 5.2K May 27 21:16 jobsubmitter_jetclass_1gpu.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 27 21:04 jobsubmitter_jetclass_1gpu.py~
-rw-rw----+ 1 avroy delta_bbhj  743 May 19 01:04 jobsubmitter_jetclass.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 18 13:59 jobsubmitter.py
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 19 13:52 UQPFIN-jetclass-run-jetclass20M_0_baseline.slurm
-rw-------+ 1 avroy delta_bbhj  973 May 19 00:59 UQPFIN-jetclass-run.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_9.slurm
-rw-------+ 1 avroy delta_bbhj  969 May 15 09:44 UQPFIN-run.slurm
/projects/bbhj/avroy/UQ_XAI_Studies/models/PFIN_UQ/model
total 200K
drwxr-s---+ 2 avroy delta_bbhj  12K May 28 10:53 jobouts
drwxr-s---+ 2 avroy delta_bbhj  16K May 27 21:18 jobsub
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 18 21:37 PFINDataset.py
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 15 14:46 PFINDataset.py~
drwxrws---+ 2 avroy delta_bbhj 4.0K May 18 21:38 __pycache__
drwxrws---+ 2 avroy delta_bbhj  20K May 28 10:25 trained_model_dicts
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:09 trained_model_dicts_old
drwxrws---+ 2 avroy delta_bbhj  36K May 28 10:53 trained_models
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:10 trained_models_old
-rw-rw----+ 1 avroy delta_bbhj  23K May 18 15:52 train_mod.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 27 21:06 train.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 18 13:50 train.py~
-rw-rw----+ 1 avroy delta_bbhj  13K May  5 09:36 UQPFIN.py
job is starting on gpua080.delta.ncsa.illinois.edu
# conda environments:
#
base                     /sw/external/python/anaconda3
toptagger_env         *  /u/avroy/.conda/envs/toptagger_env

/sw/external/python/anaconda3_gpu/bin/python
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
UQPFIN                                   [1, 8]                    --
├─Sequential: 1-1                        [60, 64]                  --
│    └─Sequential: 2-1                   [60, 100]                 --
│    │    └─Linear: 3-1                  [60, 100]                 1,200
│    │    └─ReLU: 3-2                    [60, 100]                 --
│    │    └─Dropout: 3-3                 [60, 100]                 --
│    └─Sequential: 2-2                   [60, 100]                 --
│    │    └─Linear: 3-4                  [60, 100]                 10,100
│    │    └─ReLU: 3-5                    [60, 100]                 --
│    │    └─Dropout: 3-6                 [60, 100]                 --
│    └─Sequential: 2-3                   [60, 64]                  --
│    │    └─Linear: 3-7                  [60, 64]                  6,464
│    │    └─ReLU: 3-8                    [60, 64]                  --
│    │    └─Identity: 3-9                [60, 64]                  --
├─Sequential: 1-2                        [1770, 64]                --
│    └─Sequential: 2-4                   [1770, 128]               --
│    │    └─Linear: 3-10                 [1770, 128]               640
│    │    └─ReLU: 3-11                   [1770, 128]               --
│    │    └─Dropout: 3-12                [1770, 128]               --
│    └─Sequential: 2-5                   [1770, 128]               --
│    │    └─Linear: 3-13                 [1770, 128]               16,512
│    │    └─ReLU: 3-14                   [1770, 128]               --
│    │    └─Dropout: 3-15                [1770, 128]               --
│    └─Sequential: 2-6                   [1770, 64]                --
│    │    └─Linear: 3-16                 [1770, 64]                8,256
│    │    └─ReLU: 3-17                   [1770, 64]                --
├─Sequential: 1-3                        [60, 64]                  --
│    └─Sequential: 2-7                   [60, 128]                 --
│    │    └─Linear: 3-18                 [60, 128]                 9,728
│    │    └─ReLU: 3-19                   [60, 128]                 --
│    │    └─Dropout: 3-20                [60, 128]                 --
│    └─Sequential: 2-8                   [60, 128]                 --
│    │    └─Linear: 3-21                 [60, 128]                 16,512
│    │    └─ReLU: 3-22                   [60, 128]                 --
│    │    └─Dropout: 3-23                [60, 128]                 --
│    └─Sequential: 2-9                   [60, 64]                  --
│    │    └─Linear: 3-24                 [60, 64]                  8,256
│    │    └─ReLU: 3-25                   [60, 64]                  --
├─Sequential: 1-4                        [1, 8]                    --
│    └─Sequential: 2-10                  [1, 64]                   --
│    │    └─Linear: 3-26                 [1, 64]                   4,160
│    │    └─ReLU: 3-27                   [1, 64]                   --
│    │    └─Dropout: 3-28                [1, 64]                   --
│    └─Sequential: 2-11                  [1, 100]                  --
│    │    └─Linear: 3-29                 [1, 100]                  6,500
│    │    └─ReLU: 3-30                   [1, 100]                  --
│    │    └─Dropout: 3-31                [1, 100]                  --
│    └─Sequential: 2-12                  [1, 100]                  --
│    │    └─Linear: 3-32                 [1, 100]                  10,100
│    │    └─ReLU: 3-33                   [1, 100]                  --
│    │    └─Dropout: 3-34                [1, 100]                  --
│    └─Linear: 2-13                      [1, 8]                    808
│    └─Softmax: 2-14                     [1, 8]                    --
==========================================================================================
Total params: 99,236
Trainable params: 99,236
Non-trainable params: 0
Total mult-adds (M): 48.13
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 4.81
Params size (MB): 0.40
Estimated Total Size (MB): 5.21
==========================================================================================
data type:  jetclass
m_logic, pt_logic, eta_logic:  AND AND AND
m1, m2, pt1, pt2, eta1, eta2:  0.0 10000.0 0.0 10000.0 -6.0 6.0
skip labels:  [6, 7]
classes:  8
Epoch 0
Best Validation Accuracy: 0
Current Validation Accuracy: 0.7503809333852708
Current Validation Loss: 0.00034622418158369465
Saving best model based on accuracy
Epoch 1
Best Validation Accuracy: 0.7503809333852708
Current Validation Accuracy: 0.7589487301491032
Current Validation Loss: 0.00033260634874057585
Saving best model based on accuracy
Epoch 2
Best Validation Accuracy: 0.7589487301491032
Current Validation Accuracy: 0.7624807657558237
Current Validation Loss: 0.0003287208498727005
Saving best model based on accuracy
Epoch 3
Best Validation Accuracy: 0.7624807657558237
Current Validation Accuracy: 0.7576400825079516
Current Validation Loss: 0.0003355551823844793
Epoch 4
Best Validation Accuracy: 0.7624807657558237
Current Validation Accuracy: 0.7635143035249703
Current Validation Loss: 0.0003263387481335909
Saving best model based on accuracy
Epoch 5
Best Validation Accuracy: 0.7635143035249703
Current Validation Accuracy: 0.762543290726734
Current Validation Loss: 0.0003294059855238333
Epoch 6
Best Validation Accuracy: 0.7635143035249703
Current Validation Accuracy: 0.7653700446615868
Current Validation Loss: 0.0003249077965636871
Saving best model based on accuracy
Epoch 7
Best Validation Accuracy: 0.7653700446615868
Current Validation Accuracy: 0.7628790498205221
Current Validation Loss: 0.0003278712214032846
Epoch 8
Best Validation Accuracy: 0.7653700446615868
Current Validation Accuracy: 0.7626133186941535
Current Validation Loss: 0.0003289909262441254
Epoch 9
Best Validation Accuracy: 0.7653700446615868
Current Validation Accuracy: 0.787420100902798
Current Validation Loss: 0.0002998008319399478
Saving best model based on accuracy
Epoch 10
Best Validation Accuracy: 0.787420100902798
Current Validation Accuracy: 0.801354415919858
Current Validation Loss: 0.00028212162774787064
Saving best model based on accuracy
Epoch 11
Best Validation Accuracy: 0.801354415919858
Current Validation Accuracy: 0.8081896457397674
Current Validation Loss: 0.00027175249762737897
Saving best model based on accuracy
Epoch 12
Best Validation Accuracy: 0.8081896457397674
Current Validation Accuracy: 0.8061225702014743
Current Validation Loss: 0.000275933049961004
Epoch 13
Best Validation Accuracy: 0.8081896457397674
Current Validation Accuracy: 0.8129121567926191
Current Validation Loss: 0.0002660429815501777
Saving best model based on accuracy
Epoch 14
Best Validation Accuracy: 0.8129121567926191
Current Validation Accuracy: 0.8112852570495341
Current Validation Loss: 0.0002668530972772111
Epoch 15
Best Validation Accuracy: 0.8129121567926191
Current Validation Accuracy: 0.8281338609607212
Current Validation Loss: 0.00024590330060617684
Saving best model based on accuracy
Epoch 16
Best Validation Accuracy: 0.8281338609607212
Current Validation Accuracy: 0.8266970371292035
Current Validation Loss: 0.00024626781515188544
Epoch 17
Best Validation Accuracy: 0.8281338609607212
Current Validation Accuracy: 0.8330995941504138
Current Validation Loss: 0.0002377257168133605
Saving best model based on accuracy
Epoch 18
Best Validation Accuracy: 0.8330995941504138
Current Validation Accuracy: 0.8308974646749545
Current Validation Loss: 0.00024175714552671383
Epoch 19
Best Validation Accuracy: 0.8330995941504138
Current Validation Accuracy: 0.8261236831459564
Current Validation Loss: 0.0002464097871770384
Epoch 20
Best Validation Accuracy: 0.8330995941504138
Current Validation Accuracy: 0.8335216377040581
Current Validation Loss: 0.0002372257480430014
Saving best model based on accuracy
Epoch 21
Best Validation Accuracy: 0.8335216377040581
Current Validation Accuracy: 0.8302515817254515
Current Validation Loss: 0.00024011726122205061
Epoch 22
Best Validation Accuracy: 0.8335216377040581
Current Validation Accuracy: 0.8344488830226572
Current Validation Loss: 0.00023606973940256104
Saving best model based on accuracy
Epoch 23
Best Validation Accuracy: 0.8344488830226572
Current Validation Accuracy: 0.8310881658362308
Current Validation Loss: 0.00024197202426232275
Epoch 24
Best Validation Accuracy: 0.8344488830226572
Current Validation Accuracy: 0.833990574985885
Current Validation Loss: 0.00023580580133376555
Epoch 25
Best Validation Accuracy: 0.8344488830226572
Current Validation Accuracy: 0.8326469133610236
Current Validation Loss: 0.00023849831010279963
Epoch 26
Best Validation Accuracy: 0.8344488830226572
Current Validation Accuracy: 0.8319522609342106
Current Validation Loss: 0.00023990533802690833
Epoch 27
Best Validation Accuracy: 0.8344488830226572
Current Validation Accuracy: 0.8286234314829485
Current Validation Loss: 0.00024422894339374434
Epoch 28
Best Validation Accuracy: 0.8344488830226572
Current Validation Accuracy: 0.8341074966814872
Current Validation Loss: 0.0002364564302566125
Epoch 29
[[9.66760635e-01 1.95827452e-03 2.00749170e-02 1.01808542e-02
  2.16247412e-04 6.92161033e-04 4.75978686e-06 1.12215072e-04]
 [3.91529500e-02 4.26621642e-03 1.36614591e-01 5.81180096e-01
  2.36943528e-01 7.96289532e-05 1.76158908e-03 1.38571329e-06]
 [3.66575441e-05 2.76755425e-04 1.45950195e-04 1.02296674e-07
  6.98008273e-09 9.43018496e-03 5.65450421e-07 9.90109742e-01]
 [3.21562439e-02 4.22110856e-02 1.53860956e-01 1.09948497e-02
  2.65317131e-02 7.25775421e-01 2.62836996e-03 5.84133714e-03]
 [7.61580532e-06 9.41296385e-05 4.15539262e-06 2.02466595e-07
  4.08814177e-10 7.02140504e-04 8.31868363e-07 9.99190867e-01]
 [1.20704051e-03 1.56825809e-05 5.02604572e-03 1.10708764e-02
  9.82095480e-01 1.33099129e-05 5.71535784e-04 8.66208438e-09]
 [9.97945726e-01 7.44292774e-05 1.68417802e-03 1.33916343e-04
  2.12172449e-06 1.35003487e-04 2.47309710e-08 2.45878164e-05]
 [1.81860127e-03 2.81437137e-03 1.13113500e-01 3.26797292e-02
  8.47314954e-01 6.17762926e-05 2.19598156e-03 9.76188517e-07]
 [9.92782950e-01 3.60547623e-04 5.70251094e-03 7.18585448e-04
  1.30441531e-05 3.56376666e-04 2.33527231e-07 6.57627825e-05]
 [1.21554928e-02 3.97747429e-03 9.27931145e-02 9.73688066e-02
  7.81375170e-01 7.35513968e-05 1.22551881e-02 1.18111893e-06]
 [9.74355102e-01 8.63790701e-05 1.45620750e-02 5.67843497e-04
  2.45724232e-06 4.87420766e-05 1.02452552e-02 1.32196452e-04]
 [1.52077768e-02 7.56221730e-03 1.15055442e-01 8.63852650e-02
  7.37505496e-01 1.38155985e-04 3.81417833e-02 3.82493636e-06]
 [8.59272841e-05 3.73064431e-05 7.78677000e-04 3.16485239e-05
  1.57735325e-04 9.98321831e-01 2.07275116e-06 5.84838504e-04]
 [1.87903978e-02 8.23460141e-05 8.43716692e-03 6.07485548e-02
  8.91394913e-01 1.59394513e-05 2.05305889e-02 5.70161092e-08]
 [1.66347949e-03 2.50988733e-03 2.64753075e-03 9.59532103e-04
  5.77568170e-03 1.79082217e-05 9.86418784e-01 7.27767974e-06]
 [1.11425601e-04 3.02120061e-05 8.74072648e-05 6.47758861e-06
  2.91178785e-05 9.78131115e-01 5.09381323e-07 2.16037761e-02]
 [9.53383520e-02 1.00420378e-02 5.63806057e-01 1.41078353e-01
  1.84243873e-01 1.32922828e-03 4.14899457e-03 1.30822991e-05]
 [8.51178020e-02 8.67356241e-01 4.00316119e-02 1.80072163e-03
  3.73845796e-05 1.44668928e-04 3.54570779e-03 1.96596212e-03]
 [4.29516285e-06 1.55800853e-06 3.71534807e-05 8.61894819e-07
  2.64659593e-05 9.99429524e-01 1.76020720e-07 4.99874121e-04]
 [1.51510304e-02 1.52859353e-02 7.03406259e-02 9.30283070e-02
  7.86502957e-01 1.20751378e-04 1.95624847e-02 7.89275146e-06]]
[[9.66760635e-01 1.95827452e-03 2.00749170e-02 1.01808542e-02
  2.16247412e-04 6.92161033e-04 4.75978686e-06 1.12215072e-04]
 [3.91529500e-02 4.26621642e-03 1.36614591e-01 5.81180096e-01
  2.36943528e-01 7.96289532e-05 1.76158908e-03 1.38571329e-06]
 [3.66575441e-05 2.76755425e-04 1.45950195e-04 1.02296674e-07
  6.98008273e-09 9.43018496e-03 5.65450421e-07 9.90109742e-01]
 [3.21562439e-02 4.22110856e-02 1.53860956e-01 1.09948497e-02
  2.65317131e-02 7.25775421e-01 2.62836996e-03 5.84133714e-03]
 [7.61580532e-06 9.41296385e-05 4.15539262e-06 2.02466595e-07
  4.08814177e-10 7.02140504e-04 8.31868363e-07 9.99190867e-01]
 [1.20704051e-03 1.56825809e-05 5.02604572e-03 1.10708764e-02
  9.82095480e-01 1.33099129e-05 5.71535784e-04 8.66208438e-09]
 [9.97945726e-01 7.44292774e-05 1.68417802e-03 1.33916343e-04
  2.12172449e-06 1.35003487e-04 2.47309710e-08 2.45878164e-05]
 [1.81860127e-03 2.81437137e-03 1.13113500e-01 3.26797292e-02
  8.47314954e-01 6.17762926e-05 2.19598156e-03 9.76188517e-07]
 [9.92782950e-01 3.60547623e-04 5.70251094e-03 7.18585448e-04
  1.30441531e-05 3.56376666e-04 2.33527231e-07 6.57627825e-05]
 [1.21554928e-02 3.97747429e-03 9.27931145e-02 9.73688066e-02
  7.81375170e-01 7.35513968e-05 1.22551881e-02 1.18111893e-06]
 [9.74355102e-01 8.63790701e-05 1.45620750e-02 5.67843497e-04
  2.45724232e-06 4.87420766e-05 1.02452552e-02 1.32196452e-04]
 [1.52077768e-02 7.56221730e-03 1.15055442e-01 8.63852650e-02
  7.37505496e-01 1.38155985e-04 3.81417833e-02 3.82493636e-06]
 [8.59272841e-05 3.73064431e-05 7.78677000e-04 3.16485239e-05
  1.57735325e-04 9.98321831e-01 2.07275116e-06 5.84838504e-04]
 [1.87903978e-02 8.23460141e-05 8.43716692e-03 6.07485548e-02
  8.91394913e-01 1.59394513e-05 2.05305889e-02 5.70161092e-08]
 [1.66347949e-03 2.50988733e-03 2.64753075e-03 9.59532103e-04
  5.77568170e-03 1.79082217e-05 9.86418784e-01 7.27767974e-06]
 [1.11425601e-04 3.02120061e-05 8.74072648e-05 6.47758861e-06
  2.91178785e-05 9.78131115e-01 5.09381323e-07 2.16037761e-02]
 [9.53383520e-02 1.00420378e-02 5.63806057e-01 1.41078353e-01
  1.84243873e-01 1.32922828e-03 4.14899457e-03 1.30822991e-05]
 [8.51178020e-02 8.67356241e-01 4.00316119e-02 1.80072163e-03
  3.73845796e-05 1.44668928e-04 3.54570779e-03 1.96596212e-03]
 [4.29516285e-06 1.55800853e-06 3.71534807e-05 8.61894819e-07
  2.64659593e-05 9.99429524e-01 1.76020720e-07 4.99874121e-04]
 [1.51510304e-02 1.52859353e-02 7.03406259e-02 9.30283070e-02
  7.86502957e-01 1.20751378e-04 1.95624847e-02 7.89275146e-06]]
[[1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]]
Best Validation Accuracy: 0.8344488830226572
Current Validation Accuracy: 0.8333009245567449
Current Validation Loss: 0.00023876547999679925
Saving last model
