Running "module reset". Resetting modules to system default. The following $MODULEPATH directories have been removed: None
A conda environment has been detected CONDA_PREFIX=
/sw/external/python/anaconda3 
anaconda3_gpu is loaded. Consider running conda deactivate and reloading it.

Currently Loaded Modules:
  1) cue-login-env/1.0   4) gcc/11.2.0    7) openmpi/4.1.2
  2) default             5) cuda/11.6.1   8) cudnn/8.4.1.50
  3) modtree/gpu         6) ucx/1.11.2    9) anaconda3_gpu/4.13.0

 

/u/avroy/UQ_XAI_Studies/models/PFIN_UQ/model/jobsub
total 508K
-rw-rw----+ 1 avroy delta_bbhj  925 Mar 31 16:58 jobsubmitter_dummy.py
-rw-rw----+ 1 avroy delta_bbhj 5.2K May 27 21:16 jobsubmitter_jetclass_1gpu.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 27 21:04 jobsubmitter_jetclass_1gpu.py~
-rw-rw----+ 1 avroy delta_bbhj  743 May 19 01:04 jobsubmitter_jetclass.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 18 13:59 jobsubmitter.py
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 19 13:52 UQPFIN-jetclass-run-jetclass20M_0_baseline.slurm
-rw-------+ 1 avroy delta_bbhj  973 May 19 00:59 UQPFIN-jetclass-run.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_9.slurm
-rw-------+ 1 avroy delta_bbhj  969 May 15 09:44 UQPFIN-run.slurm
/projects/bbhj/avroy/UQ_XAI_Studies/models/PFIN_UQ/model
total 200K
drwxr-s---+ 2 avroy delta_bbhj  12K May 28 09:28 jobouts
drwxr-s---+ 2 avroy delta_bbhj  16K May 27 21:18 jobsub
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 18 21:37 PFINDataset.py
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 15 14:46 PFINDataset.py~
drwxrws---+ 2 avroy delta_bbhj 4.0K May 18 21:38 __pycache__
drwxrws---+ 2 avroy delta_bbhj  20K May 28 09:28 trained_model_dicts
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:09 trained_model_dicts_old
drwxrws---+ 2 avroy delta_bbhj  36K May 28 09:28 trained_models
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:10 trained_models_old
-rw-rw----+ 1 avroy delta_bbhj  23K May 18 15:52 train_mod.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 27 21:06 train.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 18 13:50 train.py~
-rw-rw----+ 1 avroy delta_bbhj  13K May  5 09:36 UQPFIN.py
job is starting on gpua020.delta.ncsa.illinois.edu
# conda environments:
#
base                     /sw/external/python/anaconda3
toptagger_env         *  /u/avroy/.conda/envs/toptagger_env

/sw/external/python/anaconda3_gpu/bin/python
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
UQPFIN                                   [1, 8]                    --
├─Sequential: 1-1                        [60, 64]                  --
│    └─Sequential: 2-1                   [60, 100]                 --
│    │    └─Linear: 3-1                  [60, 100]                 1,200
│    │    └─ReLU: 3-2                    [60, 100]                 --
│    └─Sequential: 2-2                   [60, 100]                 --
│    │    └─Linear: 3-3                  [60, 100]                 10,100
│    │    └─ReLU: 3-4                    [60, 100]                 --
│    └─Sequential: 2-3                   [60, 64]                  --
│    │    └─Linear: 3-5                  [60, 64]                  6,464
│    │    └─ReLU: 3-6                    [60, 64]                  --
├─Sequential: 1-2                        [1770, 64]                --
│    └─Sequential: 2-4                   [1770, 128]               --
│    │    └─Linear: 3-7                  [1770, 128]               640
│    │    └─ReLU: 3-8                    [1770, 128]               --
│    └─Sequential: 2-5                   [1770, 128]               --
│    │    └─Linear: 3-9                  [1770, 128]               16,512
│    │    └─ReLU: 3-10                   [1770, 128]               --
│    └─Sequential: 2-6                   [1770, 64]                --
│    │    └─Linear: 3-11                 [1770, 64]                8,256
│    │    └─ReLU: 3-12                   [1770, 64]                --
├─Sequential: 1-3                        [60, 64]                  --
│    └─Sequential: 2-7                   [60, 128]                 --
│    │    └─Linear: 3-13                 [60, 128]                 9,728
│    │    └─ReLU: 3-14                   [60, 128]                 --
│    └─Sequential: 2-8                   [60, 128]                 --
│    │    └─Linear: 3-15                 [60, 128]                 16,512
│    │    └─ReLU: 3-16                   [60, 128]                 --
│    └─Sequential: 2-9                   [60, 64]                  --
│    │    └─Linear: 3-17                 [60, 64]                  8,256
│    │    └─ReLU: 3-18                   [60, 64]                  --
├─Sequential: 1-4                        [1, 8]                    --
│    └─Sequential: 2-10                  [1, 64]                   --
│    │    └─Linear: 3-19                 [1, 64]                   4,160
│    │    └─ReLU: 3-20                   [1, 64]                   --
│    └─Sequential: 2-11                  [1, 100]                  --
│    │    └─Linear: 3-21                 [1, 100]                  6,500
│    │    └─ReLU: 3-22                   [1, 100]                  --
│    └─Sequential: 2-12                  [1, 100]                  --
│    │    └─Linear: 3-23                 [1, 100]                  10,100
│    │    └─ReLU: 3-24                   [1, 100]                  --
│    └─Linear: 2-13                      [1, 8]                    808
│    └─Softmax: 2-14                     [1, 8]                    --
==========================================================================================
Total params: 99,236
Trainable params: 99,236
Non-trainable params: 0
Total mult-adds (M): 48.13
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 4.81
Params size (MB): 0.40
Estimated Total Size (MB): 5.21
==========================================================================================
data type:  jetclass
m_logic, pt_logic, eta_logic:  AND AND AND
m1, m2, pt1, pt2, eta1, eta2:  0.0 10000.0 0.0 10000.0 -6.0 6.0
skip labels:  [6, 7]
classes:  8
Epoch 0
Best Validation Accuracy: 0
Current Validation Accuracy: 0.7651249467756185
Current Validation Loss: 0.00032251717488676444
Saving best model based on accuracy
Epoch 1
Best Validation Accuracy: 0.7651249467756185
Current Validation Accuracy: 0.772095230532694
Current Validation Loss: 0.0003122638215622213
Saving best model based on accuracy
Epoch 2
Best Validation Accuracy: 0.772095230532694
Current Validation Accuracy: 0.7774736285303944
Current Validation Loss: 0.00030542517560226185
Saving best model based on accuracy
Epoch 3
Best Validation Accuracy: 0.7774736285303944
Current Validation Accuracy: 0.7796219865308708
Current Validation Loss: 0.0003024416653262326
Saving best model based on accuracy
Epoch 4
Best Validation Accuracy: 0.7796219865308708
Current Validation Accuracy: 0.7805511075985971
Current Validation Loss: 0.00030214458997124526
Saving best model based on accuracy
Epoch 5
Best Validation Accuracy: 0.7805511075985971
Current Validation Accuracy: 0.7863540501487781
Current Validation Loss: 0.00029516314592700445
Saving best model based on accuracy
Epoch 6
Best Validation Accuracy: 0.7863540501487781
Current Validation Accuracy: 0.7839862295004068
Current Validation Loss: 0.0002979456150898357
Epoch 7
Best Validation Accuracy: 0.7863540501487781
Current Validation Accuracy: 0.7966394078635155
Current Validation Loss: 0.0002833551788387679
Saving best model based on accuracy
Epoch 8
Best Validation Accuracy: 0.7966394078635155
Current Validation Accuracy: 0.8236564477938376
Current Validation Loss: 0.0002477008449785544
Saving best model based on accuracy
Epoch 9
Best Validation Accuracy: 0.8236564477938376
Current Validation Accuracy: 0.8284045940847626
Current Validation Loss: 0.00024113951331596682
Saving best model based on accuracy
Epoch 10
Best Validation Accuracy: 0.8284045940847626
Current Validation Accuracy: 0.8337636093414807
Current Validation Loss: 0.00023410393589209783
Saving best model based on accuracy
Epoch 11
Best Validation Accuracy: 0.8337636093414807
Current Validation Accuracy: 0.8300933935490487
Current Validation Loss: 0.00023912187978007295
Epoch 12
Best Validation Accuracy: 0.8337636093414807
Current Validation Accuracy: 0.8354580360531487
Current Validation Loss: 0.00023186052665016995
Saving best model based on accuracy
Epoch 13
Best Validation Accuracy: 0.8354580360531487
Current Validation Accuracy: 0.8420519194853444
Current Validation Loss: 0.00022285707727913437
Saving best model based on accuracy
Epoch 14
Best Validation Accuracy: 0.8420519194853444
Current Validation Accuracy: 0.8383535674560028
Current Validation Loss: 0.00022797087842417924
Epoch 15
Best Validation Accuracy: 0.8420519194853444
Current Validation Accuracy: 0.8415410904730076
Current Validation Loss: 0.00022359077894975978
Epoch 16
Best Validation Accuracy: 0.8420519194853444
Current Validation Accuracy: 0.8436450557441378
Current Validation Loss: 0.00022059121939451155
Saving best model based on accuracy
Epoch 17
Best Validation Accuracy: 0.8436450557441378
Current Validation Accuracy: 0.8463605152307703
Current Validation Loss: 0.00021687562429215356
Saving best model based on accuracy
Epoch 18
Best Validation Accuracy: 0.8463605152307703
Current Validation Accuracy: 0.8460322591334914
Current Validation Loss: 0.0002173087975237373
Epoch 19
Best Validation Accuracy: 0.8463605152307703
Current Validation Accuracy: 0.8474528264725725
Current Validation Loss: 0.00021501583151683842
Saving best model based on accuracy
Epoch 20
Best Validation Accuracy: 0.8474528264725725
Current Validation Accuracy: 0.847358413766498
Current Validation Loss: 0.0002152474379917251
Validation Accuracy has not changed much, will stop in 4 epochs if this continues
Epoch 21
Best Validation Accuracy: 0.8474528264725725
Current Validation Accuracy: 0.8485507649617566
Current Validation Loss: 0.00021358062832601234
Saving best model based on accuracy
Epoch 22
Best Validation Accuracy: 0.8485507649617566
Current Validation Accuracy: 0.8485151257283378
Current Validation Loss: 0.00021371414656367376
Validation Accuracy has not changed much, will stop in 4 epochs if this continues
Epoch 23
Best Validation Accuracy: 0.8485507649617566
Current Validation Accuracy: 0.8501832919522234
Current Validation Loss: 0.0002111587818525473
Saving best model based on accuracy
Epoch 24
Best Validation Accuracy: 0.8501832919522234
Current Validation Accuracy: 0.8510467618004941
Current Validation Loss: 0.00021017118123500087
Saving best model based on accuracy
Epoch 25
Best Validation Accuracy: 0.8510467618004941
Current Validation Accuracy: 0.8515225768291211
Current Validation Loss: 0.00020916366433950694
Saving best model based on accuracy
Epoch 26
Best Validation Accuracy: 0.8515225768291211
Current Validation Accuracy: 0.8516782640066877
Current Validation Loss: 0.00020906670740321797
Saving best model based on accuracy
Epoch 27
Best Validation Accuracy: 0.8516782640066877
Current Validation Accuracy: 0.8513475069105724
Current Validation Loss: 0.0002093075686994058
Epoch 28
Best Validation Accuracy: 0.8516782640066877
Current Validation Accuracy: 0.8515438353192306
Current Validation Loss: 0.00020898003784816532
Epoch 29
[[9.97897029e-01 1.46375722e-04 6.07382681e-04 1.17736461e-03
  7.40350470e-06 3.83655533e-05 2.09878613e-06 1.24016296e-04]
 [3.15385535e-02 5.72758727e-04 2.80271262e-01 6.52778387e-01
  3.34583037e-02 4.48385481e-06 1.37591606e-03 3.86129187e-07]
 [5.97536155e-06 5.38790482e-06 1.18926309e-05 2.82495218e-08
  1.55184825e-08 4.34414105e-04 4.47052969e-07 9.99541879e-01]
 [5.83566539e-03 7.81982671e-03 5.04829027e-02 1.08407217e-03
  3.74409766e-03 9.28583086e-01 2.04938464e-03 4.00858553e-04]
 [1.89233475e-07 1.83318082e-06 9.47887724e-09 3.44559261e-08
  8.83954160e-11 6.71379312e-05 8.45171968e-08 9.99930739e-01]
 [1.77291062e-04 3.15188004e-06 1.51919690e-03 2.55046552e-03
  9.95552957e-01 2.58773416e-05 1.71021908e-04 2.23123831e-09]
 [9.99369562e-01 1.93234337e-05 4.08400752e-04 5.34514438e-05
  1.42864053e-06 1.32621659e-04 5.01769819e-07 1.47464780e-05]
 [1.31973909e-04 1.16638752e-04 3.28627452e-02 8.78670719e-03
  9.56460595e-01 2.42720967e-06 1.63889269e-03 1.72139707e-08]
 [9.97855127e-01 9.00851810e-05 6.44640415e-04 1.22631504e-03
  4.52994209e-06 8.46390540e-05 1.32239438e-06 9.33926058e-05]
 [6.77372189e-03 1.85197196e-03 1.41747251e-01 1.02687746e-01
  7.20934510e-01 2.34272011e-05 2.59807836e-02 5.82771861e-07]
 [9.98790205e-01 2.02286628e-05 8.29893746e-04 1.78990722e-05
  1.80865186e-07 1.54106547e-05 1.01878286e-04 2.24237519e-04]
 [1.45159308e-02 4.13923030e-04 3.13965455e-02 9.46222097e-02
  8.37118983e-01 1.75832138e-05 2.19143331e-02 5.41382121e-07]
 [4.11423525e-06 4.44688396e-07 1.08398453e-05 2.29675584e-06
  1.20299001e-06 9.99912858e-01 9.34670439e-08 6.81102611e-05]
 [5.10262810e-02 3.07665396e-05 9.18413629e-04 1.78799741e-02
  1.49772510e-01 1.79805429e-04 7.80188739e-01 3.56267446e-06]
 [1.60548312e-03 7.26301130e-03 1.20802196e-02 2.09564483e-03
  1.38326141e-03 5.41504187e-06 9.75546896e-01 2.00912109e-05]
 [3.92104994e-05 9.54174084e-07 9.58819510e-06 7.22828815e-07
  9.00418308e-06 9.79153156e-01 1.89672994e-06 2.07855590e-02]
 [9.18389037e-02 6.74016192e-04 4.92902219e-01 6.37722164e-02
  3.48718703e-01 3.73594521e-05 2.05563335e-03 1.01562523e-06]
 [5.55327684e-02 9.37935889e-01 3.66155594e-03 4.66741913e-04
  2.37360673e-05 3.60302329e-06 2.02316209e-03 3.52513220e-04]
 [9.09854123e-07 5.05795867e-08 2.96421626e-06 2.51173617e-07
  6.92771255e-06 9.99957204e-01 9.47083905e-08 3.17534104e-05]
 [3.72709404e-03 5.33078006e-03 4.20670956e-02 3.28133777e-02
  8.92235100e-01 4.03509330e-06 2.38201562e-02 2.38054827e-06]]
[[9.97897029e-01 1.46375722e-04 6.07382681e-04 1.17736461e-03
  7.40350470e-06 3.83655533e-05 2.09878613e-06 1.24016296e-04]
 [3.15385535e-02 5.72758727e-04 2.80271262e-01 6.52778387e-01
  3.34583037e-02 4.48385481e-06 1.37591606e-03 3.86129187e-07]
 [5.97536155e-06 5.38790482e-06 1.18926309e-05 2.82495218e-08
  1.55184825e-08 4.34414105e-04 4.47052969e-07 9.99541879e-01]
 [5.83566539e-03 7.81982671e-03 5.04829027e-02 1.08407217e-03
  3.74409766e-03 9.28583086e-01 2.04938464e-03 4.00858553e-04]
 [1.89233475e-07 1.83318082e-06 9.47887724e-09 3.44559261e-08
  8.83954160e-11 6.71379312e-05 8.45171968e-08 9.99930739e-01]
 [1.77291062e-04 3.15188004e-06 1.51919690e-03 2.55046552e-03
  9.95552957e-01 2.58773416e-05 1.71021908e-04 2.23123831e-09]
 [9.99369562e-01 1.93234337e-05 4.08400752e-04 5.34514438e-05
  1.42864053e-06 1.32621659e-04 5.01769819e-07 1.47464780e-05]
 [1.31973909e-04 1.16638752e-04 3.28627452e-02 8.78670719e-03
  9.56460595e-01 2.42720967e-06 1.63889269e-03 1.72139707e-08]
 [9.97855127e-01 9.00851810e-05 6.44640415e-04 1.22631504e-03
  4.52994209e-06 8.46390540e-05 1.32239438e-06 9.33926058e-05]
 [6.77372189e-03 1.85197196e-03 1.41747251e-01 1.02687746e-01
  7.20934510e-01 2.34272011e-05 2.59807836e-02 5.82771861e-07]
 [9.98790205e-01 2.02286628e-05 8.29893746e-04 1.78990722e-05
  1.80865186e-07 1.54106547e-05 1.01878286e-04 2.24237519e-04]
 [1.45159308e-02 4.13923030e-04 3.13965455e-02 9.46222097e-02
  8.37118983e-01 1.75832138e-05 2.19143331e-02 5.41382121e-07]
 [4.11423525e-06 4.44688396e-07 1.08398453e-05 2.29675584e-06
  1.20299001e-06 9.99912858e-01 9.34670439e-08 6.81102611e-05]
 [5.10262810e-02 3.07665396e-05 9.18413629e-04 1.78799741e-02
  1.49772510e-01 1.79805429e-04 7.80188739e-01 3.56267446e-06]
 [1.60548312e-03 7.26301130e-03 1.20802196e-02 2.09564483e-03
  1.38326141e-03 5.41504187e-06 9.75546896e-01 2.00912109e-05]
 [3.92104994e-05 9.54174084e-07 9.58819510e-06 7.22828815e-07
  9.00418308e-06 9.79153156e-01 1.89672994e-06 2.07855590e-02]
 [9.18389037e-02 6.74016192e-04 4.92902219e-01 6.37722164e-02
  3.48718703e-01 3.73594521e-05 2.05563335e-03 1.01562523e-06]
 [5.55327684e-02 9.37935889e-01 3.66155594e-03 4.66741913e-04
  2.37360673e-05 3.60302329e-06 2.02316209e-03 3.52513220e-04]
 [9.09854123e-07 5.05795867e-08 2.96421626e-06 2.51173617e-07
  6.92771255e-06 9.99957204e-01 9.47083905e-08 3.17534104e-05]
 [3.72709404e-03 5.33078006e-03 4.20670956e-02 3.28133777e-02
  8.92235100e-01 4.03509330e-06 2.38201562e-02 2.38054827e-06]]
[[1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]]
Best Validation Accuracy: 0.8516782640066877
Current Validation Accuracy: 0.8525010926238666
Current Validation Loss: 0.00020767086240526257
Saving best model based on accuracy
Saving last model
