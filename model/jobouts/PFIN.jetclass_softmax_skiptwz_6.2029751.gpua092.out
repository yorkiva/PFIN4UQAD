Running "module reset". Resetting modules to system default. The following $MODULEPATH directories have been removed: None
A conda environment has been detected CONDA_PREFIX=
/sw/external/python/anaconda3 
anaconda3_gpu is loaded. Consider running conda deactivate and reloading it.

Currently Loaded Modules:
  1) cue-login-env/1.0   4) gcc/11.2.0    7) openmpi/4.1.2
  2) default             5) cuda/11.6.1   8) cudnn/8.4.1.50
  3) modtree/gpu         6) ucx/1.11.2    9) anaconda3_gpu/4.13.0

 

/u/avroy/UQ_XAI_Studies/models/PFIN_UQ/model/jobsub
total 508K
-rw-rw----+ 1 avroy delta_bbhj  925 Mar 31 16:58 jobsubmitter_dummy.py
-rw-rw----+ 1 avroy delta_bbhj 5.2K May 27 21:16 jobsubmitter_jetclass_1gpu.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 27 21:04 jobsubmitter_jetclass_1gpu.py~
-rw-rw----+ 1 avroy delta_bbhj  743 May 19 01:04 jobsubmitter_jetclass.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 18 13:59 jobsubmitter.py
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 19 13:52 UQPFIN-jetclass-run-jetclass20M_0_baseline.slurm
-rw-------+ 1 avroy delta_bbhj  973 May 19 00:59 UQPFIN-jetclass-run.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_9.slurm
-rw-------+ 1 avroy delta_bbhj  969 May 15 09:44 UQPFIN-run.slurm
/projects/bbhj/avroy/UQ_XAI_Studies/models/PFIN_UQ/model
total 200K
drwxr-s---+ 2 avroy delta_bbhj  12K May 28 11:01 jobouts
drwxr-s---+ 2 avroy delta_bbhj  16K May 27 21:18 jobsub
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 18 21:37 PFINDataset.py
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 15 14:46 PFINDataset.py~
drwxrws---+ 2 avroy delta_bbhj 4.0K May 18 21:38 __pycache__
drwxrws---+ 2 avroy delta_bbhj  20K May 28 10:58 trained_model_dicts
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:09 trained_model_dicts_old
drwxrws---+ 2 avroy delta_bbhj  36K May 28 11:01 trained_models
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:10 trained_models_old
-rw-rw----+ 1 avroy delta_bbhj  23K May 18 15:52 train_mod.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 27 21:06 train.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 18 13:50 train.py~
-rw-rw----+ 1 avroy delta_bbhj  13K May  5 09:36 UQPFIN.py
job is starting on gpua092.delta.ncsa.illinois.edu
# conda environments:
#
base                     /sw/external/python/anaconda3
toptagger_env         *  /u/avroy/.conda/envs/toptagger_env

/sw/external/python/anaconda3_gpu/bin/python
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
UQPFIN                                   [1, 6]                    --
├─Sequential: 1-1                        [60, 64]                  --
│    └─Sequential: 2-1                   [60, 100]                 --
│    │    └─Linear: 3-1                  [60, 100]                 1,200
│    │    └─ReLU: 3-2                    [60, 100]                 --
│    └─Sequential: 2-2                   [60, 100]                 --
│    │    └─Linear: 3-3                  [60, 100]                 10,100
│    │    └─ReLU: 3-4                    [60, 100]                 --
│    └─Sequential: 2-3                   [60, 64]                  --
│    │    └─Linear: 3-5                  [60, 64]                  6,464
│    │    └─ReLU: 3-6                    [60, 64]                  --
├─Sequential: 1-2                        [1770, 64]                --
│    └─Sequential: 2-4                   [1770, 128]               --
│    │    └─Linear: 3-7                  [1770, 128]               640
│    │    └─ReLU: 3-8                    [1770, 128]               --
│    └─Sequential: 2-5                   [1770, 128]               --
│    │    └─Linear: 3-9                  [1770, 128]               16,512
│    │    └─ReLU: 3-10                   [1770, 128]               --
│    └─Sequential: 2-6                   [1770, 64]                --
│    │    └─Linear: 3-11                 [1770, 64]                8,256
│    │    └─ReLU: 3-12                   [1770, 64]                --
├─Sequential: 1-3                        [60, 64]                  --
│    └─Sequential: 2-7                   [60, 128]                 --
│    │    └─Linear: 3-13                 [60, 128]                 9,728
│    │    └─ReLU: 3-14                   [60, 128]                 --
│    └─Sequential: 2-8                   [60, 128]                 --
│    │    └─Linear: 3-15                 [60, 128]                 16,512
│    │    └─ReLU: 3-16                   [60, 128]                 --
│    └─Sequential: 2-9                   [60, 64]                  --
│    │    └─Linear: 3-17                 [60, 64]                  8,256
│    │    └─ReLU: 3-18                   [60, 64]                  --
├─Sequential: 1-4                        [1, 6]                    --
│    └─Sequential: 2-10                  [1, 64]                   --
│    │    └─Linear: 3-19                 [1, 64]                   4,160
│    │    └─ReLU: 3-20                   [1, 64]                   --
│    └─Sequential: 2-11                  [1, 100]                  --
│    │    └─Linear: 3-21                 [1, 100]                  6,500
│    │    └─ReLU: 3-22                   [1, 100]                  --
│    └─Sequential: 2-12                  [1, 100]                  --
│    │    └─Linear: 3-23                 [1, 100]                  10,100
│    │    └─ReLU: 3-24                   [1, 100]                  --
│    └─Linear: 2-13                      [1, 6]                    606
│    └─Softmax: 2-14                     [1, 6]                    --
==========================================================================================
Total params: 99,034
Trainable params: 99,034
Non-trainable params: 0
Total mult-adds (M): 48.13
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 4.81
Params size (MB): 0.40
Estimated Total Size (MB): 5.21
==========================================================================================
data type:  jetclass
m_logic, pt_logic, eta_logic:  AND AND AND
m1, m2, pt1, pt2, eta1, eta2:  0.0 10000.0 0.0 10000.0 -6.0 6.0
skip labels:  [6, 7, 8, 9]
classes:  6
Epoch 0
Best Validation Accuracy: 0
Current Validation Accuracy: 0.7407925267992853
Current Validation Loss: 0.00045379037099899425
Saving best model based on accuracy
Epoch 1
Best Validation Accuracy: 0.7407925267992853
Current Validation Accuracy: 0.7505250633869694
Current Validation Loss: 0.0004408530196952053
Saving best model based on accuracy
Epoch 2
Best Validation Accuracy: 0.7505250633869694
Current Validation Accuracy: 0.7561137888857484
Current Validation Loss: 0.0004310962819440962
Saving best model based on accuracy
Epoch 3
Best Validation Accuracy: 0.7561137888857484
Current Validation Accuracy: 0.7577663107324707
Current Validation Loss: 0.00042846463578762533
Saving best model based on accuracy
Epoch 4
Best Validation Accuracy: 0.7577663107324707
Current Validation Accuracy: 0.7598832395764809
Current Validation Loss: 0.00042493688464939497
Saving best model based on accuracy
Epoch 5
Best Validation Accuracy: 0.7598832395764809
Current Validation Accuracy: 0.7611730737323231
Current Validation Loss: 0.00042252785803616644
Saving best model based on accuracy
Epoch 6
Best Validation Accuracy: 0.7611730737323231
Current Validation Accuracy: 0.7621794278539143
Current Validation Loss: 0.0004213168765383145
Saving best model based on accuracy
Epoch 7
Best Validation Accuracy: 0.7621794278539143
Current Validation Accuracy: 0.7654127677739897
Current Validation Loss: 0.00041726584435817284
Saving best model based on accuracy
Epoch 8
Best Validation Accuracy: 0.7654127677739897
Current Validation Accuracy: 0.7869472451993906
Current Validation Loss: 0.00038439500339024983
Saving best model based on accuracy
Epoch 9
Best Validation Accuracy: 0.7869472451993906
Current Validation Accuracy: 0.7975293881250214
Current Validation Loss: 0.00036727595381604884
Saving best model based on accuracy
Epoch 10
Best Validation Accuracy: 0.7975293881250214
Current Validation Accuracy: 0.779744351034994
Current Validation Loss: 0.0003964873222057973
Epoch 11
Best Validation Accuracy: 0.7975293881250214
Current Validation Accuracy: 0.8160256265950963
Current Validation Loss: 0.0003353088163127496
Saving best model based on accuracy
Epoch 12
Best Validation Accuracy: 0.8160256265950963
Current Validation Accuracy: 0.8221663043958581
Current Validation Loss: 0.00032419419776632603
Saving best model based on accuracy
Epoch 13
Best Validation Accuracy: 0.8221663043958581
Current Validation Accuracy: 0.8127981230286674
Current Validation Loss: 0.00034032666498396525
Epoch 14
Best Validation Accuracy: 0.8221663043958581
Current Validation Accuracy: 0.8299511663952762
Current Validation Loss: 0.0003104856196469986
Saving best model based on accuracy
Epoch 15
Best Validation Accuracy: 0.8299511663952762
Current Validation Accuracy: 0.8286713374171134
Current Validation Loss: 0.0003125109189868527
Epoch 16
Best Validation Accuracy: 0.8299511663952762
Current Validation Accuracy: 0.8308716427417855
Current Validation Loss: 0.00030864296117614093
Saving best model based on accuracy
Epoch 17
Best Validation Accuracy: 0.8308716427417855
Current Validation Accuracy: 0.8311117670060924
Current Validation Loss: 0.000308242895438906
Saving best model based on accuracy
Epoch 18
Best Validation Accuracy: 0.8311117670060924
Current Validation Accuracy: 0.8329952417042487
Current Validation Loss: 0.0003047249904457666
Saving best model based on accuracy
Epoch 19
Best Validation Accuracy: 0.8329952417042487
Current Validation Accuracy: 0.8332512074998812
Current Validation Loss: 0.00030427468738542917
Saving best model based on accuracy
Epoch 20
Best Validation Accuracy: 0.8332512074998812
Current Validation Accuracy: 0.83206225888564
Current Validation Loss: 0.00030692198378717145
Epoch 21
Best Validation Accuracy: 0.8332512074998812
Current Validation Accuracy: 0.8335355212989388
Current Validation Loss: 0.00030378316361718964
Saving best model based on accuracy
Epoch 22
Best Validation Accuracy: 0.8335355212989388
Current Validation Accuracy: 0.8341274943116396
Current Validation Loss: 0.00030233694337996844
Saving best model based on accuracy
Epoch 23
Best Validation Accuracy: 0.8341274943116396
Current Validation Accuracy: 0.8347303062668264
Current Validation Loss: 0.0003016959101675547
Saving best model based on accuracy
Epoch 24
Best Validation Accuracy: 0.8347303062668264
Current Validation Accuracy: 0.8345543818926294
Current Validation Loss: 0.0003019536399908021
Epoch 25
Best Validation Accuracy: 0.8347303062668264
Current Validation Accuracy: 0.8330986285402696
Current Validation Loss: 0.0003044297676555622
Epoch 26
Best Validation Accuracy: 0.8347303062668264
Current Validation Accuracy: 0.8348070126290356
Current Validation Loss: 0.0003012691103795716
Saving best model based on accuracy
Epoch 27
Best Validation Accuracy: 0.8348070126290356
Current Validation Accuracy: 0.8356791306167608
Current Validation Loss: 0.0003002135920614985
Saving best model based on accuracy
Epoch 28
Best Validation Accuracy: 0.8356791306167608
Current Validation Accuracy: 0.8353256143387536
Current Validation Loss: 0.0003009751270885144
Epoch 29
[[9.9491972e-01 3.7158202e-04 2.0370502e-03 2.5393954e-03 4.9287049e-05
  8.2924118e-05]
 [2.4401426e-02 1.5851093e-03 1.9605635e-01 7.1129191e-01 6.6645928e-02
  1.9353374e-05]
 [6.2612607e-03 4.3937000e-03 4.0931754e-02 2.3736616e-03 3.0208013e-03
  9.4301885e-01]
 [1.2028028e-04 4.7183476e-06 2.0040742e-03 2.5708168e-03 9.9529368e-01
  6.4108413e-06]
 [9.9987268e-01 1.6712439e-06 9.0581481e-05 9.4307079e-06 9.6181054e-08
  2.5439926e-05]
 [2.1186525e-04 4.8053113e-05 1.9449562e-02 6.4307167e-03 9.7385132e-01
  8.4259655e-06]
 [9.9918598e-01 3.3042546e-05 5.4614234e-04 1.7136108e-04 1.5942067e-06
  6.1961444e-05]
 [1.0139457e-02 1.8830461e-03 1.4804411e-01 1.9725671e-01 6.4259011e-01
  8.6604137e-05]
 [9.9556398e-01 2.8134242e-05 4.2745718e-03 1.0912139e-04 5.7368652e-06
  1.8631101e-05]
 [1.1256034e-02 2.5340606e-04 2.4271917e-02 9.4327353e-02 8.6986232e-01
  2.8945522e-05]
 [7.8400253e-06 1.0282567e-05 4.9270115e-05 6.2091372e-06 7.5233884e-06
  9.9991894e-01]
 [1.4321306e-01 2.3722193e-04 3.7819254e-03 1.1220996e-01 7.4045312e-01
  1.0466846e-04]
 [7.2820575e-07 3.2752808e-08 5.2093367e-07 1.3281368e-09 5.4472800e-08
  9.9999869e-01]
 [2.0648433e-01 3.6067350e-04 3.0077109e-01 9.7890563e-02 3.9430383e-01
  1.8955764e-04]
 [1.6108587e-01 8.3014816e-01 8.0523510e-03 6.8586372e-04 2.4316816e-05
  3.3935396e-06]
 [9.6191229e-08 8.9021079e-08 1.0730544e-06 8.0006458e-08 1.0433301e-06
  9.9999750e-01]
 [6.1179334e-03 4.0737358e-03 6.6447012e-02 4.5846395e-02 8.7750012e-01
  1.4858923e-05]
 [1.5584357e-01 3.3095598e-04 1.1345778e-02 3.8637388e-01 4.4607964e-01
  2.6172100e-05]
 [3.0872095e-02 3.6326011e-03 5.2045677e-02 2.8012639e-01 6.3330495e-01
  1.8300720e-05]
 [1.0310703e-02 6.3403770e-03 9.8132551e-01 2.0137564e-03 8.9717123e-06
  7.1149742e-07]]
[[9.9491972e-01 3.7158202e-04 2.0370502e-03 2.5393954e-03 4.9287049e-05
  8.2924118e-05]
 [2.4401426e-02 1.5851093e-03 1.9605635e-01 7.1129191e-01 6.6645928e-02
  1.9353374e-05]
 [6.2612607e-03 4.3937000e-03 4.0931754e-02 2.3736616e-03 3.0208013e-03
  9.4301885e-01]
 [1.2028028e-04 4.7183476e-06 2.0040742e-03 2.5708168e-03 9.9529368e-01
  6.4108413e-06]
 [9.9987268e-01 1.6712439e-06 9.0581481e-05 9.4307079e-06 9.6181054e-08
  2.5439926e-05]
 [2.1186525e-04 4.8053113e-05 1.9449562e-02 6.4307167e-03 9.7385132e-01
  8.4259655e-06]
 [9.9918598e-01 3.3042546e-05 5.4614234e-04 1.7136108e-04 1.5942067e-06
  6.1961444e-05]
 [1.0139457e-02 1.8830461e-03 1.4804411e-01 1.9725671e-01 6.4259011e-01
  8.6604137e-05]
 [9.9556398e-01 2.8134242e-05 4.2745718e-03 1.0912139e-04 5.7368652e-06
  1.8631101e-05]
 [1.1256034e-02 2.5340606e-04 2.4271917e-02 9.4327353e-02 8.6986232e-01
  2.8945522e-05]
 [7.8400253e-06 1.0282567e-05 4.9270115e-05 6.2091372e-06 7.5233884e-06
  9.9991894e-01]
 [1.4321306e-01 2.3722193e-04 3.7819254e-03 1.1220996e-01 7.4045312e-01
  1.0466846e-04]
 [7.2820575e-07 3.2752808e-08 5.2093367e-07 1.3281368e-09 5.4472800e-08
  9.9999869e-01]
 [2.0648433e-01 3.6067350e-04 3.0077109e-01 9.7890563e-02 3.9430383e-01
  1.8955764e-04]
 [1.6108587e-01 8.3014816e-01 8.0523510e-03 6.8586372e-04 2.4316816e-05
  3.3935396e-06]
 [9.6191229e-08 8.9021079e-08 1.0730544e-06 8.0006458e-08 1.0433301e-06
  9.9999750e-01]
 [6.1179334e-03 4.0737358e-03 6.6447012e-02 4.5846395e-02 8.7750012e-01
  1.4858923e-05]
 [1.5584357e-01 3.3095598e-04 1.1345778e-02 3.8637388e-01 4.4607964e-01
  2.6172100e-05]
 [3.0872095e-02 3.6326011e-03 5.2045677e-02 2.8012639e-01 6.3330495e-01
  1.8300720e-05]
 [1.0310703e-02 6.3403770e-03 9.8132551e-01 2.0137564e-03 8.9717123e-06
  7.1149742e-07]]
[[1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 0.]]
Best Validation Accuracy: 0.8356791306167608
Current Validation Accuracy: 0.8362110725633849
Current Validation Loss: 0.0002991694169136576
Saving best model based on accuracy
Saving last model
