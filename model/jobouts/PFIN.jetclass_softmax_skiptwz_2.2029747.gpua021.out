Running "module reset". Resetting modules to system default. The following $MODULEPATH directories have been removed: None
A conda environment has been detected CONDA_PREFIX=
/sw/external/python/anaconda3 
anaconda3_gpu is loaded. Consider running conda deactivate and reloading it.

Currently Loaded Modules:
  1) cue-login-env/1.0   4) gcc/11.2.0    7) openmpi/4.1.2
  2) default             5) cuda/11.6.1   8) cudnn/8.4.1.50
  3) modtree/gpu         6) ucx/1.11.2    9) anaconda3_gpu/4.13.0

 

/u/avroy/UQ_XAI_Studies/models/PFIN_UQ/model/jobsub
total 508K
-rw-rw----+ 1 avroy delta_bbhj  925 Mar 31 16:58 jobsubmitter_dummy.py
-rw-rw----+ 1 avroy delta_bbhj 5.2K May 27 21:16 jobsubmitter_jetclass_1gpu.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 27 21:04 jobsubmitter_jetclass_1gpu.py~
-rw-rw----+ 1 avroy delta_bbhj  743 May 19 01:04 jobsubmitter_jetclass.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 18 13:59 jobsubmitter.py
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 19 13:52 UQPFIN-jetclass-run-jetclass20M_0_baseline.slurm
-rw-------+ 1 avroy delta_bbhj  973 May 19 00:59 UQPFIN-jetclass-run.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_9.slurm
-rw-------+ 1 avroy delta_bbhj  969 May 15 09:44 UQPFIN-run.slurm
/projects/bbhj/avroy/UQ_XAI_Studies/models/PFIN_UQ/model
total 200K
drwxr-s---+ 2 avroy delta_bbhj  12K May 28 10:56 jobouts
drwxr-s---+ 2 avroy delta_bbhj  16K May 27 21:18 jobsub
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 18 21:37 PFINDataset.py
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 15 14:46 PFINDataset.py~
drwxrws---+ 2 avroy delta_bbhj 4.0K May 18 21:38 __pycache__
drwxrws---+ 2 avroy delta_bbhj  20K May 28 10:54 trained_model_dicts
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:09 trained_model_dicts_old
drwxrws---+ 2 avroy delta_bbhj  36K May 28 10:56 trained_models
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:10 trained_models_old
-rw-rw----+ 1 avroy delta_bbhj  23K May 18 15:52 train_mod.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 27 21:06 train.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 18 13:50 train.py~
-rw-rw----+ 1 avroy delta_bbhj  13K May  5 09:36 UQPFIN.py
job is starting on gpua021.delta.ncsa.illinois.edu
# conda environments:
#
base                     /sw/external/python/anaconda3
toptagger_env         *  /u/avroy/.conda/envs/toptagger_env

/sw/external/python/anaconda3_gpu/bin/python
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
UQPFIN                                   [1, 6]                    --
├─Sequential: 1-1                        [60, 64]                  --
│    └─Sequential: 2-1                   [60, 100]                 --
│    │    └─Linear: 3-1                  [60, 100]                 1,200
│    │    └─ReLU: 3-2                    [60, 100]                 --
│    └─Sequential: 2-2                   [60, 100]                 --
│    │    └─Linear: 3-3                  [60, 100]                 10,100
│    │    └─ReLU: 3-4                    [60, 100]                 --
│    └─Sequential: 2-3                   [60, 64]                  --
│    │    └─Linear: 3-5                  [60, 64]                  6,464
│    │    └─ReLU: 3-6                    [60, 64]                  --
├─Sequential: 1-2                        [1770, 64]                --
│    └─Sequential: 2-4                   [1770, 128]               --
│    │    └─Linear: 3-7                  [1770, 128]               640
│    │    └─ReLU: 3-8                    [1770, 128]               --
│    └─Sequential: 2-5                   [1770, 128]               --
│    │    └─Linear: 3-9                  [1770, 128]               16,512
│    │    └─ReLU: 3-10                   [1770, 128]               --
│    └─Sequential: 2-6                   [1770, 64]                --
│    │    └─Linear: 3-11                 [1770, 64]                8,256
│    │    └─ReLU: 3-12                   [1770, 64]                --
├─Sequential: 1-3                        [60, 64]                  --
│    └─Sequential: 2-7                   [60, 128]                 --
│    │    └─Linear: 3-13                 [60, 128]                 9,728
│    │    └─ReLU: 3-14                   [60, 128]                 --
│    └─Sequential: 2-8                   [60, 128]                 --
│    │    └─Linear: 3-15                 [60, 128]                 16,512
│    │    └─ReLU: 3-16                   [60, 128]                 --
│    └─Sequential: 2-9                   [60, 64]                  --
│    │    └─Linear: 3-17                 [60, 64]                  8,256
│    │    └─ReLU: 3-18                   [60, 64]                  --
├─Sequential: 1-4                        [1, 6]                    --
│    └─Sequential: 2-10                  [1, 64]                   --
│    │    └─Linear: 3-19                 [1, 64]                   4,160
│    │    └─ReLU: 3-20                   [1, 64]                   --
│    └─Sequential: 2-11                  [1, 100]                  --
│    │    └─Linear: 3-21                 [1, 100]                  6,500
│    │    └─ReLU: 3-22                   [1, 100]                  --
│    └─Sequential: 2-12                  [1, 100]                  --
│    │    └─Linear: 3-23                 [1, 100]                  10,100
│    │    └─ReLU: 3-24                   [1, 100]                  --
│    └─Linear: 2-13                      [1, 6]                    606
│    └─Softmax: 2-14                     [1, 6]                    --
==========================================================================================
Total params: 99,034
Trainable params: 99,034
Non-trainable params: 0
Total mult-adds (M): 48.13
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 4.81
Params size (MB): 0.40
Estimated Total Size (MB): 5.21
==========================================================================================
data type:  jetclass
m_logic, pt_logic, eta_logic:  AND AND AND
m1, m2, pt1, pt2, eta1, eta2:  0.0 10000.0 0.0 10000.0 -6.0 6.0
skip labels:  [6, 7, 8, 9]
classes:  6
Epoch 0
Best Validation Accuracy: 0
Current Validation Accuracy: 0.7409484408181234
Current Validation Loss: 0.00045499738469814076
Saving best model based on accuracy
Epoch 1
Best Validation Accuracy: 0.7409484408181234
Current Validation Accuracy: 0.7514363683206059
Current Validation Loss: 0.0004385351589238494
Saving best model based on accuracy
Epoch 2
Best Validation Accuracy: 0.7514363683206059
Current Validation Accuracy: 0.7567491176683934
Current Validation Loss: 0.0004301136375436387
Saving best model based on accuracy
Epoch 3
Best Validation Accuracy: 0.7567491176683934
Current Validation Accuracy: 0.7582640683220233
Current Validation Loss: 0.0004272657878292472
Saving best model based on accuracy
Epoch 4
Best Validation Accuracy: 0.7582640683220233
Current Validation Accuracy: 0.7597915254477525
Current Validation Loss: 0.00042483432638830133
Saving best model based on accuracy
Epoch 5
Best Validation Accuracy: 0.7597915254477525
Current Validation Accuracy: 0.7618134051038079
Current Validation Loss: 0.0004220527538360758
Saving best model based on accuracy
Epoch 6
Best Validation Accuracy: 0.7618134051038079
Current Validation Accuracy: 0.7887456758872716
Current Validation Loss: 0.0003821981761585778
Saving best model based on accuracy
Epoch 7
Best Validation Accuracy: 0.7887456758872716
Current Validation Accuracy: 0.7875083689142465
Current Validation Loss: 0.0003848739144725718
Epoch 8
Best Validation Accuracy: 0.7887456758872716
Current Validation Accuracy: 0.7878618851922536
Current Validation Loss: 0.00038327241542867837
Epoch 9
Best Validation Accuracy: 0.7887456758872716
Current Validation Accuracy: 0.8074636957959077
Current Validation Loss: 0.000349394024185687
Saving best model based on accuracy
Epoch 10
Best Validation Accuracy: 0.8074636957959077
Current Validation Accuracy: 0.8138495004498161
Current Validation Loss: 0.0003386161997196017
Saving best model based on accuracy
Epoch 11
Best Validation Accuracy: 0.8138495004498161
Current Validation Accuracy: 0.8249502450851649
Current Validation Loss: 0.0003190354587209437
Saving best model based on accuracy
Epoch 12
Best Validation Accuracy: 0.8249502450851649
Current Validation Accuracy: 0.8289664901586571
Current Validation Loss: 0.0003116422677570081
Saving best model based on accuracy
Epoch 13
Best Validation Accuracy: 0.8289664901586571
Current Validation Accuracy: 0.8247209597633443
Current Validation Loss: 0.00031870642080968715
Epoch 14
Best Validation Accuracy: 0.8289664901586571
Current Validation Accuracy: 0.8285837921124182
Current Validation Loss: 0.00031277849304188525
Epoch 15
Best Validation Accuracy: 0.8289664901586571
Current Validation Accuracy: 0.8282944757245208
Current Validation Loss: 0.00031339934935108513
Epoch 16
Best Validation Accuracy: 0.8289664901586571
Current Validation Accuracy: 0.8317737762625492
Current Validation Loss: 0.00030672820576376836
Saving best model based on accuracy
Epoch 17
Best Validation Accuracy: 0.8317737762625492
Current Validation Accuracy: 0.830028706522292
Current Validation Loss: 0.00031007071744066993
Epoch 18
Best Validation Accuracy: 0.8317737762625492
Current Validation Accuracy: 0.8300136987557728
Current Validation Loss: 0.0003098143916857186
Epoch 19
Best Validation Accuracy: 0.8317737762625492
Current Validation Accuracy: 0.8332203582020362
Current Validation Loss: 0.0003049079570737154
Saving best model based on accuracy
Epoch 20
Best Validation Accuracy: 0.8332203582020362
Current Validation Accuracy: 0.8335346875341323
Current Validation Loss: 0.0003038698537149332
Saving best model based on accuracy
Epoch 21
Best Validation Accuracy: 0.8335346875341323
Current Validation Accuracy: 0.8339582400558956
Current Validation Loss: 0.00030336513859758143
Saving best model based on accuracy
Epoch 22
Best Validation Accuracy: 0.8339582400558956
Current Validation Accuracy: 0.8335355212989388
Current Validation Loss: 0.00030394026408978974
Epoch 23
Best Validation Accuracy: 0.8339582400558956
Current Validation Accuracy: 0.833774811798439
Current Validation Loss: 0.0003035856976595419
Epoch 24
Best Validation Accuracy: 0.8339582400558956
Current Validation Accuracy: 0.8348770488727917
Current Validation Loss: 0.0003011839177542356
Saving best model based on accuracy
Epoch 25
Best Validation Accuracy: 0.8348770488727917
Current Validation Accuracy: 0.8345793948368281
Current Validation Loss: 0.00030134599769220675
Epoch 26
Best Validation Accuracy: 0.8348770488727917
Current Validation Accuracy: 0.8348845527560512
Current Validation Loss: 0.00030056222928124366
Saving best model based on accuracy
Epoch 27
Best Validation Accuracy: 0.8348845527560512
Current Validation Accuracy: 0.8354748582391388
Current Validation Loss: 0.00029995531431219023
Saving best model based on accuracy
Epoch 28
Best Validation Accuracy: 0.8354748582391388
Current Validation Accuracy: 0.8329135327531998
Current Validation Loss: 0.0003049151410152675
Epoch 29
[[9.98526812e-01 4.86601784e-05 3.90653353e-04 1.00131985e-03
  7.16487466e-06 2.53340186e-05]
 [2.80034784e-02 1.09539460e-03 2.09547117e-01 6.95767105e-01
  6.55715466e-02 1.53927303e-05]
 [1.23148998e-02 1.84999667e-02 8.45582858e-02 2.61789700e-03
  7.03580491e-03 8.74973238e-01]
 [2.38862223e-04 5.71745704e-06 2.06582830e-03 6.95036910e-03
  9.90726590e-01 1.26446457e-05]
 [9.99660015e-01 7.42233669e-06 2.80754874e-04 4.20286706e-05
  8.03873377e-08 9.70556721e-06]
 [1.50683161e-04 5.06566466e-05 2.46095918e-02 7.43017625e-03
  9.67757165e-01 1.78219420e-06]
 [9.97661948e-01 1.28024156e-04 1.42410246e-03 7.13631453e-04
  4.92894287e-06 6.74138792e-05]
 [1.14127863e-02 1.03849452e-03 1.00868940e-01 1.17253736e-01
  7.69388855e-01 3.72580071e-05]
 [9.97667611e-01 1.08076683e-05 2.24377844e-03 6.80619414e-05
  8.31195337e-07 8.86460384e-06]
 [6.32638857e-03 1.47337862e-03 5.89003004e-02 5.46091683e-02
  8.78622055e-01 6.87161228e-05]
 [3.27583548e-05 1.87650335e-06 4.72163156e-05 1.56732640e-05
  2.97576353e-05 9.99872684e-01]
 [9.37569216e-02 4.35815782e-05 2.17097718e-03 9.82773155e-02
  8.05607677e-01 1.43582336e-04]
 [2.16963667e-06 7.13276416e-09 6.69740587e-07 1.91827976e-08
  9.14176113e-08 9.99997020e-01]
 [8.81861076e-02 3.38942860e-04 1.73368230e-01 9.27213281e-02
  6.45307124e-01 7.82707793e-05]
 [4.85768378e-01 4.55239415e-01 5.72360456e-02 9.22842708e-04
  5.75297046e-04 2.58058892e-04]
 [8.89333080e-07 2.76568031e-08 3.10491828e-06 7.17456260e-07
  2.52422215e-05 9.99970078e-01]
 [6.88654371e-03 1.29203629e-02 7.71886334e-02 5.69816306e-02
  8.46014678e-01 8.18285207e-06]
 [1.01939335e-01 2.18025132e-04 7.73955090e-03 3.84700239e-01
  5.05379796e-01 2.30984169e-05]
 [3.06993872e-02 2.57624360e-03 4.98466454e-02 2.52133340e-01
  6.64666712e-01 7.77068053e-05]
 [1.34335225e-02 6.19322285e-02 9.20626938e-01 3.93396057e-03
  3.01754390e-05 4.31585431e-05]]
[[9.98526812e-01 4.86601784e-05 3.90653353e-04 1.00131985e-03
  7.16487466e-06 2.53340186e-05]
 [2.80034784e-02 1.09539460e-03 2.09547117e-01 6.95767105e-01
  6.55715466e-02 1.53927303e-05]
 [1.23148998e-02 1.84999667e-02 8.45582858e-02 2.61789700e-03
  7.03580491e-03 8.74973238e-01]
 [2.38862223e-04 5.71745704e-06 2.06582830e-03 6.95036910e-03
  9.90726590e-01 1.26446457e-05]
 [9.99660015e-01 7.42233669e-06 2.80754874e-04 4.20286706e-05
  8.03873377e-08 9.70556721e-06]
 [1.50683161e-04 5.06566466e-05 2.46095918e-02 7.43017625e-03
  9.67757165e-01 1.78219420e-06]
 [9.97661948e-01 1.28024156e-04 1.42410246e-03 7.13631453e-04
  4.92894287e-06 6.74138792e-05]
 [1.14127863e-02 1.03849452e-03 1.00868940e-01 1.17253736e-01
  7.69388855e-01 3.72580071e-05]
 [9.97667611e-01 1.08076683e-05 2.24377844e-03 6.80619414e-05
  8.31195337e-07 8.86460384e-06]
 [6.32638857e-03 1.47337862e-03 5.89003004e-02 5.46091683e-02
  8.78622055e-01 6.87161228e-05]
 [3.27583548e-05 1.87650335e-06 4.72163156e-05 1.56732640e-05
  2.97576353e-05 9.99872684e-01]
 [9.37569216e-02 4.35815782e-05 2.17097718e-03 9.82773155e-02
  8.05607677e-01 1.43582336e-04]
 [2.16963667e-06 7.13276416e-09 6.69740587e-07 1.91827976e-08
  9.14176113e-08 9.99997020e-01]
 [8.81861076e-02 3.38942860e-04 1.73368230e-01 9.27213281e-02
  6.45307124e-01 7.82707793e-05]
 [4.85768378e-01 4.55239415e-01 5.72360456e-02 9.22842708e-04
  5.75297046e-04 2.58058892e-04]
 [8.89333080e-07 2.76568031e-08 3.10491828e-06 7.17456260e-07
  2.52422215e-05 9.99970078e-01]
 [6.88654371e-03 1.29203629e-02 7.71886334e-02 5.69816306e-02
  8.46014678e-01 8.18285207e-06]
 [1.01939335e-01 2.18025132e-04 7.73955090e-03 3.84700239e-01
  5.05379796e-01 2.30984169e-05]
 [3.06993872e-02 2.57624360e-03 4.98466454e-02 2.52133340e-01
  6.64666712e-01 7.77068053e-05]
 [1.34335225e-02 6.19322285e-02 9.20626938e-01 3.93396057e-03
  3.01754390e-05 4.31585431e-05]]
[[1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 0.]]
Best Validation Accuracy: 0.8354748582391388
Current Validation Accuracy: 0.8335797108336898
Current Validation Loss: 0.00030344532278462965
Saving last model
