Running "module reset". Resetting modules to system default. The following $MODULEPATH directories have been removed: None
A conda environment has been detected CONDA_PREFIX=
/sw/external/python/anaconda3 
anaconda3_gpu is loaded. Consider running conda deactivate and reloading it.

Currently Loaded Modules:
  1) cue-login-env/1.0   4) gcc/11.2.0    7) openmpi/4.1.2
  2) default             5) cuda/11.6.1   8) cudnn/8.4.1.50
  3) modtree/gpu         6) ucx/1.11.2    9) anaconda3_gpu/4.13.0

 

/u/avroy/UQ_XAI_Studies/models/PFIN_UQ/model/jobsub
total 508K
-rw-rw----+ 1 avroy delta_bbhj  925 Mar 31 16:58 jobsubmitter_dummy.py
-rw-rw----+ 1 avroy delta_bbhj 5.2K May 27 21:16 jobsubmitter_jetclass_1gpu.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 27 21:04 jobsubmitter_jetclass_1gpu.py~
-rw-rw----+ 1 avroy delta_bbhj  743 May 19 01:04 jobsubmitter_jetclass.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 18 13:59 jobsubmitter.py
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 19 13:52 UQPFIN-jetclass-run-jetclass20M_0_baseline.slurm
-rw-------+ 1 avroy delta_bbhj  973 May 19 00:59 UQPFIN-jetclass-run.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_9.slurm
-rw-------+ 1 avroy delta_bbhj  969 May 15 09:44 UQPFIN-run.slurm
/projects/bbhj/avroy/UQ_XAI_Studies/models/PFIN_UQ/model
total 200K
drwxr-s---+ 2 avroy delta_bbhj  12K May 28 10:24 jobouts
drwxr-s---+ 2 avroy delta_bbhj  16K May 27 21:18 jobsub
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 18 21:37 PFINDataset.py
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 15 14:46 PFINDataset.py~
drwxrws---+ 2 avroy delta_bbhj 4.0K May 18 21:38 __pycache__
drwxrws---+ 2 avroy delta_bbhj  20K May 28 09:31 trained_model_dicts
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:09 trained_model_dicts_old
drwxrws---+ 2 avroy delta_bbhj  36K May 28 10:23 trained_models
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:10 trained_models_old
-rw-rw----+ 1 avroy delta_bbhj  23K May 18 15:52 train_mod.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 27 21:06 train.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 18 13:50 train.py~
-rw-rw----+ 1 avroy delta_bbhj  13K May  5 09:36 UQPFIN.py
job is starting on gpua079.delta.ncsa.illinois.edu
# conda environments:
#
base                     /sw/external/python/anaconda3
toptagger_env         *  /u/avroy/.conda/envs/toptagger_env

/sw/external/python/anaconda3_gpu/bin/python
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
UQPFIN                                   [1, 8]                    --
├─Sequential: 1-1                        [60, 64]                  --
│    └─Sequential: 2-1                   [60, 100]                 --
│    │    └─Linear: 3-1                  [60, 100]                 1,200
│    │    └─ReLU: 3-2                    [60, 100]                 --
│    └─Sequential: 2-2                   [60, 100]                 --
│    │    └─Linear: 3-3                  [60, 100]                 10,100
│    │    └─ReLU: 3-4                    [60, 100]                 --
│    └─Sequential: 2-3                   [60, 64]                  --
│    │    └─Linear: 3-5                  [60, 64]                  6,464
│    │    └─ReLU: 3-6                    [60, 64]                  --
├─Sequential: 1-2                        [1770, 64]                --
│    └─Sequential: 2-4                   [1770, 128]               --
│    │    └─Linear: 3-7                  [1770, 128]               640
│    │    └─ReLU: 3-8                    [1770, 128]               --
│    └─Sequential: 2-5                   [1770, 128]               --
│    │    └─Linear: 3-9                  [1770, 128]               16,512
│    │    └─ReLU: 3-10                   [1770, 128]               --
│    └─Sequential: 2-6                   [1770, 64]                --
│    │    └─Linear: 3-11                 [1770, 64]                8,256
│    │    └─ReLU: 3-12                   [1770, 64]                --
├─Sequential: 1-3                        [60, 64]                  --
│    └─Sequential: 2-7                   [60, 128]                 --
│    │    └─Linear: 3-13                 [60, 128]                 9,728
│    │    └─ReLU: 3-14                   [60, 128]                 --
│    └─Sequential: 2-8                   [60, 128]                 --
│    │    └─Linear: 3-15                 [60, 128]                 16,512
│    │    └─ReLU: 3-16                   [60, 128]                 --
│    └─Sequential: 2-9                   [60, 64]                  --
│    │    └─Linear: 3-17                 [60, 64]                  8,256
│    │    └─ReLU: 3-18                   [60, 64]                  --
├─Sequential: 1-4                        [1, 8]                    --
│    └─Sequential: 2-10                  [1, 64]                   --
│    │    └─Linear: 3-19                 [1, 64]                   4,160
│    │    └─ReLU: 3-20                   [1, 64]                   --
│    └─Sequential: 2-11                  [1, 100]                  --
│    │    └─Linear: 3-21                 [1, 100]                  6,500
│    │    └─ReLU: 3-22                   [1, 100]                  --
│    └─Sequential: 2-12                  [1, 100]                  --
│    │    └─Linear: 3-23                 [1, 100]                  10,100
│    │    └─ReLU: 3-24                   [1, 100]                  --
│    └─Linear: 2-13                      [1, 8]                    808
│    └─Softmax: 2-14                     [1, 8]                    --
==========================================================================================
Total params: 99,236
Trainable params: 99,236
Non-trainable params: 0
Total mult-adds (M): 48.13
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 4.81
Params size (MB): 0.40
Estimated Total Size (MB): 5.21
==========================================================================================
data type:  jetclass
m_logic, pt_logic, eta_logic:  AND AND AND
m1, m2, pt1, pt2, eta1, eta2:  0.0 10000.0 0.0 10000.0 -6.0 6.0
skip labels:  [6, 7]
classes:  8
Epoch 0
Best Validation Accuracy: 0
Current Validation Accuracy: 0.7644446750921149
Current Validation Loss: 0.0003236519262611185
Saving best model based on accuracy
Epoch 1
Best Validation Accuracy: 0.7644446750921149
Current Validation Accuracy: 0.7722640479541517
Current Validation Loss: 0.00031314701246874094
Saving best model based on accuracy
Epoch 2
Best Validation Accuracy: 0.7722640479541517
Current Validation Accuracy: 0.7778306461142919
Current Validation Loss: 0.0003055222303478573
Saving best model based on accuracy
Epoch 3
Best Validation Accuracy: 0.7778306461142919
Current Validation Accuracy: 0.7799621223726225
Current Validation Loss: 0.0003026198452237018
Saving best model based on accuracy
Epoch 4
Best Validation Accuracy: 0.7799621223726225
Current Validation Accuracy: 0.7816853105709093
Current Validation Loss: 0.000300129691723198
Saving best model based on accuracy
Epoch 5
Best Validation Accuracy: 0.7816853105709093
Current Validation Accuracy: 0.7772529153830812
Current Validation Loss: 0.0003056060629671748
Epoch 6
Best Validation Accuracy: 0.7816853105709093
Current Validation Accuracy: 0.8240909963416639
Current Validation Loss: 0.00024742478224526693
Saving best model based on accuracy
Epoch 7
Best Validation Accuracy: 0.8240909963416639
Current Validation Accuracy: 0.8224209543686509
Current Validation Loss: 0.00024916082724132005
Epoch 8
Best Validation Accuracy: 0.8240909963416639
Current Validation Accuracy: 0.826730800613495
Current Validation Loss: 0.00024415710011958493
Saving best model based on accuracy
Epoch 9
Best Validation Accuracy: 0.826730800613495
Current Validation Accuracy: 0.8349278242998297
Current Validation Loss: 0.0002325165722035887
Saving best model based on accuracy
Epoch 10
Best Validation Accuracy: 0.8349278242998297
Current Validation Accuracy: 0.8326844283435697
Current Validation Loss: 0.00023545213652156224
Epoch 11
Best Validation Accuracy: 0.8349278242998297
Current Validation Accuracy: 0.8359200955881755
Current Validation Loss: 0.00023087843106238558
Saving best model based on accuracy
Epoch 12
Best Validation Accuracy: 0.8359200955881755
Current Validation Accuracy: 0.8391832738199818
Current Validation Loss: 0.0002261810612478877
Saving best model based on accuracy
Epoch 13
Best Validation Accuracy: 0.8391832738199818
Current Validation Accuracy: 0.842872247103687
Current Validation Loss: 0.00022142960993052087
Saving best model based on accuracy
Epoch 14
Best Validation Accuracy: 0.842872247103687
Current Validation Accuracy: 0.8441908987401844
Current Validation Loss: 0.00021963141817941866
Saving best model based on accuracy
Epoch 15
Best Validation Accuracy: 0.8441908987401844
Current Validation Accuracy: 0.8459578544181082
Current Validation Loss: 0.00021704193585296845
Saving best model based on accuracy
Epoch 16
Best Validation Accuracy: 0.8459578544181082
Current Validation Accuracy: 0.8481806171339679
Current Validation Loss: 0.0002134618086339048
Saving best model based on accuracy
Epoch 17
Best Validation Accuracy: 0.8481806171339679
Current Validation Accuracy: 0.8515725968058493
Current Validation Loss: 0.00020887463521149463
Saving best model based on accuracy
Epoch 18
Best Validation Accuracy: 0.8515725968058493
Current Validation Accuracy: 0.8506434757381229
Current Validation Loss: 0.00021019481027894125
Epoch 19
Best Validation Accuracy: 0.8515725968058493
Current Validation Accuracy: 0.8466206191097569
Current Validation Loss: 0.00021584427604453858
Epoch 20
Best Validation Accuracy: 0.8515725968058493
Current Validation Accuracy: 0.8539948141789127
Current Validation Loss: 0.00020578390998495609
Saving best model based on accuracy
Epoch 21
Best Validation Accuracy: 0.8539948141789127
Current Validation Accuracy: 0.8531526028207516
Current Validation Loss: 0.00020671826425210205
Epoch 22
Best Validation Accuracy: 0.8539948141789127
Current Validation Accuracy: 0.8543143167802641
Current Validation Loss: 0.00020500953782951706
Saving best model based on accuracy
Epoch 23
Best Validation Accuracy: 0.8543143167802641
Current Validation Accuracy: 0.8543487055142648
Current Validation Loss: 0.00020482291802680693
Validation Accuracy has not changed much, will stop in 4 epochs if this continues
Saving best model based on accuracy
Epoch 24
Best Validation Accuracy: 0.8543487055142648
Current Validation Accuracy: 0.8550358549445685
Current Validation Loss: 0.00020419812168033085
Saving best model based on accuracy
Epoch 25
Best Validation Accuracy: 0.8550358549445685
Current Validation Accuracy: 0.855989986000659
Current Validation Loss: 0.00020287042930897348
Saving best model based on accuracy
Epoch 26
Best Validation Accuracy: 0.855989986000659
Current Validation Accuracy: 0.8559756052573496
Current Validation Loss: 0.00020287907469015697
Validation Accuracy has not changed much, will stop in 4 epochs if this continues
Epoch 27
Best Validation Accuracy: 0.855989986000659
Current Validation Accuracy: 0.8562844786136463
Current Validation Loss: 0.00020252993698235605
Saving best model based on accuracy
Epoch 28
Best Validation Accuracy: 0.8562844786136463
Current Validation Accuracy: 0.8569534958023861
Current Validation Loss: 0.00020146138683738114
Saving best model based on accuracy
Epoch 29
[[9.93949294e-01 4.94659063e-04 2.44982261e-03 2.85218866e-03
  4.06410072e-05 7.68753962e-05 3.87302271e-06 1.32701534e-04]
 [5.54134659e-02 2.23650225e-03 2.39674374e-01 5.69089711e-01
  1.30397782e-01 1.98243015e-05 3.16286227e-03 5.49594506e-06]
 [3.88717854e-06 4.49279833e-05 8.14710347e-06 1.24516347e-07
  1.53459414e-08 4.73243359e-04 5.42785976e-08 9.99469578e-01]
 [1.10313417e-02 5.39739709e-03 3.14255841e-02 4.69807489e-03
  1.76691692e-02 9.27660048e-01 2.01540836e-03 1.03004291e-04]
 [5.02334728e-07 5.04526679e-06 9.56346611e-08 1.56559338e-07
  3.17841131e-09 8.00021342e-04 1.11112634e-07 9.99194086e-01]
 [2.32859427e-04 4.95177437e-06 1.84491347e-03 4.03606147e-03
  9.93643522e-01 2.38723806e-05 2.13817126e-04 4.15933492e-08]
 [9.99649405e-01 1.96850506e-05 2.97107443e-04 8.67415656e-06
  2.87242699e-07 8.70546592e-06 1.24947448e-08 1.62074357e-05]
 [4.38333169e-04 1.43289042e-04 4.31933478e-02 1.66118536e-02
  9.38475788e-01 2.31672129e-06 1.13501376e-03 3.38028947e-08]
 [9.98935163e-01 7.37073715e-05 5.51826612e-04 3.79432604e-04
  5.51135054e-06 2.38217399e-05 1.89557213e-07 3.03643919e-05]
 [1.11310342e-02 5.21181675e-04 5.77554293e-02 1.67557001e-01
  7.42769897e-01 3.96098185e-05 2.02250667e-02 7.65142886e-07]
 [9.97877836e-01 8.26855921e-06 1.66462979e-03 2.58265383e-04
  7.76064735e-06 7.94973748e-05 5.19811038e-05 5.18105044e-05]
 [5.53201744e-03 5.27115946e-04 3.06402016e-02 5.06550372e-02
  9.02185738e-01 2.32781495e-05 1.04345130e-02 2.00562181e-06]
 [3.74843876e-05 4.74442732e-06 1.22246216e-04 2.60542693e-05
  4.95525383e-05 9.99708593e-01 5.19111791e-06 4.60984957e-05]
 [8.13756511e-02 3.81759601e-05 2.49314378e-03 6.32688776e-02
  4.57643896e-01 1.81694471e-04 3.94995391e-01 3.18614707e-06]
 [2.71106517e-04 1.47893070e-03 4.33921050e-05 6.42868617e-05
  9.68832610e-05 2.79238321e-07 9.98031318e-01 1.37176494e-05]
 [4.71104431e-06 8.33236356e-07 1.15187413e-05 6.77915608e-08
  1.63995833e-06 9.73940372e-01 9.53820859e-07 2.60398760e-02]
 [1.26802787e-01 1.12061319e-03 5.04435420e-01 1.04972035e-01
  2.59324640e-01 2.68424541e-04 3.07564950e-03 4.76923901e-07]
 [7.89382234e-02 9.14914310e-01 2.64054257e-03 3.63615341e-04
  8.58869043e-06 1.29928419e-04 3.95833456e-04 2.60897679e-03]
 [1.62532604e-06 2.71151322e-07 1.36843273e-05 1.01269336e-06
  4.19005228e-05 9.99867797e-01 1.08547863e-06 7.26988583e-05]
 [7.01455772e-03 1.87633112e-02 7.37876669e-02 5.38130291e-02
  8.15548420e-01 1.15667808e-05 3.10513359e-02 1.01307905e-05]]
[[9.93949294e-01 4.94659063e-04 2.44982261e-03 2.85218866e-03
  4.06410072e-05 7.68753962e-05 3.87302271e-06 1.32701534e-04]
 [5.54134659e-02 2.23650225e-03 2.39674374e-01 5.69089711e-01
  1.30397782e-01 1.98243015e-05 3.16286227e-03 5.49594506e-06]
 [3.88717854e-06 4.49279833e-05 8.14710347e-06 1.24516347e-07
  1.53459414e-08 4.73243359e-04 5.42785976e-08 9.99469578e-01]
 [1.10313417e-02 5.39739709e-03 3.14255841e-02 4.69807489e-03
  1.76691692e-02 9.27660048e-01 2.01540836e-03 1.03004291e-04]
 [5.02334728e-07 5.04526679e-06 9.56346611e-08 1.56559338e-07
  3.17841131e-09 8.00021342e-04 1.11112634e-07 9.99194086e-01]
 [2.32859427e-04 4.95177437e-06 1.84491347e-03 4.03606147e-03
  9.93643522e-01 2.38723806e-05 2.13817126e-04 4.15933492e-08]
 [9.99649405e-01 1.96850506e-05 2.97107443e-04 8.67415656e-06
  2.87242699e-07 8.70546592e-06 1.24947448e-08 1.62074357e-05]
 [4.38333169e-04 1.43289042e-04 4.31933478e-02 1.66118536e-02
  9.38475788e-01 2.31672129e-06 1.13501376e-03 3.38028947e-08]
 [9.98935163e-01 7.37073715e-05 5.51826612e-04 3.79432604e-04
  5.51135054e-06 2.38217399e-05 1.89557213e-07 3.03643919e-05]
 [1.11310342e-02 5.21181675e-04 5.77554293e-02 1.67557001e-01
  7.42769897e-01 3.96098185e-05 2.02250667e-02 7.65142886e-07]
 [9.97877836e-01 8.26855921e-06 1.66462979e-03 2.58265383e-04
  7.76064735e-06 7.94973748e-05 5.19811038e-05 5.18105044e-05]
 [5.53201744e-03 5.27115946e-04 3.06402016e-02 5.06550372e-02
  9.02185738e-01 2.32781495e-05 1.04345130e-02 2.00562181e-06]
 [3.74843876e-05 4.74442732e-06 1.22246216e-04 2.60542693e-05
  4.95525383e-05 9.99708593e-01 5.19111791e-06 4.60984957e-05]
 [8.13756511e-02 3.81759601e-05 2.49314378e-03 6.32688776e-02
  4.57643896e-01 1.81694471e-04 3.94995391e-01 3.18614707e-06]
 [2.71106517e-04 1.47893070e-03 4.33921050e-05 6.42868617e-05
  9.68832610e-05 2.79238321e-07 9.98031318e-01 1.37176494e-05]
 [4.71104431e-06 8.33236356e-07 1.15187413e-05 6.77915608e-08
  1.63995833e-06 9.73940372e-01 9.53820859e-07 2.60398760e-02]
 [1.26802787e-01 1.12061319e-03 5.04435420e-01 1.04972035e-01
  2.59324640e-01 2.68424541e-04 3.07564950e-03 4.76923901e-07]
 [7.89382234e-02 9.14914310e-01 2.64054257e-03 3.63615341e-04
  8.58869043e-06 1.29928419e-04 3.95833456e-04 2.60897679e-03]
 [1.62532604e-06 2.71151322e-07 1.36843273e-05 1.01269336e-06
  4.19005228e-05 9.99867797e-01 1.08547863e-06 7.26988583e-05]
 [7.01455772e-03 1.87633112e-02 7.37876669e-02 5.38130291e-02
  8.15548420e-01 1.15667808e-05 3.10513359e-02 1.01307905e-05]]
[[1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]]
Best Validation Accuracy: 0.8569534958023861
Current Validation Accuracy: 0.8571398202156987
Current Validation Loss: 0.0002015204796836403
Saving best model based on accuracy
Saving last model
