Running "module reset". Resetting modules to system default. The following $MODULEPATH directories have been removed: None
A conda environment has been detected CONDA_PREFIX=
/sw/external/python/anaconda3 
anaconda3_gpu is loaded. Consider running conda deactivate and reloading it.

Currently Loaded Modules:
  1) cue-login-env/1.0   4) gcc/11.2.0    7) openmpi/4.1.2
  2) default             5) cuda/11.6.1   8) cudnn/8.4.1.50
  3) modtree/gpu         6) ucx/1.11.2    9) anaconda3_gpu/4.13.0

 

/u/avroy/UQ_XAI_Studies/models/PFIN_UQ/model/jobsub
total 41K
-rw-rw----+ 1 avroy delta_bbhj  925 Mar 31 16:58 jobsubmitter_dummy.py
-rw-rw----+ 1 avroy delta_bbhj  11K May 15 09:55 jobsubmitter.py
-rw-rw----+ 1 avroy delta_bbhj  11K May 15 09:45 jobsubmitter.py~
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 15 09:55 UQPFIN-run-jetclass_trial0_20Mdata.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 15 09:44 UQPFIN-run-jetclass_trial0_fulldata.slurm
-rw-------+ 1 avroy delta_bbhj  969 May 15 09:44 UQPFIN-run.slurm
-rw-------+ 1 avroy delta_bbhj  969 May 15 09:44 UQPFIN-run.slurm~
/projects/bbhj/avroy/UQ_XAI_Studies/models/PFIN_UQ/model
total 128K
drwxr-s---+ 2 avroy delta_bbhj  12K May 15 09:55 jobouts
drwxr-s---+ 2 avroy delta_bbhj 4.0K May 15 09:55 jobsub
-rw-rw----+ 1 avroy delta_bbhj 8.3K May  1 09:53 PFINDataset.py
drwxrws---+ 2 avroy delta_bbhj 4.0K May  5 19:52 __pycache__
drwxrws---+ 2 avroy delta_bbhj  12K May 13 01:24 trained_model_dicts
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:09 trained_model_dicts_old
drwxrws---+ 2 avroy delta_bbhj  20K May 14 03:33 trained_models
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:10 trained_models_old
-rw-rw----+ 1 avroy delta_bbhj  19K May 15 09:55 train.py
-rw-rw----+ 1 avroy delta_bbhj  19K May 15 09:40 train.py~
-rw-rw----+ 1 avroy delta_bbhj  13K May  5 09:36 UQPFIN.py
job is starting on gpua001.delta.ncsa.illinois.edu
# conda environments:
#
base                     /sw/external/python/anaconda3
toptagger_env         *  /u/avroy/.conda/envs/toptagger_env

/sw/external/python/anaconda3_gpu/bin/python
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
UQPFIN                                   [1, 10]                   --
├─Sequential: 1-1                        [60, 128]                 --
│    └─Sequential: 2-1                   [60, 100]                 --
│    │    └─Linear: 3-1                  [60, 100]                 1,200
│    │    └─ReLU: 3-2                    [60, 100]                 --
│    └─Sequential: 2-2                   [60, 100]                 --
│    │    └─Linear: 3-3                  [60, 100]                 10,100
│    │    └─ReLU: 3-4                    [60, 100]                 --
│    └─Sequential: 2-3                   [60, 100]                 --
│    │    └─Linear: 3-5                  [60, 100]                 10,100
│    │    └─ReLU: 3-6                    [60, 100]                 --
│    └─Sequential: 2-4                   [60, 128]                 --
│    │    └─Linear: 3-7                  [60, 128]                 12,928
│    │    └─ReLU: 3-8                    [60, 128]                 --
├─Sequential: 1-2                        [1770, 128]               --
│    └─Sequential: 2-5                   [1770, 256]               --
│    │    └─Linear: 3-9                  [1770, 256]               1,280
│    │    └─ReLU: 3-10                   [1770, 256]               --
│    └─Sequential: 2-6                   [1770, 256]               --
│    │    └─Linear: 3-11                 [1770, 256]               65,792
│    │    └─ReLU: 3-12                   [1770, 256]               --
│    └─Sequential: 2-7                   [1770, 128]               --
│    │    └─Linear: 3-13                 [1770, 128]               32,896
│    │    └─ReLU: 3-14                   [1770, 128]               --
├─Sequential: 1-3                        [60, 128]                 --
│    └─Sequential: 2-8                   [60, 256]                 --
│    │    └─Linear: 3-15                 [60, 256]                 35,840
│    │    └─ReLU: 3-16                   [60, 256]                 --
│    └─Sequential: 2-9                   [60, 256]                 --
│    │    └─Linear: 3-17                 [60, 256]                 65,792
│    │    └─ReLU: 3-18                   [60, 256]                 --
│    └─Sequential: 2-10                  [60, 128]                 --
│    │    └─Linear: 3-19                 [60, 128]                 32,896
│    │    └─ReLU: 3-20                   [60, 128]                 --
├─Sequential: 1-4                        [1, 10]                   --
│    └─Sequential: 2-11                  [1, 128]                  --
│    │    └─Linear: 3-21                 [1, 128]                  16,512
│    │    └─ReLU: 3-22                   [1, 128]                  --
│    └─Sequential: 2-12                  [1, 100]                  --
│    │    └─Linear: 3-23                 [1, 100]                  12,900
│    │    └─ReLU: 3-24                   [1, 100]                  --
│    └─Sequential: 2-13                  [1, 100]                  --
│    │    └─Linear: 3-25                 [1, 100]                  10,100
│    │    └─ReLU: 3-26                   [1, 100]                  --
│    └─Sequential: 2-14                  [1, 100]                  --
│    │    └─Linear: 3-27                 [1, 100]                  10,100
│    │    └─ReLU: 3-28                   [1, 100]                  --
│    └─Linear: 2-15                      [1, 10]                   1,010
│    └─Softmax: 2-16                     [1, 10]                   --
==========================================================================================
Total params: 319,446
Trainable params: 319,446
Non-trainable params: 0
Total mult-adds (M): 187.13
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 9.58
Params size (MB): 1.28
Estimated Total Size (MB): 10.86
==========================================================================================
data type:  jetclass
m_logic, pt_logic, eta_logic:  AND AND AND
m1, m2, pt1, pt2, eta1, eta2:  0.0 10000.0 0.0 10000.0 -6.0 6.0
skip labels:  []
classes:  10
Epoch 0
Best Validation Accuracy: 0
Current Validation Accuracy: 0.7030493920835728
Current Validation Loss: 0.00040490018592763166
Saving best model based on accuracy
Epoch 1
Best Validation Accuracy: 0.7030493920835728
Current Validation Accuracy: 0.7137842772571388
Current Validation Loss: 0.00038860571853445707
Saving best model based on accuracy
Epoch 2
Best Validation Accuracy: 0.7137842772571388
Current Validation Accuracy: 0.7263560250093595
Current Validation Loss: 0.0003737386779577159
Saving best model based on accuracy
Epoch 3
Best Validation Accuracy: 0.7263560250093595
Current Validation Accuracy: 0.7317635081973121
Current Validation Loss: 0.00036710034768177907
Saving best model based on accuracy
Epoch 4
Best Validation Accuracy: 0.7317635081973121
Current Validation Accuracy: 0.7279551465185699
Current Validation Loss: 0.0003703409398794883
Epoch 5
Best Validation Accuracy: 0.7317635081973121
Current Validation Accuracy: 0.7307334637322245
Current Validation Loss: 0.0003667520596457986
Epoch 6
Best Validation Accuracy: 0.7317635081973121
Current Validation Accuracy: 0.7320362847927798
Current Validation Loss: 0.00036477274950780497
Saving best model based on accuracy
Epoch 7
Best Validation Accuracy: 0.7320362847927798
Current Validation Accuracy: 0.7339992752651189
Current Validation Loss: 0.000362304417664142
Saving best model based on accuracy
Epoch 8
Best Validation Accuracy: 0.7339992752651189
Current Validation Accuracy: 0.7388111545106738
Current Validation Loss: 0.00035662357776797027
Saving best model based on accuracy
Epoch 9
Best Validation Accuracy: 0.7388111545106738
Current Validation Accuracy: 0.7384863251336855
Current Validation Loss: 0.000356882606657185
Saving last model
