Running "module reset". Resetting modules to system default. The following $MODULEPATH directories have been removed: None
A conda environment has been detected CONDA_PREFIX=
/u/avroy/.conda/envs/toptagger_env 
anaconda3_gpu is loaded. Consider running conda deactivate and reloading it.

Currently Loaded Modules:
  1) cue-login-env/1.0   4) gcc/11.2.0    7) openmpi/4.1.2
  2) default             5) cuda/11.6.1   8) cudnn/8.4.1.50
  3) modtree/gpu         6) ucx/1.11.2    9) anaconda3_gpu/4.13.0

 

/u/avroy/UQ_XAI_Studies/models/PFIN_UQ/model/jobsub
total 192K
-rw-rw----+ 1 avroy delta_bbhj  925 Mar 31 16:58 jobsubmitter_dummy.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 18 13:59 jobsubmitter.py
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_9.slurm
-rw-------+ 1 avroy delta_bbhj  969 May 15 09:44 UQPFIN-run.slurm
/projects/bbhj/avroy/UQ_XAI_Studies/models/PFIN_UQ/model
total 132K
drwxr-s---+ 2 avroy delta_bbhj  12K May 18 18:12 jobouts
drwxr-s---+ 2 avroy delta_bbhj 4.0K May 18 14:02 jobsub
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 15 14:46 PFINDataset.py
drwxrws---+ 2 avroy delta_bbhj 4.0K May 18 09:47 __pycache__
drwxrws---+ 2 avroy delta_bbhj  12K May 18 18:11 trained_model_dicts
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:09 trained_model_dicts_old
drwxrws---+ 2 avroy delta_bbhj  20K May 18 18:12 trained_models
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:10 trained_models_old
-rw-rw----+ 1 avroy delta_bbhj  23K May 18 15:52 train_mod.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 18 13:50 train.py
-rw-rw----+ 1 avroy delta_bbhj  13K May  5 09:36 UQPFIN.py
job is starting on gpua018.delta.ncsa.illinois.edu
# conda environments:
#
base                     /sw/external/python/anaconda3
toptagger_env         *  /u/avroy/.conda/envs/toptagger_env

/sw/external/python/anaconda3_gpu/bin/python
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
UQPFIN                                   [1, 4]                    --
├─Sequential: 1-1                        [30, 64]                  --
│    └─Sequential: 2-1                   [30, 100]                 --
│    │    └─Linear: 3-1                  [30, 100]                 400
│    │    └─ReLU: 3-2                    [30, 100]                 --
│    └─Sequential: 2-2                   [30, 100]                 --
│    │    └─Linear: 3-3                  [30, 100]                 10,100
│    │    └─ReLU: 3-4                    [30, 100]                 --
│    └─Sequential: 2-3                   [30, 64]                  --
│    │    └─Linear: 3-5                  [30, 64]                  6,464
│    │    └─ReLU: 3-6                    [30, 64]                  --
├─Sequential: 1-2                        [435, 64]                 --
│    └─Sequential: 2-4                   [435, 128]                --
│    │    └─Linear: 3-7                  [435, 128]                640
│    │    └─ReLU: 3-8                    [435, 128]                --
│    └─Sequential: 2-5                   [435, 128]                --
│    │    └─Linear: 3-9                  [435, 128]                16,512
│    │    └─ReLU: 3-10                   [435, 128]                --
│    └─Sequential: 2-6                   [435, 64]                 --
│    │    └─Linear: 3-11                 [435, 64]                 8,256
│    │    └─ReLU: 3-12                   [435, 64]                 --
├─Sequential: 1-3                        [30, 64]                  --
│    └─Sequential: 2-7                   [30, 128]                 --
│    │    └─Linear: 3-13                 [30, 128]                 8,704
│    │    └─ReLU: 3-14                   [30, 128]                 --
│    └─Sequential: 2-8                   [30, 128]                 --
│    │    └─Linear: 3-15                 [30, 128]                 16,512
│    │    └─ReLU: 3-16                   [30, 128]                 --
│    └─Sequential: 2-9                   [30, 64]                  --
│    │    └─Linear: 3-17                 [30, 64]                  8,256
│    │    └─ReLU: 3-18                   [30, 64]                  --
├─Sequential: 1-4                        [1, 4]                    --
│    └─Sequential: 2-10                  [1, 64]                   --
│    │    └─Linear: 3-19                 [1, 64]                   4,160
│    │    └─ReLU: 3-20                   [1, 64]                   --
│    └─Sequential: 2-11                  [1, 100]                  --
│    │    └─Linear: 3-21                 [1, 100]                  6,500
│    │    └─ReLU: 3-22                   [1, 100]                  --
│    └─Sequential: 2-12                  [1, 100]                  --
│    │    └─Linear: 3-23                 [1, 100]                  10,100
│    │    └─ReLU: 3-24                   [1, 100]                  --
│    └─Linear: 2-13                      [1, 4]                    404
│    └─ReLU: 2-14                        [1, 4]                    --
==========================================================================================
Total params: 97,008
Trainable params: 97,008
Non-trainable params: 0
Total mult-adds (M): 12.59
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 1.26
Params size (MB): 0.39
Estimated Total Size (MB): 1.64
==========================================================================================
data type:  JNqgmerged
m_logic, pt_logic, eta_logic:  AND AND AND
m1, m2, pt1, pt2, eta1, eta2:  0.0 10000.0 0.0 10000.0 -6.0 6.0
skip labels:  []
classes:  4
Epoch 0
L = 0.0
Best Validation Accuracy: 0
Current Validation Accuracy: 0.7165810447982073
Current Validation Loss: 0.0017642175288181661
Saving best model based on accuracy
Epoch 1
L = 0.1
Best Validation Accuracy: 0.7165810447982073
Current Validation Accuracy: 0.7566154344869382
Current Validation Loss: 0.001872103108397552
Saving best model based on accuracy
Epoch 2
L = 0.2
Best Validation Accuracy: 0.7566154344869382
Current Validation Accuracy: 0.7520136994989535
Current Validation Loss: 0.0020648829264231622
Epoch 3
L = 0.3
Best Validation Accuracy: 0.7566154344869382
Current Validation Accuracy: 0.7849164570164127
Current Validation Loss: 0.0019754102686854887
Saving best model based on accuracy
Epoch 4
L = 0.4
Best Validation Accuracy: 0.7849164570164127
Current Validation Accuracy: 0.8034854795176987
Current Validation Loss: 0.0019457101965552391
Saving best model based on accuracy
Epoch 5
L = 0.5
Best Validation Accuracy: 0.8034854795176987
Current Validation Accuracy: 0.7925061485662741
Current Validation Loss: 0.002009191533466967
Epoch 6
L = 0.6
Best Validation Accuracy: 0.8034854795176987
Current Validation Accuracy: 0.7852194809130181
Current Validation Loss: 0.002132816927675443
Epoch 7
L = 0.7
Best Validation Accuracy: 0.8034854795176987
Current Validation Accuracy: 0.7988696503949881
Current Validation Loss: 0.0020531276856366088
Epoch 8
L = 0.8
Best Validation Accuracy: 0.8034854795176987
Current Validation Accuracy: 0.7980451435135268
Current Validation Loss: 0.002045749219254594
Epoch 9
L = 0.9
Best Validation Accuracy: 0.8034854795176987
Current Validation Accuracy: 0.8003847698780152
Current Validation Loss: 0.0020834053807202053
Epoch 10
L = 1.0
Best Validation Accuracy: 0.8034854795176987
Current Validation Accuracy: 0.784634574321896
Current Validation Loss: 0.002163688815789353
Epoch 11
L = 1.0
Best Validation Accuracy: 0.8034854795176987
Current Validation Accuracy: 0.8034291029787953
Current Validation Loss: 0.002204712037980415
Epoch 12
L = 1.0
Best Validation Accuracy: 0.8034854795176987
Current Validation Accuracy: 0.803288161631537
Current Validation Loss: 0.0020894277676119107
Epoch 13
L = 1.0
Best Validation Accuracy: 0.8034854795176987
Current Validation Accuracy: 0.8053459053015087
Current Validation Loss: 0.002094358039880299
Saving best model based on accuracy
Epoch 14
L = 1.0
Best Validation Accuracy: 0.8053459053015087
Current Validation Accuracy: 0.8123718314623369
Current Validation Loss: 0.002005112381990141
Saving best model based on accuracy
Epoch 15
L = 1.0
Best Validation Accuracy: 0.8123718314623369
Current Validation Accuracy: 0.8137107742612911
Current Validation Loss: 0.0020422316471717153
Saving best model based on accuracy
Epoch 16
L = 1.0
Best Validation Accuracy: 0.8137107742612911
Current Validation Accuracy: 0.8020690189777524
Current Validation Loss: 0.002057749990282728
Epoch 17
L = 1.0
Best Validation Accuracy: 0.8137107742612911
Current Validation Accuracy: 0.8130976794007174
Current Validation Loss: 0.002033149508347309
Epoch 18
L = 1.0
Best Validation Accuracy: 0.8137107742612911
Current Validation Accuracy: 0.8212440892722493
Current Validation Loss: 0.0019571657085538327
Saving best model based on accuracy
Epoch 19
L = 1.0
Best Validation Accuracy: 0.8212440892722493
Current Validation Accuracy: 0.8103634172639056
Current Validation Loss: 0.002079924452537793
Epoch 20
L = 1.0
Best Validation Accuracy: 0.8212440892722493
Current Validation Accuracy: 0.817459814098363
Current Validation Loss: 0.001970830260600506
Epoch 21
L = 1.0
Best Validation Accuracy: 0.8212440892722493
Current Validation Accuracy: 0.8039646800983771
Current Validation Loss: 0.002090993099506404
Epoch 22
L = 1.0
Best Validation Accuracy: 0.8212440892722493
Current Validation Accuracy: 0.8241051986215936
Current Validation Loss: 0.001963470337843751
Saving best model based on accuracy
Epoch 23
L = 1.0
Best Validation Accuracy: 0.8241051986215936
Current Validation Accuracy: 0.818136332565203
Current Validation Loss: 0.001954575072011738
Epoch 24
L = 1.0
Best Validation Accuracy: 0.8241051986215936
Current Validation Accuracy: 0.8005891348315398
Current Validation Loss: 0.0020950662534714054
Epoch 25
L = 1.0
Best Validation Accuracy: 0.8241051986215936
Current Validation Accuracy: 0.7972417778341543
Current Validation Loss: 0.0020334712922777647
Epoch 26
L = 1.0
Best Validation Accuracy: 0.8241051986215936
Current Validation Accuracy: 0.7955998111385947
Current Validation Loss: 0.002153982978999112
Epoch 27
L = 1.0
Best Validation Accuracy: 0.8241051986215936
Current Validation Accuracy: 0.8259515302706778
Current Validation Loss: 0.0019674472613251423
Saving best model based on accuracy
Epoch 28
L = 1.0
Best Validation Accuracy: 0.8259515302706778
Current Validation Accuracy: 0.8190172159855676
Current Validation Loss: 0.0019383493228325725
Epoch 29
L = 1.0
Best Validation Accuracy: 0.8259515302706778
Current Validation Accuracy: 0.8241686222278599
Current Validation Loss: 0.0019312032882288026
Epoch 30
L = 1.0
Best Validation Accuracy: 0.8259515302706778
Current Validation Accuracy: 0.8231115621234223
Current Validation Loss: 0.0019284228241473961
Epoch 31
L = 1.0
Best Validation Accuracy: 0.8259515302706778
Current Validation Accuracy: 0.8270297315772042
Current Validation Loss: 0.0019123203892886357
Saving best model based on accuracy
Epoch 32
L = 1.0
Best Validation Accuracy: 0.8270297315772042
Current Validation Accuracy: 0.8228085382268169
Current Validation Loss: 0.0019462656404548963
Epoch 33
L = 1.0
Best Validation Accuracy: 0.8270297315772042
Current Validation Accuracy: 0.8288760632262884
Current Validation Loss: 0.0018998911251597752
Saving best model based on accuracy
Epoch 34
L = 1.0
Best Validation Accuracy: 0.8288760632262884
Current Validation Accuracy: 0.811772830736489
Current Validation Loss: 0.002006309379878774
Epoch 35
L = 1.0
Best Validation Accuracy: 0.8288760632262884
Current Validation Accuracy: 0.8300317822738068
Current Validation Loss: 0.0018943955425103764
Saving best model based on accuracy
Epoch 36
L = 1.0
Best Validation Accuracy: 0.8300317822738068
Current Validation Accuracy: 0.8170228959218622
Current Validation Loss: 0.0019687178301202837
Epoch 37
L = 1.0
Best Validation Accuracy: 0.8300317822738068
Current Validation Accuracy: 0.8269099314320345
Current Validation Loss: 0.0019290137620936402
Epoch 38
L = 1.0
Best Validation Accuracy: 0.8300317822738068
Current Validation Accuracy: 0.8338794810539594
Current Validation Loss: 0.001886984127931771
Saving best model based on accuracy
Epoch 39
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8249015172336033
Current Validation Loss: 0.0018983231060725164
Epoch 40
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.820088370224731
Current Validation Loss: 0.0019261435031400266
Epoch 41
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8276146381683263
Current Validation Loss: 0.0019205019058494402
Epoch 42
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.809567098651896
Current Validation Loss: 0.002053614861818855
Epoch 43
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8252115881975716
Current Validation Loss: 0.0019537146459095195
Epoch 44
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8244716461244653
Current Validation Loss: 0.001996025830457084
Epoch 45
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8265928134007033
Current Validation Loss: 0.0018874299597789067
Epoch 46
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8275089321578825
Current Validation Loss: 0.0018999274225289355
Epoch 47
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8253666236795557
Current Validation Loss: 0.0019078796099217896
Epoch 48
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8305603123260256
Current Validation Loss: 0.0018960851052480757
Epoch 49
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8302220530926055
Current Validation Loss: 0.0018659685990965354
Epoch 50
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8280867916816417
Current Validation Loss: 0.0019069765302261793
Epoch 51
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8312932073317689
Current Validation Loss: 0.001866272199164233
Epoch 52
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8300317822738068
Current Validation Loss: 0.001898410136254957
Epoch 53
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8323361733014806
Current Validation Loss: 0.0018595084883501832
Epoch 54
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8236119039061894
Current Validation Loss: 0.0019214230639782838
Epoch 55
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8314482428137531
Current Validation Loss: 0.0018632641982167957
Epoch 56
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.7995743571312798
Current Validation Loss: 0.002033695544027013
Epoch 57
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.829672381838298
Current Validation Loss: 0.0018894060472016872
Epoch 58
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8326532913328119
Current Validation Loss: 0.0018687361428106962
Epoch 59
L = 1.0
Best Validation Accuracy: 0.8338794810539594
Current Validation Accuracy: 0.8343516345672748
Current Validation Loss: 0.0018657351966105955
Saving best model based on accuracy
Epoch 60
L = 1.0
Best Validation Accuracy: 0.8343516345672748
Current Validation Accuracy: 0.8345559995207994
Current Validation Loss: 0.0018665563896984436
Saving best model based on accuracy
Epoch 61
L = 1.0
Best Validation Accuracy: 0.8345559995207994
Current Validation Accuracy: 0.8057053057370175
Current Validation Loss: 0.0020208466794207993
Epoch 62
L = 1.0
Best Validation Accuracy: 0.8345559995207994
Current Validation Accuracy: 0.8280304151427383
Current Validation Loss: 0.0019287843012437936
Epoch 63
L = 1.0
Best Validation Accuracy: 0.8345559995207994
Current Validation Accuracy: 0.8338512927845078
Current Validation Loss: 0.0018522487364530178
Epoch 64
L = 1.0
Best Validation Accuracy: 0.8345559995207994
Current Validation Accuracy: 0.831793549114536
Current Validation Loss: 0.0018728872209554878
Epoch 65
L = 1.0
Best Validation Accuracy: 0.8345559995207994
Current Validation Accuracy: 0.8321247612805931
Current Validation Loss: 0.0018893288683792336
Epoch 66
L = 1.0
Best Validation Accuracy: 0.8345559995207994
Current Validation Accuracy: 0.832815373882159
Current Validation Loss: 0.001852064212102804
Epoch 67
L = 1.0
Best Validation Accuracy: 0.8345559995207994
Current Validation Accuracy: 0.8356905773662291
Current Validation Loss: 0.0018469247775283705
Saving best model based on accuracy
Epoch 68
L = 1.0
Best Validation Accuracy: 0.8356905773662291
Current Validation Accuracy: 0.829672381838298
Current Validation Loss: 0.0018940932687124962
Epoch 69
L = 1.0
Best Validation Accuracy: 0.8356905773662291
Current Validation Accuracy: 0.8310042775698893
Current Validation Loss: 0.0018690619082808505
Epoch 70
L = 1.0
Best Validation Accuracy: 0.8356905773662291
Current Validation Accuracy: 0.8326532913328119
Current Validation Loss: 0.0018529311332517954
Epoch 71
L = 1.0
Best Validation Accuracy: 0.8356905773662291
Current Validation Accuracy: 0.8325616794570939
Current Validation Loss: 0.0018673463042405396
Epoch 72
L = 1.0
Best Validation Accuracy: 0.8356905773662291
Current Validation Accuracy: 0.8352254709202765
Current Validation Loss: 0.0018371606783246133
Epoch 73
L = 1.0
Best Validation Accuracy: 0.8356905773662291
Current Validation Accuracy: 0.8309056186268085
Current Validation Loss: 0.0018802672935626112
Epoch 74
L = 1.0
Best Validation Accuracy: 0.8356905773662291
Current Validation Accuracy: 0.8360076953975603
Current Validation Loss: 0.001846738265348573
Saving best model based on accuracy
Epoch 75
L = 1.0
Best Validation Accuracy: 0.8360076953975603
Current Validation Accuracy: 0.8289253926978288
Current Validation Loss: 0.0019277613633000045
Epoch 76
L = 1.0
Best Validation Accuracy: 0.8360076953975603
Current Validation Accuracy: 0.8356201066925999
Current Validation Loss: 0.0018666649218334037
Epoch 77
L = 1.0
Best Validation Accuracy: 0.8360076953975603
Current Validation Accuracy: 0.8294539227500476
Current Validation Loss: 0.0018949177882908643
Epoch 78
L = 1.0
Best Validation Accuracy: 0.8360076953975603
Current Validation Accuracy: 0.834929494091034
Current Validation Loss: 0.001873596217287308
Epoch 79
L = 1.0
Best Validation Accuracy: 0.8360076953975603
Current Validation Accuracy: 0.8328294680168847
Current Validation Loss: 0.0018573085965185676
Epoch 80
L = 1.0
Best Validation Accuracy: 0.8360076953975603
Current Validation Accuracy: 0.8371493203103528
Current Validation Loss: 0.0018394794713479457
Saving best model based on accuracy
Epoch 81
L = 1.0
Best Validation Accuracy: 0.8371493203103528
Current Validation Accuracy: 0.8320754318090526
Current Validation Loss: 0.0018514740617277103
Epoch 82
L = 1.0
Best Validation Accuracy: 0.8371493203103528
Current Validation Accuracy: 0.8348660704847678
Current Validation Loss: 0.001853796489969454
Epoch 83
L = 1.0
Best Validation Accuracy: 0.8371493203103528
Current Validation Accuracy: 0.8320683847416898
Current Validation Loss: 0.0018635521949248617
Epoch 84
L = 1.0
Best Validation Accuracy: 0.8371493203103528
Current Validation Accuracy: 0.8341965990852906
Current Validation Loss: 0.0018735790257641994
Epoch 85
L = 1.0
Best Validation Accuracy: 0.8371493203103528
Current Validation Accuracy: 0.8353241298633574
Current Validation Loss: 0.0018551862084087575
Epoch 86
L = 1.0
Best Validation Accuracy: 0.8371493203103528
Current Validation Accuracy: 0.831701937238818
Current Validation Loss: 0.0018827163500141422
Epoch 87
L = 1.0
Best Validation Accuracy: 0.8371493203103528
Current Validation Accuracy: 0.8305532652586626
Current Validation Loss: 0.0018718159122818126
Epoch 88
L = 1.0
Best Validation Accuracy: 0.8371493203103528
Current Validation Accuracy: 0.8263814013798157
Current Validation Loss: 0.0019139712551904033
Epoch 89
L = 1.0
Best Validation Accuracy: 0.8371493203103528
Current Validation Accuracy: 0.8362895780920769
Current Validation Loss: 0.0018368868744887531
Epoch 90
L = 1.0
Best Validation Accuracy: 0.8371493203103528
Current Validation Accuracy: 0.832977456431506
Current Validation Loss: 0.0018905069263368034
Epoch 91
L = 1.0
Best Validation Accuracy: 0.8371493203103528
Current Validation Accuracy: 0.8377624151709266
Current Validation Loss: 0.0018585813656824936
Saving best model based on accuracy
Epoch 92
L = 1.0
Best Validation Accuracy: 0.8377624151709266
Current Validation Accuracy: 0.8337808221108786
Current Validation Loss: 0.0018667369058365493
Epoch 93
L = 1.0
Best Validation Accuracy: 0.8377624151709266
Current Validation Accuracy: 0.830010641071718
Current Validation Loss: 0.0018771368912472457
Epoch 94
L = 1.0
Best Validation Accuracy: 0.8377624151709266
Current Validation Accuracy: 0.8326532913328119
Current Validation Loss: 0.0018889785445504394
Epoch 95
L = 1.0
Best Validation Accuracy: 0.8377624151709266
Current Validation Accuracy: 0.8285378039928684
Current Validation Loss: 0.0018804182497402248
Epoch 96
L = 1.0
Best Validation Accuracy: 0.8377624151709266
Current Validation Accuracy: 0.8268183195563167
Current Validation Loss: 0.0018897016963710883
Epoch 97
L = 1.0
Best Validation Accuracy: 0.8377624151709266
Current Validation Accuracy: 0.837980874259177
Current Validation Loss: 0.0018393343707093306
Saving best model based on accuracy
Epoch 98
L = 1.0
Best Validation Accuracy: 0.837980874259177
Current Validation Accuracy: 0.8308985715594456
Current Validation Loss: 0.0018823941099224762
Epoch 99
L = 1.0
[[ 3.606373    0.          0.          0.        ]
 [ 0.         26.004475    0.          0.        ]
 [12.254281    0.          0.          0.        ]
 [ 0.          1.6668407   0.          0.        ]
 [ 0.          0.          0.          8.969604  ]
 [ 0.          0.          0.          0.0861925 ]
 [ 4.9035535   0.          0.          0.        ]
 [ 0.          2.7876036   0.          0.        ]
 [17.486143    0.          0.          0.        ]
 [ 0.          0.          0.6510006   0.        ]
 [ 0.          0.         19.869438    0.        ]
 [ 0.          0.          4.0743175   0.        ]
 [ 0.         12.120437    0.          0.        ]
 [ 0.          0.          0.         27.455439  ]
 [ 0.          0.          0.1082593   0.        ]
 [ 0.          0.          0.16099313  0.        ]
 [ 5.3523936   0.          0.          0.        ]
 [ 0.          0.          9.755663    0.        ]
 [ 0.          0.          0.          2.9997554 ]
 [ 0.          0.          0.          0.        ]]
[[0.60559386 0.13146871 0.13146871 0.13146871]
 [0.03332836 0.90001494 0.03332836 0.03332836]
 [0.81543326 0.06152226 0.06152226 0.06152226]
 [0.17646517 0.47060448 0.17646517 0.17646517]
 [0.07710336 0.07710336 0.07710336 0.76868993]
 [0.2447266  0.2447266  0.2447266  0.26582018]
 [0.6630559  0.11231472 0.11231472 0.11231472]
 [0.14732741 0.5580178  0.14732741 0.14732741]
 [0.8603751  0.04654162 0.04654162 0.04654162]
 [0.2150075  0.2150075  0.35497752 0.2150075 ]
 [0.04189458 0.04189458 0.8743163  0.04189458]
 [0.12384947 0.12384947 0.6284515  0.12384947]
 [0.06203306 0.81390077 0.06203306 0.06203306]
 [0.03179101 0.03179101 0.03179101 0.90462697]
 [0.2434121  0.2434121  0.26976374 0.2434121 ]
 [0.24032724 0.24032724 0.27901828 0.24032724]
 [0.67922646 0.1069245  0.1069245  0.1069245 ]
 [0.07269733 0.07269733 0.781908   0.07269733]
 [0.14286214 0.14286214 0.14286214 0.5714136 ]
 [0.25       0.25       0.25       0.25      ]]
[[1. 0. 0. 0.]
 [0. 1. 0. 0.]
 [1. 0. 0. 0.]
 [0. 1. 0. 0.]
 [0. 0. 0. 1.]
 [0. 0. 1. 0.]
 [1. 0. 0. 0.]
 [0. 1. 0. 0.]
 [1. 0. 0. 0.]
 [0. 0. 1. 0.]
 [0. 0. 1. 0.]
 [0. 0. 1. 0.]
 [0. 1. 0. 0.]
 [0. 0. 0. 1.]
 [0. 0. 1. 0.]
 [0. 0. 0. 1.]
 [1. 0. 0. 0.]
 [0. 0. 1. 0.]
 [0. 0. 0. 1.]
 [0. 0. 1. 0.]]
Best Validation Accuracy: 0.837980874259177
Current Validation Accuracy: 0.831969725798609
Current Validation Loss: 0.0018952004601778779
Saving last model
