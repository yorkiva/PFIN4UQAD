Running "module reset". Resetting modules to system default. The following $MODULEPATH directories have been removed: None
A conda environment has been detected CONDA_PREFIX=
/sw/external/python/anaconda3 
anaconda3_gpu is loaded. Consider running conda deactivate and reloading it.

Currently Loaded Modules:
  1) cue-login-env/1.0   4) gcc/11.2.0    7) openmpi/4.1.2
  2) default             5) cuda/11.6.1   8) cudnn/8.4.1.50
  3) modtree/gpu         6) ucx/1.11.2    9) anaconda3_gpu/4.13.0

 

/u/avroy/UQ_XAI_Studies/models/PFIN_UQ/model/jobsub
total 508K
-rw-rw----+ 1 avroy delta_bbhj  925 Mar 31 16:58 jobsubmitter_dummy.py
-rw-rw----+ 1 avroy delta_bbhj 5.2K May 27 21:16 jobsubmitter_jetclass_1gpu.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 27 21:04 jobsubmitter_jetclass_1gpu.py~
-rw-rw----+ 1 avroy delta_bbhj  743 May 19 01:04 jobsubmitter_jetclass.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 18 13:59 jobsubmitter.py
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 19 13:52 UQPFIN-jetclass-run-jetclass20M_0_baseline.slurm
-rw-------+ 1 avroy delta_bbhj  973 May 19 00:59 UQPFIN-jetclass-run.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_9.slurm
-rw-------+ 1 avroy delta_bbhj  969 May 15 09:44 UQPFIN-run.slurm
/projects/bbhj/avroy/UQ_XAI_Studies/models/PFIN_UQ/model
total 184K
drwxr-s---+ 2 avroy delta_bbhj  12K May 28 01:44 jobouts
drwxr-s---+ 2 avroy delta_bbhj  16K May 27 21:18 jobsub
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 18 21:37 PFINDataset.py
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 15 14:46 PFINDataset.py~
drwxrws---+ 2 avroy delta_bbhj 4.0K May 18 21:38 __pycache__
drwxrws---+ 2 avroy delta_bbhj  16K May 27 23:34 trained_model_dicts
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:09 trained_model_dicts_old
drwxrws---+ 2 avroy delta_bbhj  24K May 27 23:53 trained_models
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:10 trained_models_old
-rw-rw----+ 1 avroy delta_bbhj  23K May 18 15:52 train_mod.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 27 21:06 train.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 18 13:50 train.py~
-rw-rw----+ 1 avroy delta_bbhj  13K May  5 09:36 UQPFIN.py
job is starting on gpua012.delta.ncsa.illinois.edu
# conda environments:
#
base                     /sw/external/python/anaconda3
toptagger_env         *  /u/avroy/.conda/envs/toptagger_env

/sw/external/python/anaconda3_gpu/bin/python
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
UQPFIN                                   [1, 8]                    --
├─Sequential: 1-1                        [60, 64]                  --
│    └─Sequential: 2-1                   [60, 100]                 --
│    │    └─Linear: 3-1                  [60, 100]                 1,200
│    │    └─ReLU: 3-2                    [60, 100]                 --
│    └─Sequential: 2-2                   [60, 100]                 --
│    │    └─Linear: 3-3                  [60, 100]                 10,100
│    │    └─ReLU: 3-4                    [60, 100]                 --
│    └─Sequential: 2-3                   [60, 64]                  --
│    │    └─Linear: 3-5                  [60, 64]                  6,464
│    │    └─ReLU: 3-6                    [60, 64]                  --
├─Sequential: 1-2                        [1770, 64]                --
│    └─Sequential: 2-4                   [1770, 128]               --
│    │    └─Linear: 3-7                  [1770, 128]               640
│    │    └─ReLU: 3-8                    [1770, 128]               --
│    └─Sequential: 2-5                   [1770, 128]               --
│    │    └─Linear: 3-9                  [1770, 128]               16,512
│    │    └─ReLU: 3-10                   [1770, 128]               --
│    └─Sequential: 2-6                   [1770, 64]                --
│    │    └─Linear: 3-11                 [1770, 64]                8,256
│    │    └─ReLU: 3-12                   [1770, 64]                --
├─Sequential: 1-3                        [60, 64]                  --
│    └─Sequential: 2-7                   [60, 128]                 --
│    │    └─Linear: 3-13                 [60, 128]                 9,728
│    │    └─ReLU: 3-14                   [60, 128]                 --
│    └─Sequential: 2-8                   [60, 128]                 --
│    │    └─Linear: 3-15                 [60, 128]                 16,512
│    │    └─ReLU: 3-16                   [60, 128]                 --
│    └─Sequential: 2-9                   [60, 64]                  --
│    │    └─Linear: 3-17                 [60, 64]                  8,256
│    │    └─ReLU: 3-18                   [60, 64]                  --
├─Sequential: 1-4                        [1, 8]                    --
│    └─Sequential: 2-10                  [1, 64]                   --
│    │    └─Linear: 3-19                 [1, 64]                   4,160
│    │    └─ReLU: 3-20                   [1, 64]                   --
│    └─Sequential: 2-11                  [1, 100]                  --
│    │    └─Linear: 3-21                 [1, 100]                  6,500
│    │    └─ReLU: 3-22                   [1, 100]                  --
│    └─Sequential: 2-12                  [1, 100]                  --
│    │    └─Linear: 3-23                 [1, 100]                  10,100
│    │    └─ReLU: 3-24                   [1, 100]                  --
│    └─Linear: 2-13                      [1, 8]                    808
│    └─Softmax: 2-14                     [1, 8]                    --
==========================================================================================
Total params: 99,236
Trainable params: 99,236
Non-trainable params: 0
Total mult-adds (M): 48.13
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 4.81
Params size (MB): 0.40
Estimated Total Size (MB): 5.21
==========================================================================================
data type:  jetclass
m_logic, pt_logic, eta_logic:  AND AND AND
m1, m2, pt1, pt2, eta1, eta2:  0.0 10000.0 0.0 10000.0 -6.0 6.0
skip labels:  [8, 9]
classes:  8
Epoch 0
Best Validation Accuracy: 0
Current Validation Accuracy: 0.6670558373412493
Current Validation Loss: 0.0004433932855352379
Saving best model based on accuracy
Epoch 1
Best Validation Accuracy: 0.6670558373412493
Current Validation Accuracy: 0.6924634503701081
Current Validation Loss: 0.0004156460249603347
Saving best model based on accuracy
Epoch 2
Best Validation Accuracy: 0.6924634503701081
Current Validation Accuracy: 0.69733923572049
Current Validation Loss: 0.0004092475663645729
Saving best model based on accuracy
Epoch 3
Best Validation Accuracy: 0.69733923572049
Current Validation Accuracy: 0.702749687798405
Current Validation Loss: 0.0004035351970838425
Saving best model based on accuracy
Epoch 4
Best Validation Accuracy: 0.702749687798405
Current Validation Accuracy: 0.7056656538223668
Current Validation Loss: 0.0004003420880147286
Saving best model based on accuracy
Epoch 5
Best Validation Accuracy: 0.7056656538223668
Current Validation Accuracy: 0.7064185646293258
Current Validation Loss: 0.00039958372693060736
Saving best model based on accuracy
Epoch 6
Best Validation Accuracy: 0.7064185646293258
Current Validation Accuracy: 0.7068450473289488
Current Validation Loss: 0.00039862899252597665
Saving best model based on accuracy
Epoch 7
Best Validation Accuracy: 0.7068450473289488
Current Validation Accuracy: 0.7058632616421335
Current Validation Loss: 0.0003992229059752871
Epoch 8
Best Validation Accuracy: 0.7068450473289488
Current Validation Accuracy: 0.7108147132779322
Current Validation Loss: 0.0003940104616432022
Saving best model based on accuracy
Epoch 9
Best Validation Accuracy: 0.7108147132779322
Current Validation Accuracy: 0.7065698972001598
Current Validation Loss: 0.00039876406571656063
Epoch 10
Best Validation Accuracy: 0.7108147132779322
Current Validation Accuracy: 0.7128233092180921
Current Validation Loss: 0.0003918762763079411
Saving best model based on accuracy
Epoch 11
Best Validation Accuracy: 0.7128233092180921
Current Validation Accuracy: 0.7295943349089847
Current Validation Loss: 0.0003713673271652523
Saving best model based on accuracy
Epoch 12
Best Validation Accuracy: 0.7295943349089847
Current Validation Accuracy: 0.7434300089986599
Current Validation Loss: 0.00035312412063820734
Saving best model based on accuracy
Epoch 13
Best Validation Accuracy: 0.7434300089986599
Current Validation Accuracy: 0.7454279741383892
Current Validation Loss: 0.00035045544419499335
Saving best model based on accuracy
Epoch 14
Best Validation Accuracy: 0.7454279741383892
Current Validation Accuracy: 0.7354293936629174
Current Validation Loss: 0.00036417698411950287
Epoch 15
Best Validation Accuracy: 0.7454279741383892
Current Validation Accuracy: 0.7325465707226505
Current Validation Loss: 0.0003679361577874216
Epoch 16
Best Validation Accuracy: 0.7454279741383892
Current Validation Accuracy: 0.748646605304019
Current Validation Loss: 0.00034618200287287484
Saving best model based on accuracy
Epoch 17
Best Validation Accuracy: 0.748646605304019
Current Validation Accuracy: 0.7516526204610391
Current Validation Loss: 0.00034114188577585153
Saving best model based on accuracy
Epoch 18
Best Validation Accuracy: 0.7516526204610391
Current Validation Accuracy: 0.7350072883517069
Current Validation Loss: 0.00036581595386819756
Epoch 19
Best Validation Accuracy: 0.7516526204610391
Current Validation Accuracy: 0.7607357014170857
Current Validation Loss: 0.00032976654898058067
Saving best model based on accuracy
Epoch 20
Best Validation Accuracy: 0.7607357014170857
Current Validation Accuracy: 0.7429191052367948
Current Validation Loss: 0.0003523942556544077
Epoch 21
Best Validation Accuracy: 0.7607357014170857
Current Validation Accuracy: 0.7210659315989286
Current Validation Loss: 0.00038191190914927005
Epoch 22
Best Validation Accuracy: 0.7607357014170857
Current Validation Accuracy: 0.7385060723757401
Current Validation Loss: 0.0003620937838058556
Epoch 23
Best Validation Accuracy: 0.7607357014170857
Current Validation Accuracy: 0.7674068413578159
Current Validation Loss: 0.0003202615427505284
Saving best model based on accuracy
Epoch 24
Best Validation Accuracy: 0.7674068413578159
Current Validation Accuracy: 0.7669547196689194
Current Validation Loss: 0.0003209689168375541
Epoch 25
Best Validation Accuracy: 0.7674068413578159
Current Validation Accuracy: 0.7706342273002708
Current Validation Loss: 0.0003157728815276403
Saving best model based on accuracy
Epoch 26
Best Validation Accuracy: 0.7706342273002708
Current Validation Accuracy: 0.7702640253088091
Current Validation Loss: 0.0003163503772701147
Epoch 27
Best Validation Accuracy: 0.7706342273002708
Current Validation Accuracy: 0.7707117696092931
Current Validation Loss: 0.0003157017165501448
Saving best model based on accuracy
Epoch 28
Best Validation Accuracy: 0.7707117696092931
Current Validation Accuracy: 0.7697837632658319
Current Validation Loss: 0.00031698186304010074
Epoch 29
[[9.65459228e-01 1.57443050e-04 2.32460955e-03 2.68224673e-03
  4.50971347e-05 9.08405273e-05 1.51890218e-02 1.40515091e-02]
 [1.92944668e-02 2.72147940e-03 3.79098803e-01 5.28249681e-01
  6.26093373e-02 8.09639823e-06 6.27104472e-03 1.74706685e-03]
 [1.19455450e-03 4.66710515e-03 1.30997049e-02 4.91008221e-04
  1.19547755e-03 9.57520604e-01 1.97889432e-02 2.04261974e-03]
 [1.04793623e-01 1.47363739e-04 2.75202934e-03 3.09333261e-02
  1.98496296e-03 3.57522513e-04 3.81416947e-01 4.77614105e-01]
 [9.39858146e-03 2.38550439e-01 1.36947356e-05 4.23912163e-04
  1.86650780e-07 6.15709972e-09 7.51560330e-01 5.28327400e-05]
 [2.79798085e-04 1.25139095e-05 2.38552084e-03 3.46126361e-03
  9.93422210e-01 4.81311736e-06 1.96987618e-04 2.36911874e-04]
 [9.91871893e-01 2.08143206e-06 1.16453171e-04 9.17728685e-05
  1.95493476e-06 5.50633849e-05 3.45843052e-03 4.40226309e-03]
 [2.47402990e-04 1.53369198e-04 2.43643336e-02 5.68921305e-03
  9.67789531e-01 5.04525451e-06 5.05580276e-04 1.24567642e-03]
 [4.81976382e-03 1.86211822e-04 3.06293741e-03 1.15035824e-03
  3.43712675e-03 1.34163455e-03 3.42978984e-01 6.43022954e-01]
 [9.78980184e-01 2.19327558e-05 5.77744562e-04 6.17992308e-04
  1.12653315e-05 3.99856035e-05 1.00965481e-02 9.65435337e-03]
 [1.91980135e-02 1.66223291e-03 1.17019974e-01 2.09718406e-01
  6.31841600e-01 1.64967387e-05 1.07061965e-02 9.83711611e-03]
 [3.37594608e-03 3.70799601e-01 2.72358675e-03 5.21655753e-03
  1.26503481e-04 3.19899527e-06 6.17506802e-01 2.47763644e-04]
 [9.65719223e-01 8.86228736e-06 5.15484111e-03 1.13145128e-04
  7.97525627e-06 9.62996855e-05 1.61708705e-02 1.27288224e-02]
 [2.22266447e-02 2.27850556e-04 3.27631198e-02 1.27137944e-01
  8.05361688e-01 2.19124795e-05 6.64410042e-03 5.61664486e-03]
 [3.48046342e-05 2.82938363e-05 1.31299224e-04 8.36931868e-05
  1.94428139e-04 9.99422669e-01 9.16682166e-06 9.57310476e-05]
 [2.10823864e-01 4.87912948e-05 2.06203363e-03 7.49190226e-02
  5.13577044e-01 7.85392127e-04 1.19651616e-01 7.81322643e-02]
 [1.19313881e-07 3.73345124e-08 1.23729410e-06 9.09851039e-08
  1.38812609e-07 9.99998212e-01 7.81123219e-08 1.33190468e-07]
 [1.71933901e-02 2.29086936e-03 6.34773672e-02 1.36603592e-02
  6.03420138e-01 1.87954676e-04 1.83760449e-01 1.16009481e-01]
 [1.48477793e-01 3.26562033e-04 1.71261773e-01 9.22569856e-02
  5.62043726e-01 3.83080223e-05 1.98378358e-02 5.75701473e-03]
 [1.59550399e-01 2.16037169e-01 3.66996508e-03 3.53503996e-03
  5.72873905e-05 5.59950013e-06 6.05886281e-01 1.12583358e-02]]
[[9.65459228e-01 1.57443050e-04 2.32460955e-03 2.68224673e-03
  4.50971347e-05 9.08405273e-05 1.51890218e-02 1.40515091e-02]
 [1.92944668e-02 2.72147940e-03 3.79098803e-01 5.28249681e-01
  6.26093373e-02 8.09639823e-06 6.27104472e-03 1.74706685e-03]
 [1.19455450e-03 4.66710515e-03 1.30997049e-02 4.91008221e-04
  1.19547755e-03 9.57520604e-01 1.97889432e-02 2.04261974e-03]
 [1.04793623e-01 1.47363739e-04 2.75202934e-03 3.09333261e-02
  1.98496296e-03 3.57522513e-04 3.81416947e-01 4.77614105e-01]
 [9.39858146e-03 2.38550439e-01 1.36947356e-05 4.23912163e-04
  1.86650780e-07 6.15709972e-09 7.51560330e-01 5.28327400e-05]
 [2.79798085e-04 1.25139095e-05 2.38552084e-03 3.46126361e-03
  9.93422210e-01 4.81311736e-06 1.96987618e-04 2.36911874e-04]
 [9.91871893e-01 2.08143206e-06 1.16453171e-04 9.17728685e-05
  1.95493476e-06 5.50633849e-05 3.45843052e-03 4.40226309e-03]
 [2.47402990e-04 1.53369198e-04 2.43643336e-02 5.68921305e-03
  9.67789531e-01 5.04525451e-06 5.05580276e-04 1.24567642e-03]
 [4.81976382e-03 1.86211822e-04 3.06293741e-03 1.15035824e-03
  3.43712675e-03 1.34163455e-03 3.42978984e-01 6.43022954e-01]
 [9.78980184e-01 2.19327558e-05 5.77744562e-04 6.17992308e-04
  1.12653315e-05 3.99856035e-05 1.00965481e-02 9.65435337e-03]
 [1.91980135e-02 1.66223291e-03 1.17019974e-01 2.09718406e-01
  6.31841600e-01 1.64967387e-05 1.07061965e-02 9.83711611e-03]
 [3.37594608e-03 3.70799601e-01 2.72358675e-03 5.21655753e-03
  1.26503481e-04 3.19899527e-06 6.17506802e-01 2.47763644e-04]
 [9.65719223e-01 8.86228736e-06 5.15484111e-03 1.13145128e-04
  7.97525627e-06 9.62996855e-05 1.61708705e-02 1.27288224e-02]
 [2.22266447e-02 2.27850556e-04 3.27631198e-02 1.27137944e-01
  8.05361688e-01 2.19124795e-05 6.64410042e-03 5.61664486e-03]
 [3.48046342e-05 2.82938363e-05 1.31299224e-04 8.36931868e-05
  1.94428139e-04 9.99422669e-01 9.16682166e-06 9.57310476e-05]
 [2.10823864e-01 4.87912948e-05 2.06203363e-03 7.49190226e-02
  5.13577044e-01 7.85392127e-04 1.19651616e-01 7.81322643e-02]
 [1.19313881e-07 3.73345124e-08 1.23729410e-06 9.09851039e-08
  1.38812609e-07 9.99998212e-01 7.81123219e-08 1.33190468e-07]
 [1.71933901e-02 2.29086936e-03 6.34773672e-02 1.36603592e-02
  6.03420138e-01 1.87954676e-04 1.83760449e-01 1.16009481e-01]
 [1.48477793e-01 3.26562033e-04 1.71261773e-01 9.22569856e-02
  5.62043726e-01 3.83080223e-05 1.98378358e-02 5.75701473e-03]
 [1.59550399e-01 2.16037169e-01 3.66996508e-03 3.53503996e-03
  5.72873905e-05 5.59950013e-06 6.05886281e-01 1.12583358e-02]]
[[1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0.]]
Best Validation Accuracy: 0.7707117696092931
Current Validation Accuracy: 0.7708987466286292
Current Validation Loss: 0.0003153844923520399
Saving best model based on accuracy
Saving last model
