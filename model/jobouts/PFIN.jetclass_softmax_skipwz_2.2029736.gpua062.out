Running "module reset". Resetting modules to system default. The following $MODULEPATH directories have been removed: None
A conda environment has been detected CONDA_PREFIX=
/sw/external/python/anaconda3 
anaconda3_gpu is loaded. Consider running conda deactivate and reloading it.

Currently Loaded Modules:
  1) cue-login-env/1.0   4) gcc/11.2.0    7) openmpi/4.1.2
  2) default             5) cuda/11.6.1   8) cudnn/8.4.1.50
  3) modtree/gpu         6) ucx/1.11.2    9) anaconda3_gpu/4.13.0

 

/u/avroy/UQ_XAI_Studies/models/PFIN_UQ/model/jobsub
total 508K
-rw-rw----+ 1 avroy delta_bbhj  925 Mar 31 16:58 jobsubmitter_dummy.py
-rw-rw----+ 1 avroy delta_bbhj 5.2K May 27 21:16 jobsubmitter_jetclass_1gpu.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 27 21:04 jobsubmitter_jetclass_1gpu.py~
-rw-rw----+ 1 avroy delta_bbhj  743 May 19 01:04 jobsubmitter_jetclass.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 18 13:59 jobsubmitter.py
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 19 13:52 UQPFIN-jetclass-run-jetclass20M_0_baseline.slurm
-rw-------+ 1 avroy delta_bbhj  973 May 19 00:59 UQPFIN-jetclass-run.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_9.slurm
-rw-------+ 1 avroy delta_bbhj  969 May 15 09:44 UQPFIN-run.slurm
/projects/bbhj/avroy/UQ_XAI_Studies/models/PFIN_UQ/model
total 200K
drwxr-s---+ 2 avroy delta_bbhj  12K May 28 09:25 jobouts
drwxr-s---+ 2 avroy delta_bbhj  16K May 27 21:18 jobsub
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 18 21:37 PFINDataset.py
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 15 14:46 PFINDataset.py~
drwxrws---+ 2 avroy delta_bbhj 4.0K May 18 21:38 __pycache__
drwxrws---+ 2 avroy delta_bbhj  20K May 28 08:46 trained_model_dicts
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:09 trained_model_dicts_old
drwxrws---+ 2 avroy delta_bbhj  36K May 28 09:25 trained_models
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:10 trained_models_old
-rw-rw----+ 1 avroy delta_bbhj  23K May 18 15:52 train_mod.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 27 21:06 train.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 18 13:50 train.py~
-rw-rw----+ 1 avroy delta_bbhj  13K May  5 09:36 UQPFIN.py
job is starting on gpua062.delta.ncsa.illinois.edu
# conda environments:
#
base                     /sw/external/python/anaconda3
toptagger_env         *  /u/avroy/.conda/envs/toptagger_env

/sw/external/python/anaconda3_gpu/bin/python
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
UQPFIN                                   [1, 8]                    --
├─Sequential: 1-1                        [60, 64]                  --
│    └─Sequential: 2-1                   [60, 100]                 --
│    │    └─Linear: 3-1                  [60, 100]                 1,200
│    │    └─ReLU: 3-2                    [60, 100]                 --
│    └─Sequential: 2-2                   [60, 100]                 --
│    │    └─Linear: 3-3                  [60, 100]                 10,100
│    │    └─ReLU: 3-4                    [60, 100]                 --
│    └─Sequential: 2-3                   [60, 64]                  --
│    │    └─Linear: 3-5                  [60, 64]                  6,464
│    │    └─ReLU: 3-6                    [60, 64]                  --
├─Sequential: 1-2                        [1770, 64]                --
│    └─Sequential: 2-4                   [1770, 128]               --
│    │    └─Linear: 3-7                  [1770, 128]               640
│    │    └─ReLU: 3-8                    [1770, 128]               --
│    └─Sequential: 2-5                   [1770, 128]               --
│    │    └─Linear: 3-9                  [1770, 128]               16,512
│    │    └─ReLU: 3-10                   [1770, 128]               --
│    └─Sequential: 2-6                   [1770, 64]                --
│    │    └─Linear: 3-11                 [1770, 64]                8,256
│    │    └─ReLU: 3-12                   [1770, 64]                --
├─Sequential: 1-3                        [60, 64]                  --
│    └─Sequential: 2-7                   [60, 128]                 --
│    │    └─Linear: 3-13                 [60, 128]                 9,728
│    │    └─ReLU: 3-14                   [60, 128]                 --
│    └─Sequential: 2-8                   [60, 128]                 --
│    │    └─Linear: 3-15                 [60, 128]                 16,512
│    │    └─ReLU: 3-16                   [60, 128]                 --
│    └─Sequential: 2-9                   [60, 64]                  --
│    │    └─Linear: 3-17                 [60, 64]                  8,256
│    │    └─ReLU: 3-18                   [60, 64]                  --
├─Sequential: 1-4                        [1, 8]                    --
│    └─Sequential: 2-10                  [1, 64]                   --
│    │    └─Linear: 3-19                 [1, 64]                   4,160
│    │    └─ReLU: 3-20                   [1, 64]                   --
│    └─Sequential: 2-11                  [1, 100]                  --
│    │    └─Linear: 3-21                 [1, 100]                  6,500
│    │    └─ReLU: 3-22                   [1, 100]                  --
│    └─Sequential: 2-12                  [1, 100]                  --
│    │    └─Linear: 3-23                 [1, 100]                  10,100
│    │    └─ReLU: 3-24                   [1, 100]                  --
│    └─Linear: 2-13                      [1, 8]                    808
│    └─Softmax: 2-14                     [1, 8]                    --
==========================================================================================
Total params: 99,236
Trainable params: 99,236
Non-trainable params: 0
Total mult-adds (M): 48.13
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 4.81
Params size (MB): 0.40
Estimated Total Size (MB): 5.21
==========================================================================================
data type:  jetclass
m_logic, pt_logic, eta_logic:  AND AND AND
m1, m2, pt1, pt2, eta1, eta2:  0.0 10000.0 0.0 10000.0 -6.0 6.0
skip labels:  [6, 7]
classes:  8
Epoch 0
Best Validation Accuracy: 0
Current Validation Accuracy: 0.7651612112587465
Current Validation Loss: 0.00032208532695358124
Saving best model based on accuracy
Epoch 1
Best Validation Accuracy: 0.7651612112587465
Current Validation Accuracy: 0.7736283428194135
Current Validation Loss: 0.00031040884535020864
Saving best model based on accuracy
Epoch 2
Best Validation Accuracy: 0.7736283428194135
Current Validation Accuracy: 0.7760030412145851
Current Validation Loss: 0.00030757183634663244
Saving best model based on accuracy
Epoch 3
Best Validation Accuracy: 0.7760030412145851
Current Validation Accuracy: 0.7791155342664977
Current Validation Loss: 0.0003033739977973104
Saving best model based on accuracy
Epoch 4
Best Validation Accuracy: 0.7791155342664977
Current Validation Accuracy: 0.7794863073439955
Current Validation Loss: 0.0003039606913722161
Saving best model based on accuracy
Epoch 5
Best Validation Accuracy: 0.7794863073439955
Current Validation Accuracy: 0.7803572801887754
Current Validation Loss: 0.00030216670635298693
Saving best model based on accuracy
Epoch 6
Best Validation Accuracy: 0.7803572801887754
Current Validation Accuracy: 0.7829633209763149
Current Validation Loss: 0.00029823796496399144
Saving best model based on accuracy
Epoch 7
Best Validation Accuracy: 0.7829633209763149
Current Validation Accuracy: 0.8043662437686051
Current Validation Loss: 0.00027315813825812377
Saving best model based on accuracy
Epoch 8
Best Validation Accuracy: 0.8043662437686051
Current Validation Accuracy: 0.8258154350393688
Current Validation Loss: 0.0002458012549772061
Saving best model based on accuracy
Epoch 9
Best Validation Accuracy: 0.8258154350393688
Current Validation Accuracy: 0.826712668371931
Current Validation Loss: 0.00024386716264517084
Saving best model based on accuracy
Epoch 10
Best Validation Accuracy: 0.826712668371931
Current Validation Accuracy: 0.7600385403920691
Current Validation Loss: 0.0003375323730485675
Epoch 11
Best Validation Accuracy: 0.826712668371931
Current Validation Accuracy: 0.8151355447581878
Current Validation Loss: 0.0002595587917652405
Epoch 12
Best Validation Accuracy: 0.826712668371931
Current Validation Accuracy: 0.8454420234080986
Current Validation Loss: 0.00021877216776373376
Saving best model based on accuracy
Epoch 13
Best Validation Accuracy: 0.8454420234080986
Current Validation Accuracy: 0.8488683918139807
Current Validation Loss: 0.00021349858392690914
Saving best model based on accuracy
Epoch 14
Best Validation Accuracy: 0.8488683918139807
Current Validation Accuracy: 0.85053405703903
Current Validation Loss: 0.00021092624446561396
Saving best model based on accuracy
Epoch 15
Best Validation Accuracy: 0.85053405703903
Current Validation Accuracy: 0.8500057210348383
Current Validation Loss: 0.0002117469496851974
Epoch 16
Best Validation Accuracy: 0.85053405703903
Current Validation Accuracy: 0.8523110167122995
Current Validation Loss: 0.0002080156195828666
Saving best model based on accuracy
Epoch 17
Best Validation Accuracy: 0.8523110167122995
Current Validation Accuracy: 0.8522828804753898
Current Validation Loss: 0.00020789327020276894
Validation Accuracy has not changed much, will stop in 4 epochs if this continues
Epoch 18
Best Validation Accuracy: 0.8523110167122995
Current Validation Accuracy: 0.8540010666760037
Current Validation Loss: 0.00020554629918513356
Saving best model based on accuracy
Epoch 19
Best Validation Accuracy: 0.8540010666760037
Current Validation Accuracy: 0.8548651617739835
Current Validation Loss: 0.0002043967548659216
Saving best model based on accuracy
Epoch 20
Best Validation Accuracy: 0.8548651617739835
Current Validation Accuracy: 0.8546482001249249
Current Validation Loss: 0.00020480440378163297
Epoch 21
Best Validation Accuracy: 0.8548651617739835
Current Validation Accuracy: 0.8564520455356858
Current Validation Loss: 0.00020222071083815822
Saving best model based on accuracy
Epoch 22
Best Validation Accuracy: 0.8564520455356858
Current Validation Accuracy: 0.8535383818912678
Current Validation Loss: 0.00020600305493182584
Epoch 23
Best Validation Accuracy: 0.8564520455356858
Current Validation Accuracy: 0.8562075728994267
Current Validation Loss: 0.00020224997083971227
Epoch 24
Best Validation Accuracy: 0.8564520455356858
Current Validation Accuracy: 0.8573098881365745
Current Validation Loss: 0.00020110753730739255
Saving best model based on accuracy
Epoch 25
Best Validation Accuracy: 0.8573098881365745
Current Validation Accuracy: 0.8580933260220801
Current Validation Loss: 0.00019969236121027806
Saving best model based on accuracy
Epoch 26
Best Validation Accuracy: 0.8580933260220801
Current Validation Accuracy: 0.8580920755226619
Current Validation Loss: 0.0001998502674130904
Validation Accuracy has not changed much, will stop in 4 epochs if this continues
Epoch 27
Best Validation Accuracy: 0.8580933260220801
Current Validation Accuracy: 0.8572361086709004
Current Validation Loss: 0.00020077312074805826
Epoch 28
Best Validation Accuracy: 0.8580933260220801
Current Validation Accuracy: 0.8595057651149428
Current Validation Loss: 0.00019776423548817837
Saving best model based on accuracy
Epoch 29
[[9.92649615e-01 5.40245674e-04 2.75867758e-03 3.80247552e-03
  3.54779877e-05 5.69651311e-05 3.31059455e-05 1.23412159e-04]
 [5.13063557e-02 1.60745042e-03 1.38547599e-01 6.85212374e-01
  1.20359816e-01 1.31998468e-05 2.94950185e-03 3.68025349e-06]
 [2.69333168e-06 1.33290250e-05 1.14582317e-05 2.43401956e-07
  2.72602193e-07 2.51273811e-03 1.47836161e-07 9.97459114e-01]
 [1.39965098e-02 2.05567270e-03 4.30160761e-02 3.49985459e-03
  7.89002329e-03 9.26870167e-01 2.19855551e-03 4.73038119e-04]
 [1.85868885e-06 2.96323215e-05 6.52077574e-08 3.60945791e-07
  9.70006853e-10 2.18229223e-04 2.41398681e-07 9.99749601e-01]
 [5.24629024e-04 4.72336978e-06 1.62616058e-03 3.25050252e-03
  9.94228959e-01 3.37218007e-05 3.31343879e-04 2.89856423e-08]
 [9.99851584e-01 1.15579667e-06 8.96827187e-05 8.19639263e-06
  2.32294568e-07 4.72717729e-05 6.36898505e-07 1.19318861e-06]
 [2.20280592e-04 8.27353069e-05 3.70424986e-02 5.51031437e-03
  9.56028521e-01 9.60962097e-06 1.10591261e-03 5.66361322e-08]
 [9.99485850e-01 2.16393637e-05 2.30604885e-04 1.94625027e-04
  2.33989226e-06 3.75031304e-05 6.25124949e-06 2.11091992e-05]
 [1.92665067e-02 1.61129644e-03 5.44498451e-02 1.39017627e-01
  7.49689579e-01 1.95796718e-04 3.57651748e-02 4.21811546e-06]
 [9.99258816e-01 9.41320877e-07 5.87833405e-04 3.76328571e-05
  6.27093755e-07 9.55349333e-06 7.92871215e-05 2.53730304e-05]
 [3.46408859e-02 3.47750407e-04 4.03646417e-02 8.64050910e-02
  7.96056449e-01 8.47554402e-05 4.20934744e-02 7.02701800e-06]
 [6.59822899e-06 5.76174727e-07 2.40891241e-05 4.02264141e-06
  1.23613845e-05 9.99851942e-01 3.54604367e-06 9.68084641e-05]
 [8.20863098e-02 3.40292754e-05 1.78019388e-03 3.88900936e-02
  5.93396842e-01 4.19172662e-04 2.83389449e-01 3.98646762e-06]
 [2.59270397e-04 8.29523662e-04 2.57190201e-04 1.18214040e-04
  2.67850235e-04 1.29422654e-06 9.98242855e-01 2.37998520e-05]
 [8.65932452e-06 8.68316548e-08 7.40376754e-06 7.71185000e-07
  8.87834722e-06 9.85405564e-01 1.36752661e-07 1.45685589e-02]
 [8.87349471e-02 2.50239111e-03 6.72868431e-01 1.05691083e-01
  9.82471332e-02 1.08900313e-04 3.18459198e-02 1.25898396e-06]
 [4.98334765e-02 9.46293056e-01 1.45231164e-03 4.65149380e-04
  9.70886231e-06 6.61425520e-06 5.61890658e-04 1.37782993e-03]
 [1.19109291e-06 4.88374567e-08 5.69293070e-06 6.94857079e-07
  1.03877828e-05 9.99914169e-01 2.25486261e-08 6.78892175e-05]
 [4.56614746e-03 9.34940018e-03 1.05772093e-01 1.79054532e-02
  8.18031013e-01 4.25571088e-05 4.43229862e-02 1.03088341e-05]]
[[9.92649615e-01 5.40245674e-04 2.75867758e-03 3.80247552e-03
  3.54779877e-05 5.69651311e-05 3.31059455e-05 1.23412159e-04]
 [5.13063557e-02 1.60745042e-03 1.38547599e-01 6.85212374e-01
  1.20359816e-01 1.31998468e-05 2.94950185e-03 3.68025349e-06]
 [2.69333168e-06 1.33290250e-05 1.14582317e-05 2.43401956e-07
  2.72602193e-07 2.51273811e-03 1.47836161e-07 9.97459114e-01]
 [1.39965098e-02 2.05567270e-03 4.30160761e-02 3.49985459e-03
  7.89002329e-03 9.26870167e-01 2.19855551e-03 4.73038119e-04]
 [1.85868885e-06 2.96323215e-05 6.52077574e-08 3.60945791e-07
  9.70006853e-10 2.18229223e-04 2.41398681e-07 9.99749601e-01]
 [5.24629024e-04 4.72336978e-06 1.62616058e-03 3.25050252e-03
  9.94228959e-01 3.37218007e-05 3.31343879e-04 2.89856423e-08]
 [9.99851584e-01 1.15579667e-06 8.96827187e-05 8.19639263e-06
  2.32294568e-07 4.72717729e-05 6.36898505e-07 1.19318861e-06]
 [2.20280592e-04 8.27353069e-05 3.70424986e-02 5.51031437e-03
  9.56028521e-01 9.60962097e-06 1.10591261e-03 5.66361322e-08]
 [9.99485850e-01 2.16393637e-05 2.30604885e-04 1.94625027e-04
  2.33989226e-06 3.75031304e-05 6.25124949e-06 2.11091992e-05]
 [1.92665067e-02 1.61129644e-03 5.44498451e-02 1.39017627e-01
  7.49689579e-01 1.95796718e-04 3.57651748e-02 4.21811546e-06]
 [9.99258816e-01 9.41320877e-07 5.87833405e-04 3.76328571e-05
  6.27093755e-07 9.55349333e-06 7.92871215e-05 2.53730304e-05]
 [3.46408859e-02 3.47750407e-04 4.03646417e-02 8.64050910e-02
  7.96056449e-01 8.47554402e-05 4.20934744e-02 7.02701800e-06]
 [6.59822899e-06 5.76174727e-07 2.40891241e-05 4.02264141e-06
  1.23613845e-05 9.99851942e-01 3.54604367e-06 9.68084641e-05]
 [8.20863098e-02 3.40292754e-05 1.78019388e-03 3.88900936e-02
  5.93396842e-01 4.19172662e-04 2.83389449e-01 3.98646762e-06]
 [2.59270397e-04 8.29523662e-04 2.57190201e-04 1.18214040e-04
  2.67850235e-04 1.29422654e-06 9.98242855e-01 2.37998520e-05]
 [8.65932452e-06 8.68316548e-08 7.40376754e-06 7.71185000e-07
  8.87834722e-06 9.85405564e-01 1.36752661e-07 1.45685589e-02]
 [8.87349471e-02 2.50239111e-03 6.72868431e-01 1.05691083e-01
  9.82471332e-02 1.08900313e-04 3.18459198e-02 1.25898396e-06]
 [4.98334765e-02 9.46293056e-01 1.45231164e-03 4.65149380e-04
  9.70886231e-06 6.61425520e-06 5.61890658e-04 1.37782993e-03]
 [1.19109291e-06 4.88374567e-08 5.69293070e-06 6.94857079e-07
  1.03877828e-05 9.99914169e-01 2.25486261e-08 6.78892175e-05]
 [4.56614746e-03 9.34940018e-03 1.05772093e-01 1.79054532e-02
  8.18031013e-01 4.25571088e-05 4.43229862e-02 1.03088341e-05]]
[[1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0.]]
Best Validation Accuracy: 0.8595057651149428
Current Validation Accuracy: 0.8585816460448892
Current Validation Loss: 0.00019873619595226941
Saving last model
