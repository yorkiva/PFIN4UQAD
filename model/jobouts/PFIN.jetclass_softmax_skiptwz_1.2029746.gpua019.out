Running "module reset". Resetting modules to system default. The following $MODULEPATH directories have been removed: None
A conda environment has been detected CONDA_PREFIX=
/sw/external/python/anaconda3 
anaconda3_gpu is loaded. Consider running conda deactivate and reloading it.

Currently Loaded Modules:
  1) cue-login-env/1.0   4) gcc/11.2.0    7) openmpi/4.1.2
  2) default             5) cuda/11.6.1   8) cudnn/8.4.1.50
  3) modtree/gpu         6) ucx/1.11.2    9) anaconda3_gpu/4.13.0

 

/u/avroy/UQ_XAI_Studies/models/PFIN_UQ/model/jobsub
total 508K
-rw-rw----+ 1 avroy delta_bbhj  925 Mar 31 16:58 jobsubmitter_dummy.py
-rw-rw----+ 1 avroy delta_bbhj 5.2K May 27 21:16 jobsubmitter_jetclass_1gpu.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 27 21:04 jobsubmitter_jetclass_1gpu.py~
-rw-rw----+ 1 avroy delta_bbhj  743 May 19 01:04 jobsubmitter_jetclass.py
-rw-rw----+ 1 avroy delta_bbhj  15K May 18 13:59 jobsubmitter.py
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 19 13:52 UQPFIN-jetclass-run-jetclass20M_0_baseline.slurm
-rw-------+ 1 avroy delta_bbhj  973 May 19 00:59 UQPFIN-jetclass-run.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 27 21:18 UQPFIN-run-jetclass_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiph.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skiptwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiph_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skiptwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 27 21:18 UQPFIN-run-jetclass_softmax_skipwz_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0.1_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_0_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_nominal_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_baseline_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_baseline.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skiptop.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.2K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_dropout_skipwz.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skiptop_9.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_0.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_1.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_2.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_3.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_4.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_5.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_6.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_7.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_8.slurm
-rw-rw----+ 1 avroy delta_bbhj 1.1K May 18 14:02 UQPFIN-run-JNqgmerged_softmax_skipwz_9.slurm
-rw-------+ 1 avroy delta_bbhj  969 May 15 09:44 UQPFIN-run.slurm
/projects/bbhj/avroy/UQ_XAI_Studies/models/PFIN_UQ/model
total 200K
drwxr-s---+ 2 avroy delta_bbhj  12K May 28 10:54 jobouts
drwxr-s---+ 2 avroy delta_bbhj  16K May 27 21:18 jobsub
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 18 21:37 PFINDataset.py
-rw-rw----+ 1 avroy delta_bbhj 8.4K May 15 14:46 PFINDataset.py~
drwxrws---+ 2 avroy delta_bbhj 4.0K May 18 21:38 __pycache__
drwxrws---+ 2 avroy delta_bbhj  20K May 28 10:25 trained_model_dicts
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:09 trained_model_dicts_old
drwxrws---+ 2 avroy delta_bbhj  36K May 28 10:54 trained_models
drwxr-s---+ 2 avroy delta_bbhj 4.0K Mar 31 15:10 trained_models_old
-rw-rw----+ 1 avroy delta_bbhj  23K May 18 15:52 train_mod.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 27 21:06 train.py
-rw-rw----+ 1 avroy delta_bbhj  20K May 18 13:50 train.py~
-rw-rw----+ 1 avroy delta_bbhj  13K May  5 09:36 UQPFIN.py
job is starting on gpua019.delta.ncsa.illinois.edu
# conda environments:
#
base                     /sw/external/python/anaconda3
toptagger_env         *  /u/avroy/.conda/envs/toptagger_env

/sw/external/python/anaconda3_gpu/bin/python
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
UQPFIN                                   [1, 6]                    --
├─Sequential: 1-1                        [60, 64]                  --
│    └─Sequential: 2-1                   [60, 100]                 --
│    │    └─Linear: 3-1                  [60, 100]                 1,200
│    │    └─ReLU: 3-2                    [60, 100]                 --
│    └─Sequential: 2-2                   [60, 100]                 --
│    │    └─Linear: 3-3                  [60, 100]                 10,100
│    │    └─ReLU: 3-4                    [60, 100]                 --
│    └─Sequential: 2-3                   [60, 64]                  --
│    │    └─Linear: 3-5                  [60, 64]                  6,464
│    │    └─ReLU: 3-6                    [60, 64]                  --
├─Sequential: 1-2                        [1770, 64]                --
│    └─Sequential: 2-4                   [1770, 128]               --
│    │    └─Linear: 3-7                  [1770, 128]               640
│    │    └─ReLU: 3-8                    [1770, 128]               --
│    └─Sequential: 2-5                   [1770, 128]               --
│    │    └─Linear: 3-9                  [1770, 128]               16,512
│    │    └─ReLU: 3-10                   [1770, 128]               --
│    └─Sequential: 2-6                   [1770, 64]                --
│    │    └─Linear: 3-11                 [1770, 64]                8,256
│    │    └─ReLU: 3-12                   [1770, 64]                --
├─Sequential: 1-3                        [60, 64]                  --
│    └─Sequential: 2-7                   [60, 128]                 --
│    │    └─Linear: 3-13                 [60, 128]                 9,728
│    │    └─ReLU: 3-14                   [60, 128]                 --
│    └─Sequential: 2-8                   [60, 128]                 --
│    │    └─Linear: 3-15                 [60, 128]                 16,512
│    │    └─ReLU: 3-16                   [60, 128]                 --
│    └─Sequential: 2-9                   [60, 64]                  --
│    │    └─Linear: 3-17                 [60, 64]                  8,256
│    │    └─ReLU: 3-18                   [60, 64]                  --
├─Sequential: 1-4                        [1, 6]                    --
│    └─Sequential: 2-10                  [1, 64]                   --
│    │    └─Linear: 3-19                 [1, 64]                   4,160
│    │    └─ReLU: 3-20                   [1, 64]                   --
│    └─Sequential: 2-11                  [1, 100]                  --
│    │    └─Linear: 3-21                 [1, 100]                  6,500
│    │    └─ReLU: 3-22                   [1, 100]                  --
│    └─Sequential: 2-12                  [1, 100]                  --
│    │    └─Linear: 3-23                 [1, 100]                  10,100
│    │    └─ReLU: 3-24                   [1, 100]                  --
│    └─Linear: 2-13                      [1, 6]                    606
│    └─Softmax: 2-14                     [1, 6]                    --
==========================================================================================
Total params: 99,034
Trainable params: 99,034
Non-trainable params: 0
Total mult-adds (M): 48.13
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 4.81
Params size (MB): 0.40
Estimated Total Size (MB): 5.21
==========================================================================================
data type:  jetclass
m_logic, pt_logic, eta_logic:  AND AND AND
m1, m2, pt1, pt2, eta1, eta2:  0.0 10000.0 0.0 10000.0 -6.0 6.0
skip labels:  [6, 7, 8, 9]
classes:  6
Epoch 0
Best Validation Accuracy: 0
Current Validation Accuracy: 0.741705499262535
Current Validation Loss: 0.0004523535752341393
Saving best model based on accuracy
Epoch 1
Best Validation Accuracy: 0.741705499262535
Current Validation Accuracy: 0.7514230280837
Current Validation Loss: 0.0004385988299647003
Saving best model based on accuracy
Epoch 2
Best Validation Accuracy: 0.7514230280837
Current Validation Accuracy: 0.7571835091326428
Current Validation Loss: 0.00042938468735718305
Saving best model based on accuracy
Epoch 3
Best Validation Accuracy: 0.7571835091326428
Current Validation Accuracy: 0.7580923127718594
Current Validation Loss: 0.00042777737832410296
Saving best model based on accuracy
Epoch 4
Best Validation Accuracy: 0.7580923127718594
Current Validation Accuracy: 0.7604226854063645
Current Validation Loss: 0.00042407098475332286
Saving best model based on accuracy
Epoch 5
Best Validation Accuracy: 0.7604226854063645
Current Validation Accuracy: 0.7614115304670167
Current Validation Loss: 0.00042247613442231375
Saving best model based on accuracy
Epoch 6
Best Validation Accuracy: 0.7614115304670167
Current Validation Accuracy: 0.7614515511777344
Current Validation Loss: 0.0004221814789148616
Saving best model based on accuracy
Epoch 7
Best Validation Accuracy: 0.7614515511777344
Current Validation Accuracy: 0.764106258322015
Current Validation Loss: 0.00041835507534846816
Saving best model based on accuracy
Epoch 8
Best Validation Accuracy: 0.764106258322015
Current Validation Accuracy: 0.7612339385632064
Current Validation Loss: 0.0004231257680934875
Epoch 9
Best Validation Accuracy: 0.764106258322015
Current Validation Accuracy: 0.7601525456090193
Current Validation Loss: 0.0004249544184324319
Epoch 10
Best Validation Accuracy: 0.764106258322015
Current Validation Accuracy: 0.7989159389984317
Current Validation Loss: 0.00036562810633010515
Saving best model based on accuracy
Epoch 11
Best Validation Accuracy: 0.7989159389984317
Current Validation Accuracy: 0.8290648744058383
Current Validation Loss: 0.00031291453788208844
Saving best model based on accuracy
Epoch 12
Best Validation Accuracy: 0.8290648744058383
Current Validation Accuracy: 0.8022968552892789
Current Validation Loss: 0.00035917917974636417
Epoch 13
Best Validation Accuracy: 0.8290648744058383
Current Validation Accuracy: 0.8318746618041503
Current Validation Loss: 0.0003076758178576451
Saving best model based on accuracy
Epoch 14
Best Validation Accuracy: 0.8318746618041503
Current Validation Accuracy: 0.8156470973728904
Current Validation Loss: 0.0003366732905587127
Epoch 15
Best Validation Accuracy: 0.8318746618041503
Current Validation Accuracy: 0.8022118112790035
Current Validation Loss: 0.00035896001936065606
Epoch 16
Best Validation Accuracy: 0.8318746618041503
Current Validation Accuracy: 0.8291490846513071
Current Validation Loss: 0.0003114558109610619
Epoch 17
Best Validation Accuracy: 0.8318746618041503
Current Validation Accuracy: 0.8339574062910889
Current Validation Loss: 0.00030316149305969765
Saving best model based on accuracy
Epoch 18
Best Validation Accuracy: 0.8339574062910889
Current Validation Accuracy: 0.8349921084161054
Current Validation Loss: 0.00030100314529049496
Saving best model based on accuracy
Epoch 19
Best Validation Accuracy: 0.8349921084161054
Current Validation Accuracy: 0.8368797519382948
Current Validation Loss: 0.0002988018555587459
Saving best model based on accuracy
Epoch 20
Best Validation Accuracy: 0.8368797519382948
Current Validation Accuracy: 0.8392626517556169
Current Validation Loss: 0.00029360894815132996
Saving best model based on accuracy
Epoch 21
Best Validation Accuracy: 0.8392626517556169
Current Validation Accuracy: 0.8400238790240616
Current Validation Loss: 0.0002918870279498564
Saving best model based on accuracy
Epoch 22
Best Validation Accuracy: 0.8400238790240616
Current Validation Accuracy: 0.8392626517556169
Current Validation Loss: 0.00029381441113095994
Epoch 23
Best Validation Accuracy: 0.8400238790240616
Current Validation Accuracy: 0.8162674183890163
Current Validation Loss: 0.00033504114393367624
Epoch 24
Best Validation Accuracy: 0.8400238790240616
Current Validation Accuracy: 0.8400972503270443
Current Validation Loss: 0.0002920642206184035
Saving best model based on accuracy
Epoch 25
Best Validation Accuracy: 0.8400972503270443
Current Validation Accuracy: 0.8410010513774211
Current Validation Loss: 0.0002902979272767802
Saving best model based on accuracy
Epoch 26
Best Validation Accuracy: 0.8410010513774211
Current Validation Accuracy: 0.8414796323764214
Current Validation Loss: 0.0002897316402386977
Saving best model based on accuracy
Epoch 27
Best Validation Accuracy: 0.8414796323764214
Current Validation Accuracy: 0.8425485188585092
Current Validation Loss: 0.0002874902914490101
Saving best model based on accuracy
Epoch 28
Best Validation Accuracy: 0.8425485188585092
Current Validation Accuracy: 0.8406683792195795
Current Validation Loss: 0.00029129266299974274
Epoch 29
[[9.9292094e-01 1.8869121e-04 3.1789092e-03 3.6321059e-03 4.8531780e-05
  3.0784959e-05]
 [3.2000739e-02 6.1703927e-04 1.0106212e-01 7.8858274e-01 7.7717692e-02
  1.9695661e-05]
 [1.7616063e-03 9.0384105e-04 1.4449140e-02 3.0086661e-04 8.2570768e-04
  9.8175883e-01]
 [4.4776549e-04 7.2294154e-07 3.7842023e-04 3.7437158e-03 9.9538523e-01
  4.4097513e-05]
 [9.9973494e-01 2.3753200e-06 1.8365224e-04 3.3634118e-05 4.0169436e-07
  4.5034085e-05]
 [2.6847515e-04 8.6328648e-05 2.2165654e-02 7.3006861e-03 9.7017598e-01
  2.9103373e-06]
 [9.9925524e-01 2.5770021e-05 5.2925589e-04 1.5994662e-04 1.9485626e-06
  2.7877966e-05]
 [1.1723097e-02 1.6655095e-03 1.4849205e-01 1.9117513e-01 6.4693016e-01
  1.4093827e-05]
 [9.9872237e-01 2.9764260e-06 1.2170874e-03 4.9928331e-05 1.2219410e-06
  6.4447158e-06]
 [6.1312113e-03 1.4590136e-03 5.7404377e-02 5.5524305e-02 8.7946618e-01
  1.4961156e-05]
 [1.4820308e-06 5.9027337e-07 4.0883592e-06 9.1171182e-07 7.2832645e-06
  9.9998558e-01]
 [6.5627918e-02 8.2327068e-05 3.5580727e-03 5.9926022e-02 8.7038183e-01
  4.2380748e-04]
 [6.3193539e-07 7.1883910e-08 8.8194668e-07 1.4795857e-11 4.7464335e-09
  9.9999833e-01]
 [4.5849726e-02 3.1687906e-03 3.6683112e-01 8.2579955e-02 5.0107610e-01
  4.9428875e-04]
 [3.1735525e-01 6.5856802e-01 1.7716968e-02 2.5377034e-03 8.6336152e-04
  2.9586975e-03]
 [2.6637755e-07 3.7819254e-07 2.7303820e-06 9.5333590e-08 5.6865897e-06
  9.9999082e-01]
 [4.2342641e-03 4.9852738e-03 5.0416913e-02 3.3516467e-02 9.0682751e-01
  1.9559799e-05]
 [1.2692975e-01 1.2877387e-04 4.4928431e-03 4.1070890e-01 4.5768410e-01
  5.5706489e-05]
 [1.4110965e-02 2.5189302e-03 6.2240601e-02 1.0670717e-01 8.1437176e-01
  5.0651062e-05]
 [9.7238906e-03 3.9038971e-02 9.4548994e-01 5.6551760e-03 8.6419241e-05
  5.6707913e-06]]
[[9.9292094e-01 1.8869121e-04 3.1789092e-03 3.6321059e-03 4.8531780e-05
  3.0784959e-05]
 [3.2000739e-02 6.1703927e-04 1.0106212e-01 7.8858274e-01 7.7717692e-02
  1.9695661e-05]
 [1.7616063e-03 9.0384105e-04 1.4449140e-02 3.0086661e-04 8.2570768e-04
  9.8175883e-01]
 [4.4776549e-04 7.2294154e-07 3.7842023e-04 3.7437158e-03 9.9538523e-01
  4.4097513e-05]
 [9.9973494e-01 2.3753200e-06 1.8365224e-04 3.3634118e-05 4.0169436e-07
  4.5034085e-05]
 [2.6847515e-04 8.6328648e-05 2.2165654e-02 7.3006861e-03 9.7017598e-01
  2.9103373e-06]
 [9.9925524e-01 2.5770021e-05 5.2925589e-04 1.5994662e-04 1.9485626e-06
  2.7877966e-05]
 [1.1723097e-02 1.6655095e-03 1.4849205e-01 1.9117513e-01 6.4693016e-01
  1.4093827e-05]
 [9.9872237e-01 2.9764260e-06 1.2170874e-03 4.9928331e-05 1.2219410e-06
  6.4447158e-06]
 [6.1312113e-03 1.4590136e-03 5.7404377e-02 5.5524305e-02 8.7946618e-01
  1.4961156e-05]
 [1.4820308e-06 5.9027337e-07 4.0883592e-06 9.1171182e-07 7.2832645e-06
  9.9998558e-01]
 [6.5627918e-02 8.2327068e-05 3.5580727e-03 5.9926022e-02 8.7038183e-01
  4.2380748e-04]
 [6.3193539e-07 7.1883910e-08 8.8194668e-07 1.4795857e-11 4.7464335e-09
  9.9999833e-01]
 [4.5849726e-02 3.1687906e-03 3.6683112e-01 8.2579955e-02 5.0107610e-01
  4.9428875e-04]
 [3.1735525e-01 6.5856802e-01 1.7716968e-02 2.5377034e-03 8.6336152e-04
  2.9586975e-03]
 [2.6637755e-07 3.7819254e-07 2.7303820e-06 9.5333590e-08 5.6865897e-06
  9.9999082e-01]
 [4.2342641e-03 4.9852738e-03 5.0416913e-02 3.3516467e-02 9.0682751e-01
  1.9559799e-05]
 [1.2692975e-01 1.2877387e-04 4.4928431e-03 4.1070890e-01 4.5768410e-01
  5.5706489e-05]
 [1.4110965e-02 2.5189302e-03 6.2240601e-02 1.0670717e-01 8.1437176e-01
  5.0651062e-05]
 [9.7238906e-03 3.9038971e-02 9.4548994e-01 5.6551760e-03 8.6419241e-05
  5.6707913e-06]]
[[1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 0.]]
Best Validation Accuracy: 0.8425485188585092
Current Validation Accuracy: 0.8423083945942025
Current Validation Loss: 0.0002884691402731343
Saving last model
